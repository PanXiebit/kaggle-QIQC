[2019-02-23 18:55:06,597]   >> device: cuda n_gpu: 1, distributed training: False, 16-bits training: False
[2019-02-23 18:55:06,613]   >> LOOKING AT /home/panxie/Document/kaggle/quora/data/splited_data/train.csv
[2019-02-23 18:56:45,951]   >> ***** Running evaluation *****
[2019-02-23 18:56:45,951]   >>   Num examples = 261225
[2019-02-23 18:56:45,952]   >>   Batch size = 8
[2019-02-23 18:59:07,523]   >> ***** Running training *****
[2019-02-23 18:59:07,524]   >>   Num examples = 1044897
[2019-02-23 18:59:07,524]   >>   Batch size = 64
[2019-02-23 18:59:07,524]   >>   Num steps = 48979
[2019-02-23 19:00:21,288]   >> |----epoch 0, eclipse 300/16327, lr 3.052328548969967e-06,loss 0.4544, acc 0.6164
[2019-02-23 19:01:34,163]   >> |----epoch 0, eclipse 600/16327, lr 6.114865554625452e-06,loss 0.3019, acc 0.9314
[2019-02-23 19:02:47,163]   >> |----epoch 0, eclipse 900/16327, lr 9.177402560280938e-06,loss 0.1908, acc 0.9371
[2019-02-23 19:04:00,216]   >> |----epoch 0, eclipse 1200/16327, lr 1.2239939565936422e-05,loss 0.1373, acc 0.9479
[2019-02-23 19:05:13,279]   >> |----epoch 0, eclipse 1500/16327, lr 1.5302476571591906e-05,loss 0.1224, acc 0.9486
[2019-02-23 19:06:26,384]   >> |----epoch 0, eclipse 1800/16327, lr 1.836501357724739e-05,loss 0.1142, acc 0.9518
[2019-02-23 19:07:39,501]   >> |----epoch 0, eclipse 2100/16327, lr 2.1427550582902875e-05,loss 0.1123, acc 0.9518
[2019-02-23 19:08:52,617]   >> |----epoch 0, eclipse 2400/16327, lr 2.4490087588558362e-05,loss 0.1106, acc 0.9525
[2019-02-23 19:10:05,740]   >> |----epoch 0, eclipse 2700/16327, lr 2.7552624594213843e-05,loss 0.1073, acc 0.9543
[2019-02-23 19:11:18,877]   >> |----epoch 0, eclipse 3000/16327, lr 3.0615161599869334e-05,loss 0.1138, acc 0.9531
[2019-02-23 19:12:31,970]   >> |----epoch 0, eclipse 3300/16327, lr 3.367769860552482e-05,loss 0.1151, acc 0.9514
[2019-02-23 19:13:45,129]   >> |----epoch 0, eclipse 3600/16327, lr 3.67402356111803e-05,loss 0.1129, acc 0.9522
[2019-02-23 19:14:58,238]   >> |----epoch 0, eclipse 3900/16327, lr 3.980277261683578e-05,loss 0.1053, acc 0.9528
[2019-02-23 19:16:11,355]   >> |----epoch 0, eclipse 4200/16327, lr 4.286530962249127e-05,loss 0.1081, acc 0.9547
[2019-02-23 19:17:24,542]   >> |----epoch 0, eclipse 4500/16327, lr 4.592784662814676e-05,loss 0.1064, acc 0.9526
[2019-02-23 19:18:37,736]   >> |----epoch 0, eclipse 4800/16327, lr 4.899038363380224e-05,loss 0.1100, acc 0.9543
[2019-02-23 19:19:51,108]   >> |----epoch 0, eclipse 5100/16327, lr 4.479470793605423e-05,loss 0.1032, acc 0.9558
[2019-02-23 19:21:04,326]   >> |----epoch 0, eclipse 5400/16327, lr 4.448845423548868e-05,loss 0.1086, acc 0.9532
[2019-02-23 19:22:17,574]   >> |----epoch 0, eclipse 5700/16327, lr 4.418220053492314e-05,loss 0.1000, acc 0.9568
[2019-02-23 19:23:30,812]   >> |----epoch 0, eclipse 6000/16327, lr 4.3875946834357584e-05,loss 0.1058, acc 0.9556
[2019-02-23 19:24:44,105]   >> |----epoch 0, eclipse 6300/16327, lr 4.356969313379203e-05,loss 0.1013, acc 0.9580
[2019-02-23 19:25:57,403]   >> |----epoch 0, eclipse 6600/16327, lr 4.326343943322649e-05,loss 0.1003, acc 0.9578
[2019-02-23 19:27:10,695]   >> |----epoch 0, eclipse 6900/16327, lr 4.2957185732660936e-05,loss 0.0984, acc 0.9591
[2019-02-23 19:28:23,975]   >> |----epoch 0, eclipse 7200/16327, lr 4.265093203209539e-05,loss 0.0959, acc 0.9598
[2019-02-23 19:29:37,284]   >> |----epoch 0, eclipse 7500/16327, lr 4.234467833152984e-05,loss 0.0991, acc 0.9581
[2019-02-23 19:30:50,595]   >> |----epoch 0, eclipse 7800/16327, lr 4.203842463096429e-05,loss 0.1031, acc 0.9564
[2019-02-23 19:32:03,866]   >> |----epoch 0, eclipse 8100/16327, lr 4.173217093039875e-05,loss 0.1011, acc 0.9570
[2019-02-23 19:33:17,073]   >> |----epoch 0, eclipse 8400/16327, lr 4.1425917229833194e-05,loss 0.1006, acc 0.9582
[2019-02-23 19:34:30,277]   >> |----epoch 0, eclipse 8700/16327, lr 4.111966352926765e-05,loss 0.0958, acc 0.9590
[2019-02-23 19:35:43,486]   >> |----epoch 0, eclipse 9000/16327, lr 4.08134098287021e-05,loss 0.1002, acc 0.9567
[2019-02-23 19:36:56,702]   >> |----epoch 0, eclipse 9300/16327, lr 4.0507156128136546e-05,loss 0.0952, acc 0.9590
[2019-02-23 19:38:09,906]   >> |----epoch 0, eclipse 9600/16327, lr 4.0200902427571e-05,loss 0.0988, acc 0.9563
[2019-02-23 19:39:23,105]   >> |----epoch 0, eclipse 9900/16327, lr 3.989464872700545e-05,loss 0.1005, acc 0.9585
[2019-02-23 19:40:36,310]   >> |----epoch 0, eclipse 10200/16327, lr 3.9588395026439905e-05,loss 0.0973, acc 0.9596
[2019-02-23 19:41:49,515]   >> |----epoch 0, eclipse 10500/16327, lr 3.928214132587436e-05,loss 0.1046, acc 0.9565
[2019-02-23 19:43:02,713]   >> |----epoch 0, eclipse 10800/16327, lr 3.8975887625308804e-05,loss 0.0963, acc 0.9583
[2019-02-23 19:44:15,904]   >> |----epoch 0, eclipse 11100/16327, lr 3.866963392474326e-05,loss 0.0995, acc 0.9587
[2019-02-23 19:45:29,133]   >> |----epoch 0, eclipse 11400/16327, lr 3.8363380224177716e-05,loss 0.1002, acc 0.9553
[2019-02-23 19:46:42,446]   >> |----epoch 0, eclipse 11700/16327, lr 3.805712652361216e-05,loss 0.0961, acc 0.9593
[2019-02-23 19:47:55,745]   >> |----epoch 0, eclipse 12000/16327, lr 3.7750872823046615e-05,loss 0.0991, acc 0.9591
[2019-02-23 19:49:09,040]   >> |----epoch 0, eclipse 12300/16327, lr 3.744461912248106e-05,loss 0.0986, acc 0.9582
[2019-02-23 19:50:22,344]   >> |----epoch 0, eclipse 12600/16327, lr 3.7138365421915515e-05,loss 0.0952, acc 0.9590
[2019-02-23 19:51:35,668]   >> |----epoch 0, eclipse 12900/16327, lr 3.6832111721349974e-05,loss 0.0953, acc 0.9603
[2019-02-23 19:52:48,997]   >> |----epoch 0, eclipse 13200/16327, lr 3.652585802078442e-05,loss 0.0931, acc 0.9607
[2019-02-23 19:54:02,317]   >> |----epoch 0, eclipse 13500/16327, lr 3.6219604320218867e-05,loss 0.0959, acc 0.9583
[2019-02-23 19:55:15,633]   >> |----epoch 0, eclipse 13800/16327, lr 3.591335061965332e-05,loss 0.0946, acc 0.9595
[2019-02-23 19:56:28,966]   >> |----epoch 0, eclipse 14100/16327, lr 3.560709691908777e-05,loss 0.0894, acc 0.9622
[2019-02-23 19:57:42,286]   >> |----epoch 0, eclipse 14400/16327, lr 3.5300843218522225e-05,loss 0.0954, acc 0.9588
[2019-02-23 19:58:55,606]   >> |----epoch 0, eclipse 14700/16327, lr 3.499458951795668e-05,loss 0.0962, acc 0.9572
[2019-02-23 20:00:08,932]   >> |----epoch 0, eclipse 15000/16327, lr 3.4688335817391124e-05,loss 0.0972, acc 0.9572
[2019-02-23 20:01:22,249]   >> |----epoch 0, eclipse 15300/16327, lr 3.4382082116825584e-05,loss 0.0952, acc 0.9587
[2019-02-23 20:02:35,511]   >> |----epoch 0, eclipse 15600/16327, lr 3.407582841626003e-05,loss 0.0920, acc 0.9607
[2019-02-23 20:03:48,741]   >> |----epoch 0, eclipse 15900/16327, lr 3.376957471569448e-05,loss 0.0919, acc 0.9617
[2019-02-23 20:05:01,970]   >> |----epoch 0, eclipse 16200/16327, lr 3.3463321015128936e-05,loss 0.0980, acc 0.9570
[2019-02-23 21:38:09,853]   >> device: cuda n_gpu: 1, distributed training: False, 16-bits training: False
[2019-02-23 21:38:09,870]   >> LOOKING AT /home/panxie/Document/kaggle/quora/data/splited_data/train.csv
[2019-02-23 21:39:49,596]   >> ***** Running evaluation *****
[2019-02-23 21:39:49,596]   >>   Num examples = 261225
[2019-02-23 21:39:49,596]   >>   Batch size = 8
[2019-02-23 21:42:09,863]   >> ***** Running training *****
[2019-02-23 21:42:09,863]   >>   Num examples = 1044897
[2019-02-23 21:42:09,864]   >>   Batch size = 64
[2019-02-23 21:42:09,864]   >>   Num steps = 48979
[2019-02-23 21:43:23,312]   >> |----epoch 0, eclipse 300/16327, lr 3.052328548969967e-06,loss 0.4544, acc 0.6164
[2019-02-23 21:44:35,929]   >> |----epoch 0, eclipse 600/16327, lr 6.114865554625452e-06,loss 0.3019, acc 0.9314
[2019-02-23 21:45:48,655]   >> |----epoch 0, eclipse 900/16327, lr 9.177402560280938e-06,loss 0.1908, acc 0.9371
[2019-02-23 21:47:01,431]   >> |----epoch 0, eclipse 1200/16327, lr 1.2239939565936422e-05,loss 0.1373, acc 0.9479
[2019-02-23 21:48:14,236]   >> |----epoch 0, eclipse 1500/16327, lr 1.5302476571591906e-05,loss 0.1224, acc 0.9486
[2019-02-23 21:49:27,070]   >> |----epoch 0, eclipse 1800/16327, lr 1.836501357724739e-05,loss 0.1142, acc 0.9518
[2019-02-23 21:50:39,907]   >> |----epoch 0, eclipse 2100/16327, lr 2.1427550582902875e-05,loss 0.1123, acc 0.9518
[2019-02-23 21:51:52,790]   >> |----epoch 0, eclipse 2400/16327, lr 2.4490087588558362e-05,loss 0.1106, acc 0.9525
[2019-02-23 21:53:05,707]   >> |----epoch 0, eclipse 2700/16327, lr 2.7552624594213843e-05,loss 0.1073, acc 0.9543
[2019-02-23 21:54:18,620]   >> |----epoch 0, eclipse 3000/16327, lr 3.0615161599869334e-05,loss 0.1138, acc 0.9531
[2019-02-23 21:55:31,578]   >> |----epoch 0, eclipse 3300/16327, lr 3.367769860552482e-05,loss 0.1151, acc 0.9514
[2019-02-23 21:56:44,531]   >> |----epoch 0, eclipse 3600/16327, lr 3.67402356111803e-05,loss 0.1129, acc 0.9522
[2019-02-23 21:57:57,479]   >> |----epoch 0, eclipse 3900/16327, lr 3.980277261683578e-05,loss 0.1053, acc 0.9528
[2019-02-23 21:59:10,418]   >> |----epoch 0, eclipse 4200/16327, lr 4.286530962249127e-05,loss 0.1081, acc 0.9547
[2019-02-23 22:00:23,339]   >> |----epoch 0, eclipse 4500/16327, lr 4.592784662814676e-05,loss 0.1064, acc 0.9526
[2019-02-23 22:01:36,274]   >> |----epoch 0, eclipse 4800/16327, lr 4.899038363380224e-05,loss 0.1100, acc 0.9543
[2019-02-23 22:02:49,223]   >> |----epoch 0, eclipse 5100/16327, lr 4.479470793605423e-05,loss 0.1032, acc 0.9558
[2019-02-23 22:04:02,178]   >> |----epoch 0, eclipse 5400/16327, lr 4.448845423548868e-05,loss 0.1086, acc 0.9532
[2019-02-23 22:05:15,137]   >> |----epoch 0, eclipse 5700/16327, lr 4.418220053492314e-05,loss 0.1000, acc 0.9568
[2019-02-23 22:06:28,108]   >> |----epoch 0, eclipse 6000/16327, lr 4.3875946834357584e-05,loss 0.1058, acc 0.9556
[2019-02-23 22:07:41,080]   >> |----epoch 0, eclipse 6300/16327, lr 4.356969313379203e-05,loss 0.1013, acc 0.9580
[2019-02-23 22:08:54,164]   >> |----epoch 0, eclipse 6600/16327, lr 4.326343943322649e-05,loss 0.1003, acc 0.9578
[2019-02-23 22:10:07,280]   >> |----epoch 0, eclipse 6900/16327, lr 4.2957185732660936e-05,loss 0.0984, acc 0.9591
[2019-02-23 22:11:20,368]   >> |----epoch 0, eclipse 7200/16327, lr 4.265093203209539e-05,loss 0.0959, acc 0.9598
[2019-02-23 22:12:33,467]   >> |----epoch 0, eclipse 7500/16327, lr 4.234467833152984e-05,loss 0.0991, acc 0.9581
[2019-02-23 22:13:46,555]   >> |----epoch 0, eclipse 7800/16327, lr 4.203842463096429e-05,loss 0.1031, acc 0.9564
[2019-02-23 22:14:59,635]   >> |----epoch 0, eclipse 8100/16327, lr 4.173217093039875e-05,loss 0.1011, acc 0.9570
[2019-02-23 22:16:12,705]   >> |----epoch 0, eclipse 8400/16327, lr 4.1425917229833194e-05,loss 0.1006, acc 0.9582
[2019-02-23 22:17:25,778]   >> |----epoch 0, eclipse 8700/16327, lr 4.111966352926765e-05,loss 0.0958, acc 0.9590
[2019-02-23 22:18:38,860]   >> |----epoch 0, eclipse 9000/16327, lr 4.08134098287021e-05,loss 0.1002, acc 0.9567
[2019-02-23 22:19:51,941]   >> |----epoch 0, eclipse 9300/16327, lr 4.0507156128136546e-05,loss 0.0952, acc 0.9590
[2019-02-23 22:21:05,013]   >> |----epoch 0, eclipse 9600/16327, lr 4.0200902427571e-05,loss 0.0988, acc 0.9563
[2019-02-23 22:22:18,110]   >> |----epoch 0, eclipse 9900/16327, lr 3.989464872700545e-05,loss 0.1005, acc 0.9585
[2019-02-23 22:23:31,229]   >> |----epoch 0, eclipse 10200/16327, lr 3.9588395026439905e-05,loss 0.0973, acc 0.9596
[2019-02-23 22:24:44,359]   >> |----epoch 0, eclipse 10500/16327, lr 3.928214132587436e-05,loss 0.1046, acc 0.9565
[2019-02-23 22:25:57,489]   >> |----epoch 0, eclipse 10800/16327, lr 3.8975887625308804e-05,loss 0.0963, acc 0.9583
[2019-02-23 22:27:10,617]   >> |----epoch 0, eclipse 11100/16327, lr 3.866963392474326e-05,loss 0.0995, acc 0.9587
[2019-02-23 22:28:23,761]   >> |----epoch 0, eclipse 11400/16327, lr 3.8363380224177716e-05,loss 0.1002, acc 0.9553
[2019-02-23 22:29:37,214]   >> |----epoch 0, eclipse 11700/16327, lr 3.805712652361216e-05,loss 0.0961, acc 0.9593
[2019-02-23 22:30:50,427]   >> |----epoch 0, eclipse 12000/16327, lr 3.7750872823046615e-05,loss 0.0991, acc 0.9591
[2019-02-23 22:32:03,617]   >> |----epoch 0, eclipse 12300/16327, lr 3.744461912248106e-05,loss 0.0986, acc 0.9582
[2019-02-23 22:33:16,867]   >> |----epoch 0, eclipse 12600/16327, lr 3.7138365421915515e-05,loss 0.0952, acc 0.9590
[2019-02-23 22:34:30,261]   >> |----epoch 0, eclipse 12900/16327, lr 3.6832111721349974e-05,loss 0.0953, acc 0.9603
[2019-02-23 22:35:43,472]   >> |----epoch 0, eclipse 13200/16327, lr 3.652585802078442e-05,loss 0.0931, acc 0.9607
[2019-02-23 22:36:56,602]   >> |----epoch 0, eclipse 13500/16327, lr 3.6219604320218867e-05,loss 0.0959, acc 0.9583
[2019-02-23 22:38:09,725]   >> |----epoch 0, eclipse 13800/16327, lr 3.591335061965332e-05,loss 0.0946, acc 0.9595
[2019-02-23 22:39:22,841]   >> |----epoch 0, eclipse 14100/16327, lr 3.560709691908777e-05,loss 0.0894, acc 0.9622
[2019-02-23 22:40:35,965]   >> |----epoch 0, eclipse 14400/16327, lr 3.5300843218522225e-05,loss 0.0954, acc 0.9588
[2019-02-23 22:41:49,099]   >> |----epoch 0, eclipse 14700/16327, lr 3.499458951795668e-05,loss 0.0962, acc 0.9572
[2019-02-23 22:43:02,221]   >> |----epoch 0, eclipse 15000/16327, lr 3.4688335817391124e-05,loss 0.0972, acc 0.9572
[2019-02-23 22:44:15,325]   >> |----epoch 0, eclipse 15300/16327, lr 3.4382082116825584e-05,loss 0.0952, acc 0.9587
[2019-02-23 22:45:28,433]   >> |----epoch 0, eclipse 15600/16327, lr 3.407582841626003e-05,loss 0.0920, acc 0.9607
[2019-02-23 22:46:41,538]   >> |----epoch 0, eclipse 15900/16327, lr 3.376957471569448e-05,loss 0.0919, acc 0.9617
[2019-02-23 22:47:54,643]   >> |----epoch 0, eclipse 16200/16327, lr 3.3463321015128936e-05,loss 0.0980, acc 0.9570
[2019-02-24 13:34:56,585]   >> device: cuda n_gpu: 1, distributed training: False, 16-bits training: False
[2019-02-24 13:34:56,602]   >> LOOKING AT /home/panxie/Document/kaggle/quora/data/splited_data/train.csv
[2019-02-24 13:36:36,088]   >> ***** Running evaluation *****
[2019-02-24 13:36:36,088]   >>   Num examples = 261225
[2019-02-24 13:36:36,088]   >>   Batch size = 8
[2019-02-24 13:38:55,399]   >> ***** Running training *****
[2019-02-24 13:38:55,399]   >>   Num examples = 1044897
[2019-02-24 13:38:55,399]   >>   Batch size = 64
[2019-02-24 13:38:55,400]   >>   Num steps = 48979
[2019-02-24 13:40:08,940]   >> |----epoch 0, eclipse 300/16327, lr 3.052328548969967e-06,loss 0.4544, acc 0.6164
[2019-02-24 13:41:21,669]   >> |----epoch 0, eclipse 600/16327, lr 6.114865554625452e-06,loss 0.3019, acc 0.9314
[2019-02-24 13:42:34,518]   >> |----epoch 0, eclipse 900/16327, lr 9.177402560280938e-06,loss 0.1908, acc 0.9371
[2019-02-24 13:43:47,408]   >> |----epoch 0, eclipse 1200/16327, lr 1.2239939565936422e-05,loss 0.1373, acc 0.9479
[2019-02-24 13:45:00,347]   >> |----epoch 0, eclipse 1500/16327, lr 1.5302476571591906e-05,loss 0.1224, acc 0.9486
[2019-02-24 13:46:13,306]   >> |----epoch 0, eclipse 1800/16327, lr 1.836501357724739e-05,loss 0.1142, acc 0.9518
[2019-02-24 13:47:26,293]   >> |----epoch 0, eclipse 2100/16327, lr 2.1427550582902875e-05,loss 0.1123, acc 0.9518
[2019-02-24 13:48:39,310]   >> |----epoch 0, eclipse 2400/16327, lr 2.4490087588558362e-05,loss 0.1106, acc 0.9525
[2019-02-24 13:49:52,341]   >> |----epoch 0, eclipse 2700/16327, lr 2.7552624594213843e-05,loss 0.1073, acc 0.9543
[2019-02-24 13:51:05,403]   >> |----epoch 0, eclipse 3000/16327, lr 3.0615161599869334e-05,loss 0.1138, acc 0.9531
[2019-02-24 13:52:18,468]   >> |----epoch 0, eclipse 3300/16327, lr 3.367769860552482e-05,loss 0.1151, acc 0.9514
[2019-02-24 13:53:31,530]   >> |----epoch 0, eclipse 3600/16327, lr 3.67402356111803e-05,loss 0.1129, acc 0.9522
[2019-02-24 13:54:44,609]   >> |----epoch 0, eclipse 3900/16327, lr 3.980277261683578e-05,loss 0.1053, acc 0.9528
[2019-02-24 13:55:57,697]   >> |----epoch 0, eclipse 4200/16327, lr 4.286530962249127e-05,loss 0.1081, acc 0.9547
[2019-02-24 13:57:10,867]   >> |----epoch 0, eclipse 4500/16327, lr 4.592784662814676e-05,loss 0.1064, acc 0.9526
[2019-02-24 13:58:24,066]   >> |----epoch 0, eclipse 4800/16327, lr 4.899038363380224e-05,loss 0.1100, acc 0.9543
[2019-02-24 13:59:37,264]   >> |----epoch 0, eclipse 5100/16327, lr 4.479470793605423e-05,loss 0.1032, acc 0.9558
[2019-02-24 14:00:50,470]   >> |----epoch 0, eclipse 5400/16327, lr 4.448845423548868e-05,loss 0.1086, acc 0.9532
[2019-02-24 14:02:03,690]   >> |----epoch 0, eclipse 5700/16327, lr 4.418220053492314e-05,loss 0.1000, acc 0.9568
[2019-02-24 14:03:16,909]   >> |----epoch 0, eclipse 6000/16327, lr 4.3875946834357584e-05,loss 0.1058, acc 0.9556
[2019-02-24 14:04:30,112]   >> |----epoch 0, eclipse 6300/16327, lr 4.356969313379203e-05,loss 0.1013, acc 0.9580
[2019-02-24 14:05:43,338]   >> |----epoch 0, eclipse 6600/16327, lr 4.326343943322649e-05,loss 0.1003, acc 0.9578
[2019-02-24 14:06:56,568]   >> |----epoch 0, eclipse 6900/16327, lr 4.2957185732660936e-05,loss 0.0984, acc 0.9591
[2019-02-24 14:08:09,800]   >> |----epoch 0, eclipse 7200/16327, lr 4.265093203209539e-05,loss 0.0959, acc 0.9598
[2019-02-24 14:09:23,009]   >> |----epoch 0, eclipse 7500/16327, lr 4.234467833152984e-05,loss 0.0991, acc 0.9581
[2019-02-24 14:10:36,235]   >> |----epoch 0, eclipse 7800/16327, lr 4.203842463096429e-05,loss 0.1031, acc 0.9564
[2019-02-24 14:11:49,463]   >> |----epoch 0, eclipse 8100/16327, lr 4.173217093039875e-05,loss 0.1011, acc 0.9570
[2019-02-24 14:13:02,691]   >> |----epoch 0, eclipse 8400/16327, lr 4.1425917229833194e-05,loss 0.1006, acc 0.9582
[2019-02-24 14:14:15,918]   >> |----epoch 0, eclipse 8700/16327, lr 4.111966352926765e-05,loss 0.0958, acc 0.9590
[2019-02-24 14:15:29,115]   >> |----epoch 0, eclipse 9000/16327, lr 4.08134098287021e-05,loss 0.1002, acc 0.9567
[2019-02-24 14:16:42,243]   >> |----epoch 0, eclipse 9300/16327, lr 4.0507156128136546e-05,loss 0.0952, acc 0.9590
[2019-02-24 14:17:55,380]   >> |----epoch 0, eclipse 9600/16327, lr 4.0200902427571e-05,loss 0.0988, acc 0.9563
[2019-02-24 14:19:08,525]   >> |----epoch 0, eclipse 9900/16327, lr 3.989464872700545e-05,loss 0.1005, acc 0.9585
[2019-02-24 14:20:21,674]   >> |----epoch 0, eclipse 10200/16327, lr 3.9588395026439905e-05,loss 0.0973, acc 0.9596
[2019-02-24 14:21:34,826]   >> |----epoch 0, eclipse 10500/16327, lr 3.928214132587436e-05,loss 0.1046, acc 0.9565
[2019-02-24 14:22:47,978]   >> |----epoch 0, eclipse 10800/16327, lr 3.8975887625308804e-05,loss 0.0963, acc 0.9583
[2019-02-24 14:24:01,133]   >> |----epoch 0, eclipse 11100/16327, lr 3.866963392474326e-05,loss 0.0995, acc 0.9587
[2019-02-24 14:25:14,303]   >> |----epoch 0, eclipse 11400/16327, lr 3.8363380224177716e-05,loss 0.1002, acc 0.9553
[2019-02-24 14:26:27,462]   >> |----epoch 0, eclipse 11700/16327, lr 3.805712652361216e-05,loss 0.0961, acc 0.9593
[2019-02-24 14:27:40,616]   >> |----epoch 0, eclipse 12000/16327, lr 3.7750872823046615e-05,loss 0.0991, acc 0.9591
[2019-02-24 14:28:53,775]   >> |----epoch 0, eclipse 12300/16327, lr 3.744461912248106e-05,loss 0.0986, acc 0.9582
[2019-02-24 14:30:06,941]   >> |----epoch 0, eclipse 12600/16327, lr 3.7138365421915515e-05,loss 0.0952, acc 0.9590
[2019-02-24 14:31:20,102]   >> |----epoch 0, eclipse 12900/16327, lr 3.6832111721349974e-05,loss 0.0953, acc 0.9603
[2019-02-24 14:32:33,260]   >> |----epoch 0, eclipse 13200/16327, lr 3.652585802078442e-05,loss 0.0931, acc 0.9607
[2019-02-24 14:33:46,410]   >> |----epoch 0, eclipse 13500/16327, lr 3.6219604320218867e-05,loss 0.0959, acc 0.9583
[2019-02-24 14:34:59,564]   >> |----epoch 0, eclipse 13800/16327, lr 3.591335061965332e-05,loss 0.0946, acc 0.9595
[2019-02-24 14:36:12,722]   >> |----epoch 0, eclipse 14100/16327, lr 3.560709691908777e-05,loss 0.0894, acc 0.9622
[2019-02-24 14:37:25,879]   >> |----epoch 0, eclipse 14400/16327, lr 3.5300843218522225e-05,loss 0.0954, acc 0.9588
[2019-02-24 14:38:39,026]   >> |----epoch 0, eclipse 14700/16327, lr 3.499458951795668e-05,loss 0.0962, acc 0.9572
[2019-02-24 14:39:52,148]   >> |----epoch 0, eclipse 15000/16327, lr 3.4688335817391124e-05,loss 0.0972, acc 0.9572
[2019-02-24 14:41:05,274]   >> |----epoch 0, eclipse 15300/16327, lr 3.4382082116825584e-05,loss 0.0952, acc 0.9587
[2019-02-24 14:42:18,413]   >> |----epoch 0, eclipse 15600/16327, lr 3.407582841626003e-05,loss 0.0920, acc 0.9607
[2019-02-24 14:43:31,560]   >> |----epoch 0, eclipse 15900/16327, lr 3.376957471569448e-05,loss 0.0919, acc 0.9617
[2019-02-24 14:44:44,702]   >> |----epoch 0, eclipse 16200/16327, lr 3.3463321015128936e-05,loss 0.0980, acc 0.9570
[2019-02-24 15:01:02,410]   >> device: cuda n_gpu: 1, distributed training: False, 16-bits training: False
[2019-02-24 15:01:02,426]   >> LOOKING AT /home/panxie/Document/kaggle/quora/data/splited_data/train.csv
[2019-02-24 15:02:39,619]   >> ***** Running evaluation *****
[2019-02-24 15:02:39,619]   >>   Num examples = 261225
[2019-02-24 15:02:39,620]   >>   Batch size = 8
[2019-02-24 15:05:06,825]   >> ***** Running training *****
[2019-02-24 15:05:06,825]   >>   Num examples = 1044897
[2019-02-24 15:05:06,825]   >>   Batch size = 64
[2019-02-24 15:05:06,825]   >>   Num steps = 48979
[2019-02-24 15:21:48,918]   >> device: cuda n_gpu: 1, distributed training: False, 16-bits training: False
[2019-02-24 15:21:48,934]   >> LOOKING AT /home/panxie/Document/kaggle/quora/data/splited_data/train.csv
[2019-02-24 15:23:26,661]   >> ***** Running evaluation *****
[2019-02-24 15:23:26,661]   >>   Num examples = 261225
[2019-02-24 15:23:26,673]   >>   Batch size = 8
[2019-02-24 15:25:47,947]   >> ***** Running training *****
[2019-02-24 15:25:47,947]   >>   Num examples = 1044897
[2019-02-24 15:25:47,947]   >>   Batch size = 64
[2019-02-24 15:25:47,947]   >>   Num steps = 48979
[2019-02-24 15:28:03,947]   >> device: cuda n_gpu: 1, distributed training: False, 16-bits training: False
[2019-02-24 15:28:03,964]   >> LOOKING AT /home/panxie/Document/kaggle/quora/data/splited_data/train.csv
[2019-02-24 15:28:10,760]   >> ***** Running evaluation *****
[2019-02-24 15:28:10,760]   >>   Num examples = 11
[2019-02-24 15:28:10,760]   >>   Batch size = 8
[2019-02-24 15:28:10,763]   >> ***** Running training *****
[2019-02-24 15:28:10,763]   >>   Num examples = 11
[2019-02-24 15:28:10,763]   >>   Batch size = 64
[2019-02-24 15:28:10,763]   >>   Num steps = 0
[2019-02-24 15:29:22,819]   >> device: cuda n_gpu: 1, distributed training: False, 16-bits training: False
[2019-02-24 15:29:22,836]   >> LOOKING AT /home/panxie/Document/kaggle/quora/data/splited_data/train.csv
[2019-02-24 15:29:29,632]   >> ***** Running evaluation *****
[2019-02-24 15:29:29,632]   >>   Num examples = 11
[2019-02-24 15:29:29,632]   >>   Batch size = 8
[2019-02-24 15:29:29,635]   >> ***** Running training *****
[2019-02-24 15:29:29,635]   >>   Num examples = 11
[2019-02-24 15:29:29,635]   >>   Batch size = 64
[2019-02-24 15:29:29,635]   >>   Num steps = 0
[2019-02-24 15:29:43,656]   >> device: cuda n_gpu: 1, distributed training: False, 16-bits training: False
[2019-02-24 15:29:43,673]   >> LOOKING AT /home/panxie/Document/kaggle/quora/data/splited_data/train.csv
[2019-02-24 15:29:50,485]   >> ***** Running evaluation *****
[2019-02-24 15:29:50,485]   >>   Num examples = 11
[2019-02-24 15:29:50,485]   >>   Batch size = 8
[2019-02-24 15:29:50,487]   >> ***** Running training *****
[2019-02-24 15:29:50,487]   >>   Num examples = 11
[2019-02-24 15:29:50,487]   >>   Batch size = 64
[2019-02-24 15:29:50,487]   >>   Num steps = 0
[2019-02-24 15:31:43,470]   >> device: cuda n_gpu: 1, distributed training: False, 16-bits training: False
[2019-02-24 15:31:43,487]   >> LOOKING AT /home/panxie/Document/kaggle/quora/data/splited_data/train.csv
[2019-02-24 15:31:50,258]   >> ***** Running evaluation *****
[2019-02-24 15:31:50,258]   >>   Num examples = 11
[2019-02-24 15:31:50,258]   >>   Batch size = 8
[2019-02-24 15:31:50,260]   >> ***** Running training *****
[2019-02-24 15:31:50,260]   >>   Num examples = 11
[2019-02-24 15:31:50,260]   >>   Batch size = 64
[2019-02-24 15:31:50,261]   >>   Num steps = 0
[2019-02-24 15:32:38,266]   >> device: cuda n_gpu: 1, distributed training: False, 16-bits training: False
[2019-02-24 15:32:38,282]   >> LOOKING AT /home/panxie/Document/kaggle/quora/data/splited_data/train.csv
[2019-02-24 15:32:45,089]   >> ***** Running evaluation *****
[2019-02-24 15:32:45,089]   >>   Num examples = 101
[2019-02-24 15:32:45,089]   >>   Batch size = 8
[2019-02-24 15:32:45,092]   >> ***** Running training *****
[2019-02-24 15:32:45,092]   >>   Num examples = 11
[2019-02-24 15:32:45,092]   >>   Batch size = 64
[2019-02-24 15:32:45,092]   >>   Num steps = 0
[2019-02-24 15:33:07,160]   >> device: cuda n_gpu: 1, distributed training: False, 16-bits training: False
[2019-02-24 15:33:07,177]   >> LOOKING AT /home/panxie/Document/kaggle/quora/data/splited_data/train.csv
[2019-02-24 15:33:14,017]   >> ***** Running evaluation *****
[2019-02-24 15:33:14,017]   >>   Num examples = 101
[2019-02-24 15:33:14,017]   >>   Batch size = 8
[2019-02-24 15:33:14,031]   >> ***** Running training *****
[2019-02-24 15:33:14,031]   >>   Num examples = 101
[2019-02-24 15:33:14,032]   >>   Batch size = 64
[2019-02-24 15:33:14,032]   >>   Num steps = 4
[2019-02-24 15:33:15,203]   >> epcoh 0, threshold 0.2000, accuracy 0.0495, precision 0.0495, recall 1.0000, f1 0.0943, best_f1 0.0943
[2019-02-24 15:33:15,205]   >> epcoh 0, threshold 0.2102, accuracy 0.0495, precision 0.0495, recall 1.0000, f1 0.0943, best_f1 0.0943
[2019-02-24 15:33:15,206]   >> epcoh 0, threshold 0.2203, accuracy 0.0495, precision 0.0495, recall 1.0000, f1 0.0943, best_f1 0.0943
[2019-02-24 15:33:15,208]   >> epcoh 0, threshold 0.2305, accuracy 0.0495, precision 0.0495, recall 1.0000, f1 0.0943, best_f1 0.0943
[2019-02-24 15:33:15,209]   >> epcoh 0, threshold 0.2407, accuracy 0.0495, precision 0.0495, recall 1.0000, f1 0.0943, best_f1 0.0943
[2019-02-24 15:33:15,211]   >> epcoh 0, threshold 0.2508, accuracy 0.0495, precision 0.0495, recall 1.0000, f1 0.0943, best_f1 0.0943
[2019-02-24 15:33:15,212]   >> epcoh 0, threshold 0.2610, accuracy 0.0495, precision 0.0495, recall 1.0000, f1 0.0943, best_f1 0.0943
[2019-02-24 15:33:15,213]   >> epcoh 0, threshold 0.2712, accuracy 0.0495, precision 0.0495, recall 1.0000, f1 0.0943, best_f1 0.0943
[2019-02-24 15:33:15,214]   >> epcoh 0, threshold 0.2814, accuracy 0.0495, precision 0.0495, recall 1.0000, f1 0.0943, best_f1 0.0943
[2019-02-24 15:33:15,215]   >> epcoh 0, threshold 0.2915, accuracy 0.0495, precision 0.0495, recall 1.0000, f1 0.0943, best_f1 0.0943
[2019-02-24 15:33:15,217]   >> epcoh 0, threshold 0.3017, accuracy 0.0495, precision 0.0495, recall 1.0000, f1 0.0943, best_f1 0.0943
[2019-02-24 15:33:15,218]   >> epcoh 0, threshold 0.3119, accuracy 0.0495, precision 0.0495, recall 1.0000, f1 0.0943, best_f1 0.0943
[2019-02-24 15:33:15,520]   >> epcoh 0, threshold 0.3220, accuracy 0.0594, precision 0.0500, recall 1.0000, f1 0.0952, best_f1 0.0952
[2019-02-24 15:33:15,521]   >> epcoh 0, threshold 0.3322, accuracy 0.0594, precision 0.0500, recall 1.0000, f1 0.0952, best_f1 0.0952
[2019-02-24 15:33:15,522]   >> epcoh 0, threshold 0.3424, accuracy 0.0594, precision 0.0500, recall 1.0000, f1 0.0952, best_f1 0.0952
[2019-02-24 15:33:15,523]   >> epcoh 0, threshold 0.3525, accuracy 0.0594, precision 0.0500, recall 1.0000, f1 0.0952, best_f1 0.0952
[2019-02-24 15:33:15,524]   >> epcoh 0, threshold 0.3627, accuracy 0.0594, precision 0.0500, recall 1.0000, f1 0.0952, best_f1 0.0952
[2019-02-24 15:33:15,525]   >> epcoh 0, threshold 0.3729, accuracy 0.0594, precision 0.0500, recall 1.0000, f1 0.0952, best_f1 0.0952
[2019-02-24 15:33:15,526]   >> epcoh 0, threshold 0.3831, accuracy 0.0594, precision 0.0500, recall 1.0000, f1 0.0952, best_f1 0.0952
[2019-02-24 15:33:15,527]   >> epcoh 0, threshold 0.3932, accuracy 0.0594, precision 0.0500, recall 1.0000, f1 0.0952, best_f1 0.0952
[2019-02-24 15:33:15,528]   >> epcoh 0, threshold 0.4034, accuracy 0.0495, precision 0.0404, recall 0.8000, f1 0.0769, best_f1 0.0952
[2019-02-24 15:33:15,529]   >> epcoh 0, threshold 0.4136, accuracy 0.0495, precision 0.0404, recall 0.8000, f1 0.0769, best_f1 0.0952
[2019-02-24 15:33:15,530]   >> epcoh 0, threshold 0.4237, accuracy 0.0594, precision 0.0408, recall 0.8000, f1 0.0777, best_f1 0.0952
[2019-02-24 15:33:15,531]   >> epcoh 0, threshold 0.4339, accuracy 0.0594, precision 0.0408, recall 0.8000, f1 0.0777, best_f1 0.0952
[2019-02-24 15:33:15,532]   >> epcoh 0, threshold 0.4441, accuracy 0.0693, precision 0.0412, recall 0.8000, f1 0.0784, best_f1 0.0952
[2019-02-24 15:33:15,533]   >> epcoh 0, threshold 0.4542, accuracy 0.0990, precision 0.0426, recall 0.8000, f1 0.0808, best_f1 0.0952
[2019-02-24 15:33:15,534]   >> epcoh 0, threshold 0.4644, accuracy 0.2079, precision 0.0482, recall 0.8000, f1 0.0909, best_f1 0.0952
[2019-02-24 15:33:16,042]   >> epcoh 0, threshold 0.4746, accuracy 0.5842, precision 0.0698, recall 0.6000, f1 0.1250, best_f1 0.1250
[2019-02-24 15:33:16,567]   >> epcoh 0, threshold 0.4847, accuracy 0.8119, precision 0.1111, recall 0.4000, f1 0.1739, best_f1 0.1739
[2019-02-24 15:33:16,568]   >> epcoh 0, threshold 0.4949, accuracy 0.8812, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1739
[2019-02-24 15:33:16,569]   >> epcoh 0, threshold 0.5051, accuracy 0.9307, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1739
[2019-02-24 15:33:16,570]   >> epcoh 0, threshold 0.5153, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1739
[2019-02-24 15:33:16,571]   >> epcoh 0, threshold 0.5254, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1739
[2019-02-24 15:33:16,572]   >> epcoh 0, threshold 0.5356, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1739
[2019-02-24 15:33:16,573]   >> epcoh 0, threshold 0.5458, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1739
[2019-02-24 15:33:16,574]   >> epcoh 0, threshold 0.5559, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1739
[2019-02-24 15:33:16,575]   >> epcoh 0, threshold 0.5661, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1739
[2019-02-24 15:33:16,576]   >> epcoh 0, threshold 0.5763, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1739
[2019-02-24 15:33:16,577]   >> epcoh 0, threshold 0.5864, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1739
[2019-02-24 15:33:16,578]   >> epcoh 0, threshold 0.5966, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1739
[2019-02-24 15:33:16,579]   >> epcoh 0, threshold 0.6068, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1739
[2019-02-24 15:33:16,580]   >> epcoh 0, threshold 0.6169, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1739
[2019-02-24 15:33:16,581]   >> epcoh 0, threshold 0.6271, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1739
[2019-02-24 15:33:16,582]   >> epcoh 0, threshold 0.6373, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1739
[2019-02-24 15:33:16,583]   >> epcoh 0, threshold 0.6475, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1739
[2019-02-24 15:33:16,584]   >> epcoh 0, threshold 0.6576, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1739
[2019-02-24 15:33:16,585]   >> epcoh 0, threshold 0.6678, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1739
[2019-02-24 15:33:16,586]   >> epcoh 0, threshold 0.6780, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1739
[2019-02-24 15:33:16,587]   >> epcoh 0, threshold 0.6881, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1739
[2019-02-24 15:33:16,588]   >> epcoh 0, threshold 0.6983, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1739
[2019-02-24 15:33:16,589]   >> epcoh 0, threshold 0.7085, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1739
[2019-02-24 15:33:16,590]   >> epcoh 0, threshold 0.7186, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1739
[2019-02-24 15:33:16,590]   >> epcoh 0, threshold 0.7288, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1739
[2019-02-24 15:33:16,591]   >> epcoh 0, threshold 0.7390, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1739
[2019-02-24 15:33:16,592]   >> epcoh 0, threshold 0.7492, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1739
[2019-02-24 15:33:16,593]   >> epcoh 0, threshold 0.7593, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1739
[2019-02-24 15:33:16,594]   >> epcoh 0, threshold 0.7695, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1739
[2019-02-24 15:33:16,595]   >> epcoh 0, threshold 0.7797, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1739
[2019-02-24 15:33:16,596]   >> epcoh 0, threshold 0.7898, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1739
[2019-02-24 15:33:16,597]   >> epcoh 0, threshold 0.8000, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1739
[2019-02-24 15:33:16,612]   >> ***** Running training *****
[2019-02-24 15:33:16,612]   >>   Num examples = 101
[2019-02-24 15:33:16,612]   >>   Batch size = 64
[2019-02-24 15:33:16,612]   >>   Num steps = 4
[2019-02-24 15:33:17,517]   >> epcoh 1, threshold 0.2000, accuracy 0.0495, precision 0.0495, recall 1.0000, f1 0.0943, best_f1 0.0943
[2019-02-24 15:33:17,519]   >> epcoh 1, threshold 0.2102, accuracy 0.0495, precision 0.0495, recall 1.0000, f1 0.0943, best_f1 0.0943
[2019-02-24 15:33:17,521]   >> epcoh 1, threshold 0.2203, accuracy 0.0495, precision 0.0495, recall 1.0000, f1 0.0943, best_f1 0.0943
[2019-02-24 15:33:17,522]   >> epcoh 1, threshold 0.2305, accuracy 0.0495, precision 0.0495, recall 1.0000, f1 0.0943, best_f1 0.0943
[2019-02-24 15:33:17,524]   >> epcoh 1, threshold 0.2407, accuracy 0.0495, precision 0.0495, recall 1.0000, f1 0.0943, best_f1 0.0943
[2019-02-24 15:33:17,525]   >> epcoh 1, threshold 0.2508, accuracy 0.0495, precision 0.0495, recall 1.0000, f1 0.0943, best_f1 0.0943
[2019-02-24 15:33:17,526]   >> epcoh 1, threshold 0.2610, accuracy 0.0495, precision 0.0495, recall 1.0000, f1 0.0943, best_f1 0.0943
[2019-02-24 15:33:17,527]   >> epcoh 1, threshold 0.2712, accuracy 0.0495, precision 0.0495, recall 1.0000, f1 0.0943, best_f1 0.0943
[2019-02-24 15:33:17,991]   >> epcoh 1, threshold 0.2814, accuracy 0.0594, precision 0.0500, recall 1.0000, f1 0.0952, best_f1 0.0952
[2019-02-24 15:33:17,993]   >> epcoh 1, threshold 0.2915, accuracy 0.0495, precision 0.0404, recall 0.8000, f1 0.0769, best_f1 0.0952
[2019-02-24 15:33:17,993]   >> epcoh 1, threshold 0.3017, accuracy 0.0594, precision 0.0408, recall 0.8000, f1 0.0777, best_f1 0.0952
[2019-02-24 15:33:17,994]   >> epcoh 1, threshold 0.3119, accuracy 0.0693, precision 0.0412, recall 0.8000, f1 0.0784, best_f1 0.0952
[2019-02-24 15:33:17,995]   >> epcoh 1, threshold 0.3220, accuracy 0.0891, precision 0.0421, recall 0.8000, f1 0.0800, best_f1 0.0952
[2019-02-24 15:33:17,996]   >> epcoh 1, threshold 0.3322, accuracy 0.0990, precision 0.0426, recall 0.8000, f1 0.0808, best_f1 0.0952
[2019-02-24 15:33:17,997]   >> epcoh 1, threshold 0.3424, accuracy 0.1287, precision 0.0440, recall 0.8000, f1 0.0833, best_f1 0.0952
[2019-02-24 15:33:17,998]   >> epcoh 1, threshold 0.3525, accuracy 0.1782, precision 0.0465, recall 0.8000, f1 0.0879, best_f1 0.0952
[2019-02-24 15:33:17,999]   >> epcoh 1, threshold 0.3627, accuracy 0.2475, precision 0.0506, recall 0.8000, f1 0.0952, best_f1 0.0952
[2019-02-24 15:33:18,518]   >> epcoh 1, threshold 0.3729, accuracy 0.3168, precision 0.0556, recall 0.8000, f1 0.1039, best_f1 0.1039
[2019-02-24 15:33:18,519]   >> epcoh 1, threshold 0.3831, accuracy 0.3861, precision 0.0476, recall 0.6000, f1 0.0882, best_f1 0.1039
[2019-02-24 15:33:18,520]   >> epcoh 1, threshold 0.3932, accuracy 0.5941, precision 0.0500, recall 0.4000, f1 0.0889, best_f1 0.1039
[2019-02-24 15:33:18,521]   >> epcoh 1, threshold 0.4034, accuracy 0.7129, precision 0.0385, recall 0.2000, f1 0.0645, best_f1 0.1039
[2019-02-24 15:33:19,042]   >> epcoh 1, threshold 0.4136, accuracy 0.8416, precision 0.0769, recall 0.2000, f1 0.1111, best_f1 0.1111
[2019-02-24 15:33:19,043]   >> epcoh 1, threshold 0.4237, accuracy 0.8812, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1111
[2019-02-24 15:33:19,044]   >> epcoh 1, threshold 0.4339, accuracy 0.9406, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1111
[2019-02-24 15:33:19,045]   >> epcoh 1, threshold 0.4441, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1111
[2019-02-24 15:33:19,046]   >> epcoh 1, threshold 0.4542, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1111
[2019-02-24 15:33:19,047]   >> epcoh 1, threshold 0.4644, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1111
[2019-02-24 15:33:19,048]   >> epcoh 1, threshold 0.4746, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1111
[2019-02-24 15:33:19,049]   >> epcoh 1, threshold 0.4847, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1111
[2019-02-24 15:33:19,050]   >> epcoh 1, threshold 0.4949, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1111
[2019-02-24 15:33:19,051]   >> epcoh 1, threshold 0.5051, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1111
[2019-02-24 15:33:19,052]   >> epcoh 1, threshold 0.5153, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1111
[2019-02-24 15:33:19,053]   >> epcoh 1, threshold 0.5254, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1111
[2019-02-24 15:33:19,054]   >> epcoh 1, threshold 0.5356, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1111
[2019-02-24 15:33:19,055]   >> epcoh 1, threshold 0.5458, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1111
[2019-02-24 15:33:19,056]   >> epcoh 1, threshold 0.5559, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1111
[2019-02-24 15:33:19,057]   >> epcoh 1, threshold 0.5661, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1111
[2019-02-24 15:33:19,058]   >> epcoh 1, threshold 0.5763, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1111
[2019-02-24 15:33:19,059]   >> epcoh 1, threshold 0.5864, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1111
[2019-02-24 15:33:19,060]   >> epcoh 1, threshold 0.5966, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1111
[2019-02-24 15:33:19,061]   >> epcoh 1, threshold 0.6068, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1111
[2019-02-24 15:33:19,062]   >> epcoh 1, threshold 0.6169, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1111
[2019-02-24 15:33:19,063]   >> epcoh 1, threshold 0.6271, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1111
[2019-02-24 15:33:19,064]   >> epcoh 1, threshold 0.6373, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1111
[2019-02-24 15:33:19,065]   >> epcoh 1, threshold 0.6475, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1111
[2019-02-24 15:33:19,066]   >> epcoh 1, threshold 0.6576, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1111
[2019-02-24 15:33:19,067]   >> epcoh 1, threshold 0.6678, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1111
[2019-02-24 15:33:19,068]   >> epcoh 1, threshold 0.6780, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1111
[2019-02-24 15:33:19,069]   >> epcoh 1, threshold 0.6881, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1111
[2019-02-24 15:33:19,070]   >> epcoh 1, threshold 0.6983, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1111
[2019-02-24 15:33:19,071]   >> epcoh 1, threshold 0.7085, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1111
[2019-02-24 15:33:19,072]   >> epcoh 1, threshold 0.7186, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1111
[2019-02-24 15:33:19,073]   >> epcoh 1, threshold 0.7288, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1111
[2019-02-24 15:33:19,073]   >> epcoh 1, threshold 0.7390, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1111
[2019-02-24 15:33:19,074]   >> epcoh 1, threshold 0.7492, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1111
[2019-02-24 15:33:19,075]   >> epcoh 1, threshold 0.7593, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1111
[2019-02-24 15:33:19,076]   >> epcoh 1, threshold 0.7695, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1111
[2019-02-24 15:33:19,077]   >> epcoh 1, threshold 0.7797, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1111
[2019-02-24 15:33:19,078]   >> epcoh 1, threshold 0.7898, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1111
[2019-02-24 15:33:19,079]   >> epcoh 1, threshold 0.8000, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1111
[2019-02-24 15:33:19,094]   >> ***** Running training *****
[2019-02-24 15:33:19,094]   >>   Num examples = 101
[2019-02-24 15:33:19,094]   >>   Batch size = 64
[2019-02-24 15:33:19,094]   >>   Num steps = 4
[2019-02-24 15:33:19,968]   >> epcoh 2, threshold 0.2000, accuracy 0.0495, precision 0.0495, recall 1.0000, f1 0.0943, best_f1 0.0943
[2019-02-24 15:33:19,969]   >> epcoh 2, threshold 0.2102, accuracy 0.0495, precision 0.0495, recall 1.0000, f1 0.0943, best_f1 0.0943
[2019-02-24 15:33:19,970]   >> epcoh 2, threshold 0.2203, accuracy 0.0495, precision 0.0495, recall 1.0000, f1 0.0943, best_f1 0.0943
[2019-02-24 15:33:19,971]   >> epcoh 2, threshold 0.2305, accuracy 0.0495, precision 0.0495, recall 1.0000, f1 0.0943, best_f1 0.0943
[2019-02-24 15:33:19,972]   >> epcoh 2, threshold 0.2407, accuracy 0.0495, precision 0.0495, recall 1.0000, f1 0.0943, best_f1 0.0943
[2019-02-24 15:33:19,972]   >> epcoh 2, threshold 0.2508, accuracy 0.0495, precision 0.0495, recall 1.0000, f1 0.0943, best_f1 0.0943
[2019-02-24 15:33:19,973]   >> epcoh 2, threshold 0.2610, accuracy 0.0495, precision 0.0495, recall 1.0000, f1 0.0943, best_f1 0.0943
[2019-02-24 15:33:19,974]   >> epcoh 2, threshold 0.2712, accuracy 0.0495, precision 0.0495, recall 1.0000, f1 0.0943, best_f1 0.0943
[2019-02-24 15:33:19,975]   >> epcoh 2, threshold 0.2814, accuracy 0.0495, precision 0.0495, recall 1.0000, f1 0.0943, best_f1 0.0943
[2019-02-24 15:33:19,976]   >> epcoh 2, threshold 0.2915, accuracy 0.0495, precision 0.0495, recall 1.0000, f1 0.0943, best_f1 0.0943
[2019-02-24 15:33:19,977]   >> epcoh 2, threshold 0.3017, accuracy 0.0495, precision 0.0495, recall 1.0000, f1 0.0943, best_f1 0.0943
[2019-02-24 15:33:19,978]   >> epcoh 2, threshold 0.3119, accuracy 0.0495, precision 0.0495, recall 1.0000, f1 0.0943, best_f1 0.0943
[2019-02-24 15:33:19,979]   >> epcoh 2, threshold 0.3220, accuracy 0.0495, precision 0.0495, recall 1.0000, f1 0.0943, best_f1 0.0943
[2019-02-24 15:33:19,980]   >> epcoh 2, threshold 0.3322, accuracy 0.0495, precision 0.0495, recall 1.0000, f1 0.0943, best_f1 0.0943
[2019-02-24 15:33:19,981]   >> epcoh 2, threshold 0.3424, accuracy 0.0495, precision 0.0495, recall 1.0000, f1 0.0943, best_f1 0.0943
[2019-02-24 15:33:19,982]   >> epcoh 2, threshold 0.3525, accuracy 0.0495, precision 0.0495, recall 1.0000, f1 0.0943, best_f1 0.0943
[2019-02-24 15:33:19,982]   >> epcoh 2, threshold 0.3627, accuracy 0.0495, precision 0.0495, recall 1.0000, f1 0.0943, best_f1 0.0943
[2019-02-24 15:33:20,488]   >> epcoh 2, threshold 0.3729, accuracy 0.0594, precision 0.0500, recall 1.0000, f1 0.0952, best_f1 0.0952
[2019-02-24 15:33:20,489]   >> epcoh 2, threshold 0.3831, accuracy 0.0594, precision 0.0500, recall 1.0000, f1 0.0952, best_f1 0.0952
[2019-02-24 15:33:20,490]   >> epcoh 2, threshold 0.3932, accuracy 0.0594, precision 0.0500, recall 1.0000, f1 0.0952, best_f1 0.0952
[2019-02-24 15:33:20,491]   >> epcoh 2, threshold 0.4034, accuracy 0.0594, precision 0.0500, recall 1.0000, f1 0.0952, best_f1 0.0952
[2019-02-24 15:33:20,492]   >> epcoh 2, threshold 0.4136, accuracy 0.0594, precision 0.0500, recall 1.0000, f1 0.0952, best_f1 0.0952
[2019-02-24 15:33:20,493]   >> epcoh 2, threshold 0.4237, accuracy 0.0594, precision 0.0500, recall 1.0000, f1 0.0952, best_f1 0.0952
[2019-02-24 15:33:20,494]   >> epcoh 2, threshold 0.4339, accuracy 0.0594, precision 0.0500, recall 1.0000, f1 0.0952, best_f1 0.0952
[2019-02-24 15:33:20,495]   >> epcoh 2, threshold 0.4441, accuracy 0.0495, precision 0.0404, recall 0.8000, f1 0.0769, best_f1 0.0952
[2019-02-24 15:33:20,496]   >> epcoh 2, threshold 0.4542, accuracy 0.0495, precision 0.0404, recall 0.8000, f1 0.0769, best_f1 0.0952
[2019-02-24 15:33:20,497]   >> epcoh 2, threshold 0.4644, accuracy 0.0495, precision 0.0404, recall 0.8000, f1 0.0769, best_f1 0.0952
[2019-02-24 15:33:20,498]   >> epcoh 2, threshold 0.4746, accuracy 0.0891, precision 0.0421, recall 0.8000, f1 0.0800, best_f1 0.0952
[2019-02-24 15:33:20,498]   >> epcoh 2, threshold 0.4847, accuracy 0.2079, precision 0.0482, recall 0.8000, f1 0.0909, best_f1 0.0952
[2019-02-24 15:33:22,174]   >> epcoh 2, threshold 0.4949, accuracy 0.4752, precision 0.0714, recall 0.8000, f1 0.1311, best_f1 0.1311
[2019-02-24 15:33:23,624]   >> epcoh 2, threshold 0.5051, accuracy 0.7624, precision 0.1200, recall 0.6000, f1 0.2000, best_f1 0.2000
[2019-02-24 15:33:23,626]   >> epcoh 2, threshold 0.5153, accuracy 0.8515, precision 0.0833, recall 0.2000, f1 0.1176, best_f1 0.2000
[2019-02-24 15:33:23,626]   >> epcoh 2, threshold 0.5254, accuracy 0.9406, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2000
[2019-02-24 15:33:23,627]   >> epcoh 2, threshold 0.5356, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2000
[2019-02-24 15:33:23,628]   >> epcoh 2, threshold 0.5458, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2000
[2019-02-24 15:33:23,629]   >> epcoh 2, threshold 0.5559, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2000
[2019-02-24 15:33:23,630]   >> epcoh 2, threshold 0.5661, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2000
[2019-02-24 15:33:23,631]   >> epcoh 2, threshold 0.5763, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2000
[2019-02-24 15:33:23,632]   >> epcoh 2, threshold 0.5864, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2000
[2019-02-24 15:33:23,633]   >> epcoh 2, threshold 0.5966, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2000
[2019-02-24 15:33:23,634]   >> epcoh 2, threshold 0.6068, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2000
[2019-02-24 15:33:23,634]   >> epcoh 2, threshold 0.6169, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2000
[2019-02-24 15:33:23,635]   >> epcoh 2, threshold 0.6271, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2000
[2019-02-24 15:33:23,636]   >> epcoh 2, threshold 0.6373, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2000
[2019-02-24 15:33:23,637]   >> epcoh 2, threshold 0.6475, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2000
[2019-02-24 15:33:23,638]   >> epcoh 2, threshold 0.6576, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2000
[2019-02-24 15:33:23,639]   >> epcoh 2, threshold 0.6678, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2000
[2019-02-24 15:33:23,640]   >> epcoh 2, threshold 0.6780, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2000
[2019-02-24 15:33:23,641]   >> epcoh 2, threshold 0.6881, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2000
[2019-02-24 15:33:23,641]   >> epcoh 2, threshold 0.6983, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2000
[2019-02-24 15:33:23,642]   >> epcoh 2, threshold 0.7085, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2000
[2019-02-24 15:33:23,643]   >> epcoh 2, threshold 0.7186, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2000
[2019-02-24 15:33:23,644]   >> epcoh 2, threshold 0.7288, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2000
[2019-02-24 15:33:23,645]   >> epcoh 2, threshold 0.7390, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2000
[2019-02-24 15:33:23,646]   >> epcoh 2, threshold 0.7492, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2000
[2019-02-24 15:33:23,647]   >> epcoh 2, threshold 0.7593, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2000
[2019-02-24 15:33:23,648]   >> epcoh 2, threshold 0.7695, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2000
[2019-02-24 15:33:23,648]   >> epcoh 2, threshold 0.7797, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2000
[2019-02-24 15:33:23,649]   >> epcoh 2, threshold 0.7898, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2000
[2019-02-24 15:33:23,650]   >> epcoh 2, threshold 0.8000, accuracy 0.9505, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2000
[2019-02-24 15:35:06,218]   >> device: cuda n_gpu: 1, distributed training: False, 16-bits training: False
[2019-02-24 15:35:06,234]   >> LOOKING AT /home/panxie/Document/kaggle/quora/data/splited_data/train.csv
[2019-02-24 15:36:45,319]   >> ***** Running evaluation *****
[2019-02-24 15:36:45,319]   >>   Num examples = 261225
[2019-02-24 15:36:45,320]   >>   Batch size = 8
[2019-02-24 15:39:09,414]   >> ***** Running training *****
[2019-02-24 15:39:09,414]   >>   Num examples = 1044897
[2019-02-24 15:39:09,426]   >>   Batch size = 64
[2019-02-24 15:39:09,427]   >>   Num steps = 48979
[2019-02-24 15:40:23,213]   >> |----epoch 0, eclipse 300/16327, lr 0.0000,loss 0.4544, acc 0.6164
[2019-02-24 15:41:35,957]   >> |----epoch 0, eclipse 600/16327, lr 0.0000,loss 0.3019, acc 0.9314
[2019-02-24 15:42:48,825]   >> |----epoch 0, eclipse 900/16327, lr 0.0000,loss 0.1908, acc 0.9371
[2019-02-24 15:44:01,751]   >> |----epoch 0, eclipse 1200/16327, lr 0.0000,loss 0.1373, acc 0.9479
[2019-02-24 15:45:14,772]   >> |----epoch 0, eclipse 1500/16327, lr 0.0000,loss 0.1224, acc 0.9486
[2019-02-24 15:46:27,707]   >> |----epoch 0, eclipse 1800/16327, lr 0.0000,loss 0.1142, acc 0.9518
[2019-02-24 15:47:40,675]   >> |----epoch 0, eclipse 2100/16327, lr 0.0000,loss 0.1123, acc 0.9518
[2019-02-24 15:48:53,672]   >> |----epoch 0, eclipse 2400/16327, lr 0.0000,loss 0.1106, acc 0.9525
[2019-02-24 15:50:06,667]   >> |----epoch 0, eclipse 2700/16327, lr 0.0000,loss 0.1073, acc 0.9543
[2019-02-24 15:51:19,669]   >> |----epoch 0, eclipse 3000/16327, lr 0.0000,loss 0.1138, acc 0.9531
[2019-02-24 15:52:32,688]   >> |----epoch 0, eclipse 3300/16327, lr 0.0000,loss 0.1151, acc 0.9514
[2019-02-24 15:53:45,704]   >> |----epoch 0, eclipse 3600/16327, lr 0.0000,loss 0.1129, acc 0.9522
[2019-02-24 15:54:58,729]   >> |----epoch 0, eclipse 3900/16327, lr 0.0000,loss 0.1053, acc 0.9528
[2019-02-24 15:56:11,772]   >> |----epoch 0, eclipse 4200/16327, lr 0.0000,loss 0.1081, acc 0.9547
[2019-02-24 15:57:24,824]   >> |----epoch 0, eclipse 4500/16327, lr 0.0000,loss 0.1064, acc 0.9526
[2019-02-24 15:58:37,980]   >> |----epoch 0, eclipse 4800/16327, lr 0.0000,loss 0.1100, acc 0.9543
[2019-02-24 15:59:51,151]   >> |----epoch 0, eclipse 5100/16327, lr 0.0000,loss 0.1032, acc 0.9558
[2019-02-24 16:01:04,352]   >> |----epoch 0, eclipse 5400/16327, lr 0.0000,loss 0.1086, acc 0.9532
[2019-02-24 16:02:17,593]   >> |----epoch 0, eclipse 5700/16327, lr 0.0000,loss 0.1000, acc 0.9568
[2019-02-24 16:03:30,808]   >> |----epoch 0, eclipse 6000/16327, lr 0.0000,loss 0.1058, acc 0.9556
[2019-02-24 16:04:44,009]   >> |----epoch 0, eclipse 6300/16327, lr 0.0000,loss 0.1013, acc 0.9580
[2019-02-24 16:05:57,207]   >> |----epoch 0, eclipse 6600/16327, lr 0.0000,loss 0.1003, acc 0.9578
[2019-02-24 16:07:10,394]   >> |----epoch 0, eclipse 6900/16327, lr 0.0000,loss 0.0984, acc 0.9591
[2019-02-24 16:08:23,585]   >> |----epoch 0, eclipse 7200/16327, lr 0.0000,loss 0.0959, acc 0.9598
[2019-02-24 16:09:36,780]   >> |----epoch 0, eclipse 7500/16327, lr 0.0000,loss 0.0991, acc 0.9581
[2019-02-24 16:10:50,005]   >> |----epoch 0, eclipse 7800/16327, lr 0.0000,loss 0.1031, acc 0.9564
[2019-02-24 16:12:03,208]   >> |----epoch 0, eclipse 8100/16327, lr 0.0000,loss 0.1011, acc 0.9570
[2019-02-24 16:13:16,395]   >> |----epoch 0, eclipse 8400/16327, lr 0.0000,loss 0.1006, acc 0.9582
[2019-02-24 16:14:29,604]   >> |----epoch 0, eclipse 8700/16327, lr 0.0000,loss 0.0958, acc 0.9590
[2019-02-24 16:15:42,818]   >> |----epoch 0, eclipse 9000/16327, lr 0.0000,loss 0.1002, acc 0.9567
[2019-02-24 16:16:56,049]   >> |----epoch 0, eclipse 9300/16327, lr 0.0000,loss 0.0952, acc 0.9590
[2019-02-24 16:18:09,287]   >> |----epoch 0, eclipse 9600/16327, lr 0.0000,loss 0.0988, acc 0.9563
[2019-02-24 16:19:22,577]   >> |----epoch 0, eclipse 9900/16327, lr 0.0000,loss 0.1005, acc 0.9585
[2019-02-24 16:20:35,922]   >> |----epoch 0, eclipse 10200/16327, lr 0.0000,loss 0.0973, acc 0.9596
[2019-02-24 16:21:49,258]   >> |----epoch 0, eclipse 10500/16327, lr 0.0000,loss 0.1046, acc 0.9565
[2019-02-24 16:23:02,605]   >> |----epoch 0, eclipse 10800/16327, lr 0.0000,loss 0.0963, acc 0.9583
[2019-02-24 16:24:15,946]   >> |----epoch 0, eclipse 11100/16327, lr 0.0000,loss 0.0995, acc 0.9587
[2019-02-24 16:25:29,295]   >> |----epoch 0, eclipse 11400/16327, lr 0.0000,loss 0.1002, acc 0.9553
[2019-02-24 16:26:42,638]   >> |----epoch 0, eclipse 11700/16327, lr 0.0000,loss 0.0961, acc 0.9593
[2019-02-24 16:27:55,975]   >> |----epoch 0, eclipse 12000/16327, lr 0.0000,loss 0.0991, acc 0.9591
[2019-02-24 16:29:09,311]   >> |----epoch 0, eclipse 12300/16327, lr 0.0000,loss 0.0986, acc 0.9582
[2019-02-24 16:30:22,638]   >> |----epoch 0, eclipse 12600/16327, lr 0.0000,loss 0.0952, acc 0.9590
[2019-02-24 16:31:35,970]   >> |----epoch 0, eclipse 12900/16327, lr 0.0000,loss 0.0953, acc 0.9603
[2019-02-24 16:32:49,303]   >> |----epoch 0, eclipse 13200/16327, lr 0.0000,loss 0.0931, acc 0.9607
[2019-02-24 16:34:02,655]   >> |----epoch 0, eclipse 13500/16327, lr 0.0000,loss 0.0959, acc 0.9583
[2019-02-24 16:35:16,020]   >> |----epoch 0, eclipse 13800/16327, lr 0.0000,loss 0.0946, acc 0.9595
[2019-02-24 16:36:29,374]   >> |----epoch 0, eclipse 14100/16327, lr 0.0000,loss 0.0894, acc 0.9622
[2019-02-24 16:37:42,710]   >> |----epoch 0, eclipse 14400/16327, lr 0.0000,loss 0.0954, acc 0.9588
[2019-02-24 16:38:56,052]   >> |----epoch 0, eclipse 14700/16327, lr 0.0000,loss 0.0962, acc 0.9572
[2019-02-24 16:40:09,388]   >> |----epoch 0, eclipse 15000/16327, lr 0.0000,loss 0.0972, acc 0.9572
[2019-02-24 16:41:22,710]   >> |----epoch 0, eclipse 15300/16327, lr 0.0000,loss 0.0952, acc 0.9587
[2019-02-24 16:42:36,037]   >> |----epoch 0, eclipse 15600/16327, lr 0.0000,loss 0.0920, acc 0.9607
[2019-02-24 16:43:49,394]   >> |----epoch 0, eclipse 15900/16327, lr 0.0000,loss 0.0919, acc 0.9617
[2019-02-24 16:45:02,736]   >> |----epoch 0, eclipse 16200/16327, lr 0.0000,loss 0.0980, acc 0.9570
[2019-02-24 17:05:02,025]   >> device: cuda n_gpu: 1, distributed training: False, 16-bits training: False
[2019-02-24 17:05:02,041]   >> LOOKING AT /home/panxie/Document/kaggle/quora/data/splited_data/train.csv
[2019-02-24 17:05:09,052]   >> ***** Running evaluation *****
[2019-02-24 17:05:09,052]   >>   Num examples = 1001
[2019-02-24 17:05:09,053]   >>   Batch size = 8
[2019-02-24 17:05:09,185]   >> ***** Running training *****
[2019-02-24 17:05:09,185]   >>   Num examples = 1001
[2019-02-24 17:05:09,185]   >>   Batch size = 64
[2019-02-24 17:05:09,185]   >>   Num steps = 46
[2019-02-24 17:38:14,693]   >> device: cuda n_gpu: 1, distributed training: False, 16-bits training: False
[2019-02-24 17:38:14,710]   >> LOOKING AT /home/panxie/Document/kaggle/quora/data/splited_data/train.csv
[2019-02-24 17:38:21,774]   >> ***** Running evaluation *****
[2019-02-24 17:38:21,774]   >>   Num examples = 1001
[2019-02-24 17:38:21,775]   >>   Batch size = 8
[2019-02-24 17:38:21,908]   >> ***** Running training *****
[2019-02-24 17:38:21,908]   >>   Num examples = 1001
[2019-02-24 17:38:21,920]   >>   Batch size = 64
[2019-02-24 17:38:21,920]   >>   Num steps = 46
[2019-02-24 17:38:49,731]   >> device: cuda n_gpu: 1, distributed training: False, 16-bits training: False
[2019-02-24 17:38:49,747]   >> LOOKING AT /home/panxie/Document/kaggle/quora/data/splited_data/train.csv
[2019-02-24 17:38:56,775]   >> ***** Running evaluation *****
[2019-02-24 17:38:56,775]   >>   Num examples = 1001
[2019-02-24 17:38:56,776]   >>   Batch size = 8
[2019-02-24 17:38:56,909]   >> ***** Running training *****
[2019-02-24 17:38:56,909]   >>   Num examples = 1001
[2019-02-24 17:38:56,909]   >>   Batch size = 64
[2019-02-24 17:38:56,909]   >>   Num steps = 46
[2019-02-24 17:39:28,458]   >> device: cuda n_gpu: 1, distributed training: False, 16-bits training: False
[2019-02-24 17:39:28,475]   >> LOOKING AT /home/panxie/Document/kaggle/quora/data/splited_data/train.csv
[2019-02-24 17:39:35,474]   >> ***** Running evaluation *****
[2019-02-24 17:39:35,474]   >>   Num examples = 1001
[2019-02-24 17:39:35,474]   >>   Batch size = 8
[2019-02-24 17:39:35,606]   >> ***** Running training *****
[2019-02-24 17:39:35,606]   >>   Num examples = 1001
[2019-02-24 17:39:35,606]   >>   Batch size = 64
[2019-02-24 17:39:35,606]   >>   Num steps = 46
[2019-02-24 17:39:59,795]   >> device: cuda n_gpu: 1, distributed training: False, 16-bits training: False
[2019-02-24 17:39:59,812]   >> LOOKING AT /home/panxie/Document/kaggle/quora/data/splited_data/train.csv
[2019-02-24 17:40:06,807]   >> ***** Running evaluation *****
[2019-02-24 17:40:06,807]   >>   Num examples = 1001
[2019-02-24 17:40:06,807]   >>   Batch size = 8
[2019-02-24 17:40:06,940]   >> ***** Running training *****
[2019-02-24 17:40:06,940]   >>   Num examples = 1001
[2019-02-24 17:40:06,940]   >>   Batch size = 64
[2019-02-24 17:40:06,940]   >>   Num steps = 46
[2019-02-24 17:40:31,189]   >> device: cuda n_gpu: 1, distributed training: False, 16-bits training: False
[2019-02-24 17:40:31,205]   >> LOOKING AT /home/panxie/Document/kaggle/quora/data/splited_data/train.csv
[2019-02-24 17:40:38,260]   >> ***** Running evaluation *****
[2019-02-24 17:40:38,260]   >>   Num examples = 1001
[2019-02-24 17:40:38,260]   >>   Batch size = 8
[2019-02-24 17:40:38,392]   >> ***** Running training *****
[2019-02-24 17:40:38,392]   >>   Num examples = 1001
[2019-02-24 17:40:38,392]   >>   Batch size = 64
[2019-02-24 17:40:38,392]   >>   Num steps = 46
[2019-02-24 17:41:13,186]   >> device: cuda n_gpu: 1, distributed training: False, 16-bits training: False
[2019-02-24 17:41:13,203]   >> LOOKING AT /home/panxie/Document/kaggle/quora/data/splited_data/train.csv
[2019-02-24 17:41:20,408]   >> ***** Running evaluation *****
[2019-02-24 17:41:20,408]   >>   Num examples = 1001
[2019-02-24 17:41:20,408]   >>   Batch size = 8
[2019-02-24 17:41:20,543]   >> ***** Running training *****
[2019-02-24 17:41:20,543]   >>   Num examples = 1001
[2019-02-24 17:41:20,544]   >>   Batch size = 64
[2019-02-24 17:41:20,544]   >>   Num steps = 46
[2019-02-24 17:53:25,005]   >> device: cuda n_gpu: 1, distributed training: False, 16-bits training: False
[2019-02-24 17:53:25,022]   >> LOOKING AT /home/panxie/Document/kaggle/quora/data/splited_data/train.csv
[2019-02-24 17:53:32,079]   >> ***** Running evaluation *****
[2019-02-24 17:53:32,079]   >>   Num examples = 1001
[2019-02-24 17:53:32,079]   >>   Batch size = 8
[2019-02-24 17:53:32,210]   >> ***** Running training *****
[2019-02-24 17:53:32,210]   >>   Num examples = 1001
[2019-02-24 17:53:32,210]   >>   Batch size = 64
[2019-02-24 17:53:32,210]   >>   Num steps = 46
[2019-02-24 17:53:55,680]   >> device: cuda n_gpu: 1, distributed training: False, 16-bits training: False
[2019-02-24 17:53:55,696]   >> LOOKING AT /home/panxie/Document/kaggle/quora/data/splited_data/train.csv
[2019-02-24 17:54:02,864]   >> ***** Running evaluation *****
[2019-02-24 17:54:02,864]   >>   Num examples = 1001
[2019-02-24 17:54:02,864]   >>   Batch size = 8
[2019-02-24 17:54:03,001]   >> ***** Running training *****
[2019-02-24 17:54:03,001]   >>   Num examples = 1001
[2019-02-24 17:54:03,001]   >>   Batch size = 64
[2019-02-24 17:54:03,001]   >>   Num steps = 46
[2019-02-24 17:54:53,362]   >> device: cuda n_gpu: 1, distributed training: False, 16-bits training: False
[2019-02-24 17:54:53,379]   >> LOOKING AT /home/panxie/Document/kaggle/quora/data/splited_data/train.csv
[2019-02-24 17:55:00,407]   >> ***** Running evaluation *****
[2019-02-24 17:55:00,407]   >>   Num examples = 1002
[2019-02-24 17:55:00,408]   >>   Batch size = 8
[2019-02-24 17:55:00,542]   >> ***** Running training *****
[2019-02-24 17:55:00,542]   >>   Num examples = 1001
[2019-02-24 17:55:00,542]   >>   Batch size = 64
[2019-02-24 17:55:00,542]   >>   Num steps = 46
[2019-02-24 17:55:27,827]   >> device: cuda n_gpu: 1, distributed training: False, 16-bits training: False
[2019-02-24 17:55:27,843]   >> LOOKING AT /home/panxie/Document/kaggle/quora/data/splited_data/train.csv
[2019-02-24 17:55:34,886]   >> ***** Running evaluation *****
[2019-02-24 17:55:34,886]   >>   Num examples = 1002
[2019-02-24 17:55:34,886]   >>   Batch size = 8
[2019-02-24 17:55:35,019]   >> ***** Running training *****
[2019-02-24 17:55:35,019]   >>   Num examples = 1001
[2019-02-24 17:55:35,019]   >>   Batch size = 64
[2019-02-24 17:55:35,019]   >>   Num steps = 46
[2019-02-24 17:55:40,386]   >> epcoh 0, threshold 0.2000, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.0000
[2019-02-24 17:55:40,387]   >> epcoh 0, threshold 0.2103, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.0000
[2019-02-24 17:55:40,388]   >> epcoh 0, threshold 0.2205, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.0000
[2019-02-24 17:55:40,389]   >> epcoh 0, threshold 0.2308, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.0000
[2019-02-24 17:55:40,390]   >> epcoh 0, threshold 0.2410, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.0000
[2019-02-24 17:55:40,391]   >> epcoh 0, threshold 0.2513, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.0000
[2019-02-24 17:55:40,392]   >> epcoh 0, threshold 0.2615, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.0000
[2019-02-24 17:55:40,393]   >> epcoh 0, threshold 0.2718, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.0000
[2019-02-24 17:55:40,395]   >> epcoh 0, threshold 0.2821, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.0000
[2019-02-24 17:55:40,396]   >> epcoh 0, threshold 0.2923, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.0000
[2019-02-24 17:55:40,397]   >> epcoh 0, threshold 0.3026, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.0000
[2019-02-24 17:55:40,398]   >> epcoh 0, threshold 0.3128, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.0000
[2019-02-24 17:55:40,399]   >> epcoh 0, threshold 0.3231, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.0000
[2019-02-24 17:55:40,400]   >> epcoh 0, threshold 0.3333, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.0000
[2019-02-24 17:55:40,401]   >> epcoh 0, threshold 0.3436, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.0000
[2019-02-24 17:55:40,402]   >> epcoh 0, threshold 0.3538, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.0000
[2019-02-24 17:55:40,403]   >> epcoh 0, threshold 0.3641, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.0000
[2019-02-24 17:55:40,405]   >> epcoh 0, threshold 0.3744, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.0000
[2019-02-24 17:55:40,406]   >> epcoh 0, threshold 0.3846, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.0000
[2019-02-24 17:55:40,407]   >> epcoh 0, threshold 0.3949, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.0000
[2019-02-24 17:55:40,408]   >> epcoh 0, threshold 0.4051, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.0000
[2019-02-24 17:55:40,409]   >> epcoh 0, threshold 0.4154, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.0000
[2019-02-24 17:55:40,410]   >> epcoh 0, threshold 0.4256, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.0000
[2019-02-24 17:55:40,411]   >> epcoh 0, threshold 0.4359, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.0000
[2019-02-24 17:55:40,412]   >> epcoh 0, threshold 0.4462, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.0000
[2019-02-24 17:55:40,413]   >> epcoh 0, threshold 0.4564, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.0000
[2019-02-24 17:55:40,414]   >> epcoh 0, threshold 0.4667, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.0000
[2019-02-24 17:55:40,416]   >> epcoh 0, threshold 0.4769, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.0000
[2019-02-24 17:55:40,417]   >> epcoh 0, threshold 0.4872, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.0000
[2019-02-24 17:55:40,418]   >> epcoh 0, threshold 0.4974, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.0000
[2019-02-24 17:55:40,419]   >> epcoh 0, threshold 0.5077, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.0000
[2019-02-24 17:55:40,420]   >> epcoh 0, threshold 0.5179, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.0000
[2019-02-24 17:55:40,421]   >> epcoh 0, threshold 0.5282, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.0000
[2019-02-24 17:55:40,422]   >> epcoh 0, threshold 0.5385, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.0000
[2019-02-24 17:55:40,423]   >> epcoh 0, threshold 0.5487, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.0000
[2019-02-24 17:55:40,424]   >> epcoh 0, threshold 0.5590, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.0000
[2019-02-24 17:55:40,426]   >> epcoh 0, threshold 0.5692, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.0000
[2019-02-24 17:55:40,427]   >> epcoh 0, threshold 0.5795, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.0000
[2019-02-24 17:55:40,428]   >> epcoh 0, threshold 0.5897, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.0000
[2019-02-24 17:55:40,429]   >> epcoh 0, threshold 0.6000, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.0000
[2019-02-24 17:55:40,569]   >> ***** Running training *****
[2019-02-24 17:55:40,569]   >>   Num examples = 1001
[2019-02-24 17:55:40,569]   >>   Batch size = 64
[2019-02-24 17:55:40,569]   >>   Num steps = 46
[2019-02-24 17:55:46,431]   >> epcoh 1, threshold 0.2000, accuracy 0.9301, precision 0.4375, recall 0.5833, f1 0.5000, best_f1 0.5000
[2019-02-24 17:55:46,748]   >> epcoh 1, threshold 0.2103, accuracy 0.9351, precision 0.4648, recall 0.5500, f1 0.5038, best_f1 0.5038
[2019-02-24 17:55:46,750]   >> epcoh 1, threshold 0.2205, accuracy 0.9391, precision 0.4918, recall 0.5000, f1 0.4959, best_f1 0.5038
[2019-02-24 17:55:46,751]   >> epcoh 1, threshold 0.2308, accuracy 0.9391, precision 0.4912, recall 0.4667, f1 0.4786, best_f1 0.5038
[2019-02-24 17:55:46,752]   >> epcoh 1, threshold 0.2410, accuracy 0.9441, precision 0.5417, recall 0.4333, f1 0.4815, best_f1 0.5038
[2019-02-24 17:55:46,753]   >> epcoh 1, threshold 0.2513, accuracy 0.9431, precision 0.5349, recall 0.3833, f1 0.4466, best_f1 0.5038
[2019-02-24 17:55:46,755]   >> epcoh 1, threshold 0.2615, accuracy 0.9461, precision 0.5833, recall 0.3500, f1 0.4375, best_f1 0.5038
[2019-02-24 17:55:46,756]   >> epcoh 1, threshold 0.2718, accuracy 0.9461, precision 0.6000, recall 0.3000, f1 0.4000, best_f1 0.5038
[2019-02-24 17:55:46,757]   >> epcoh 1, threshold 0.2821, accuracy 0.9461, precision 0.6364, recall 0.2333, f1 0.3415, best_f1 0.5038
[2019-02-24 17:55:46,758]   >> epcoh 1, threshold 0.2923, accuracy 0.9431, precision 0.6000, recall 0.1500, f1 0.2400, best_f1 0.5038
[2019-02-24 17:55:46,759]   >> epcoh 1, threshold 0.3026, accuracy 0.9401, precision 0.5000, recall 0.0833, f1 0.1429, best_f1 0.5038
[2019-02-24 17:55:46,760]   >> epcoh 1, threshold 0.3128, accuracy 0.9401, precision 0.5000, recall 0.0667, f1 0.1176, best_f1 0.5038
[2019-02-24 17:55:46,762]   >> epcoh 1, threshold 0.3231, accuracy 0.9411, precision 0.6000, recall 0.0500, f1 0.0923, best_f1 0.5038
[2019-02-24 17:55:46,763]   >> epcoh 1, threshold 0.3333, accuracy 0.9401, precision 0.5000, recall 0.0167, f1 0.0323, best_f1 0.5038
[2019-02-24 17:55:46,764]   >> epcoh 1, threshold 0.3436, accuracy 0.9401, precision 0.5000, recall 0.0167, f1 0.0323, best_f1 0.5038
[2019-02-24 17:55:46,765]   >> epcoh 1, threshold 0.3538, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.5038
[2019-02-24 17:55:46,766]   >> epcoh 1, threshold 0.3641, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.5038
[2019-02-24 17:55:46,767]   >> epcoh 1, threshold 0.3744, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.5038
[2019-02-24 17:55:46,768]   >> epcoh 1, threshold 0.3846, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.5038
[2019-02-24 17:55:46,770]   >> epcoh 1, threshold 0.3949, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.5038
[2019-02-24 17:55:46,771]   >> epcoh 1, threshold 0.4051, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.5038
[2019-02-24 17:55:46,772]   >> epcoh 1, threshold 0.4154, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.5038
[2019-02-24 17:55:46,773]   >> epcoh 1, threshold 0.4256, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.5038
[2019-02-24 17:55:46,774]   >> epcoh 1, threshold 0.4359, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.5038
[2019-02-24 17:55:46,776]   >> epcoh 1, threshold 0.4462, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.5038
[2019-02-24 17:55:46,777]   >> epcoh 1, threshold 0.4564, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.5038
[2019-02-24 17:55:46,778]   >> epcoh 1, threshold 0.4667, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.5038
[2019-02-24 17:55:46,779]   >> epcoh 1, threshold 0.4769, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.5038
[2019-02-24 17:55:46,780]   >> epcoh 1, threshold 0.4872, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.5038
[2019-02-24 17:55:46,781]   >> epcoh 1, threshold 0.4974, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.5038
[2019-02-24 17:55:46,783]   >> epcoh 1, threshold 0.5077, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.5038
[2019-02-24 17:55:46,784]   >> epcoh 1, threshold 0.5179, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.5038
[2019-02-24 17:55:46,785]   >> epcoh 1, threshold 0.5282, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.5038
[2019-02-24 17:55:46,786]   >> epcoh 1, threshold 0.5385, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.5038
[2019-02-24 17:55:46,787]   >> epcoh 1, threshold 0.5487, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.5038
[2019-02-24 17:55:46,788]   >> epcoh 1, threshold 0.5590, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.5038
[2019-02-24 17:55:46,790]   >> epcoh 1, threshold 0.5692, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.5038
[2019-02-24 17:55:46,791]   >> epcoh 1, threshold 0.5795, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.5038
[2019-02-24 17:55:46,792]   >> epcoh 1, threshold 0.5897, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.5038
[2019-02-24 17:55:46,793]   >> epcoh 1, threshold 0.6000, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.5038
[2019-02-24 17:55:46,934]   >> ***** Running training *****
[2019-02-24 17:55:46,934]   >>   Num examples = 1001
[2019-02-24 17:55:46,934]   >>   Batch size = 64
[2019-02-24 17:55:46,935]   >>   Num steps = 46
[2019-02-24 17:55:52,816]   >> epcoh 2, threshold 0.2000, accuracy 0.9441, precision 0.5588, recall 0.3167, f1 0.4043, best_f1 0.4043
[2019-02-24 17:55:52,823]   >> epcoh 2, threshold 0.2103, accuracy 0.9441, precision 0.5625, recall 0.3000, f1 0.3913, best_f1 0.4043
[2019-02-24 17:55:52,828]   >> epcoh 2, threshold 0.2205, accuracy 0.9451, precision 0.5806, recall 0.3000, f1 0.3956, best_f1 0.4043
[2019-02-24 17:55:52,831]   >> epcoh 2, threshold 0.2308, accuracy 0.9431, precision 0.5652, recall 0.2167, f1 0.3133, best_f1 0.4043
[2019-02-24 17:55:52,834]   >> epcoh 2, threshold 0.2410, accuracy 0.9421, precision 0.5500, recall 0.1833, f1 0.2750, best_f1 0.4043
[2019-02-24 17:55:52,836]   >> epcoh 2, threshold 0.2513, accuracy 0.9431, precision 0.5882, recall 0.1667, f1 0.2597, best_f1 0.4043
[2019-02-24 17:55:52,839]   >> epcoh 2, threshold 0.2615, accuracy 0.9421, precision 0.5714, recall 0.1333, f1 0.2162, best_f1 0.4043
[2019-02-24 17:55:52,841]   >> epcoh 2, threshold 0.2718, accuracy 0.9411, precision 0.5455, recall 0.1000, f1 0.1690, best_f1 0.4043
[2019-02-24 17:55:52,843]   >> epcoh 2, threshold 0.2821, accuracy 0.9411, precision 0.5556, recall 0.0833, f1 0.1449, best_f1 0.4043
[2019-02-24 17:55:52,845]   >> epcoh 2, threshold 0.2923, accuracy 0.9381, precision 0.3333, recall 0.0333, f1 0.0606, best_f1 0.4043
[2019-02-24 17:55:52,846]   >> epcoh 2, threshold 0.3026, accuracy 0.9381, precision 0.3333, recall 0.0333, f1 0.0606, best_f1 0.4043
[2019-02-24 17:55:52,848]   >> epcoh 2, threshold 0.3128, accuracy 0.9391, precision 0.3333, recall 0.0167, f1 0.0317, best_f1 0.4043
[2019-02-24 17:55:52,849]   >> epcoh 2, threshold 0.3231, accuracy 0.9401, precision 0.5000, recall 0.0167, f1 0.0323, best_f1 0.4043
[2019-02-24 17:55:52,851]   >> epcoh 2, threshold 0.3333, accuracy 0.9401, precision 0.5000, recall 0.0167, f1 0.0323, best_f1 0.4043
[2019-02-24 17:55:52,852]   >> epcoh 2, threshold 0.3436, accuracy 0.9401, precision 0.5000, recall 0.0167, f1 0.0323, best_f1 0.4043
[2019-02-24 17:55:52,854]   >> epcoh 2, threshold 0.3538, accuracy 0.9411, precision 1.0000, recall 0.0167, f1 0.0328, best_f1 0.4043
[2019-02-24 17:55:52,855]   >> epcoh 2, threshold 0.3641, accuracy 0.9411, precision 1.0000, recall 0.0167, f1 0.0328, best_f1 0.4043
[2019-02-24 17:55:52,856]   >> epcoh 2, threshold 0.3744, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.4043
[2019-02-24 17:55:52,858]   >> epcoh 2, threshold 0.3846, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.4043
[2019-02-24 17:55:52,859]   >> epcoh 2, threshold 0.3949, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.4043
[2019-02-24 17:55:52,860]   >> epcoh 2, threshold 0.4051, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.4043
[2019-02-24 17:55:52,861]   >> epcoh 2, threshold 0.4154, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.4043
[2019-02-24 17:55:52,863]   >> epcoh 2, threshold 0.4256, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.4043
[2019-02-24 17:55:52,864]   >> epcoh 2, threshold 0.4359, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.4043
[2019-02-24 17:55:52,865]   >> epcoh 2, threshold 0.4462, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.4043
[2019-02-24 17:55:52,866]   >> epcoh 2, threshold 0.4564, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.4043
[2019-02-24 17:55:52,867]   >> epcoh 2, threshold 0.4667, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.4043
[2019-02-24 17:55:52,868]   >> epcoh 2, threshold 0.4769, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.4043
[2019-02-24 17:55:52,869]   >> epcoh 2, threshold 0.4872, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.4043
[2019-02-24 17:55:52,870]   >> epcoh 2, threshold 0.4974, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.4043
[2019-02-24 17:55:52,871]   >> epcoh 2, threshold 0.5077, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.4043
[2019-02-24 17:55:52,872]   >> epcoh 2, threshold 0.5179, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.4043
[2019-02-24 17:55:52,873]   >> epcoh 2, threshold 0.5282, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.4043
[2019-02-24 17:55:52,874]   >> epcoh 2, threshold 0.5385, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.4043
[2019-02-24 17:55:52,875]   >> epcoh 2, threshold 0.5487, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.4043
[2019-02-24 17:55:52,876]   >> epcoh 2, threshold 0.5590, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.4043
[2019-02-24 17:55:52,877]   >> epcoh 2, threshold 0.5692, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.4043
[2019-02-24 17:55:52,878]   >> epcoh 2, threshold 0.5795, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.4043
[2019-02-24 17:55:52,879]   >> epcoh 2, threshold 0.5897, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.4043
[2019-02-24 17:55:52,880]   >> epcoh 2, threshold 0.6000, accuracy 0.9401, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.4043
[2019-02-24 18:02:06,576]   >> device: cuda n_gpu: 1, distributed training: False, 16-bits training: False
[2019-02-24 18:02:06,592]   >> LOOKING AT /home/panxie/Document/kaggle/quora/data/splited_data/train.csv
[2019-02-24 18:02:13,443]   >> ***** Running evaluation *****
[2019-02-24 18:02:13,443]   >>   Num examples = 18
[2019-02-24 18:02:13,443]   >>   Batch size = 8
[2019-02-24 18:02:13,457]   >> ***** Running training *****
[2019-02-24 18:02:13,457]   >>   Num examples = 101
[2019-02-24 18:02:13,457]   >>   Batch size = 64
[2019-02-24 18:02:13,457]   >>   Num steps = 4
[2019-02-24 18:02:14,461]   >> epcoh 0, threshold 0.2000, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:14,463]   >> epcoh 0, threshold 0.2103, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:14,464]   >> epcoh 0, threshold 0.2205, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:14,466]   >> epcoh 0, threshold 0.2308, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:14,467]   >> epcoh 0, threshold 0.2410, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:14,468]   >> epcoh 0, threshold 0.2513, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:14,470]   >> epcoh 0, threshold 0.2615, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:14,471]   >> epcoh 0, threshold 0.2718, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:14,472]   >> epcoh 0, threshold 0.2821, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:14,473]   >> epcoh 0, threshold 0.2923, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:14,475]   >> epcoh 0, threshold 0.3026, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:14,476]   >> epcoh 0, threshold 0.3128, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:14,477]   >> epcoh 0, threshold 0.3231, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:14,478]   >> epcoh 0, threshold 0.3333, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:14,479]   >> epcoh 0, threshold 0.3436, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:14,480]   >> epcoh 0, threshold 0.3538, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:14,481]   >> epcoh 0, threshold 0.3641, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:14,482]   >> epcoh 0, threshold 0.3744, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:14,483]   >> epcoh 0, threshold 0.3846, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:14,484]   >> epcoh 0, threshold 0.3949, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:14,485]   >> epcoh 0, threshold 0.4051, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:14,485]   >> epcoh 0, threshold 0.4154, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:14,486]   >> epcoh 0, threshold 0.4256, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:14,487]   >> epcoh 0, threshold 0.4359, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:14,488]   >> epcoh 0, threshold 0.4462, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:14,793]   >> epcoh 0, threshold 0.4564, accuracy 0.1111, precision 0.0588, recall 1.0000, f1 0.1111, best_f1 0.1111
[2019-02-24 18:02:15,299]   >> epcoh 0, threshold 0.4667, accuracy 0.2222, precision 0.0667, recall 1.0000, f1 0.1250, best_f1 0.1250
[2019-02-24 18:02:15,825]   >> epcoh 0, threshold 0.4769, accuracy 0.6111, precision 0.1250, recall 1.0000, f1 0.2222, best_f1 0.2222
[2019-02-24 18:02:15,826]   >> epcoh 0, threshold 0.4872, accuracy 0.8889, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2222
[2019-02-24 18:02:15,827]   >> epcoh 0, threshold 0.4974, accuracy 0.8889, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2222
[2019-02-24 18:02:15,828]   >> epcoh 0, threshold 0.5077, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2222
[2019-02-24 18:02:15,829]   >> epcoh 0, threshold 0.5179, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2222
[2019-02-24 18:02:15,830]   >> epcoh 0, threshold 0.5282, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2222
[2019-02-24 18:02:15,831]   >> epcoh 0, threshold 0.5385, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2222
[2019-02-24 18:02:15,832]   >> epcoh 0, threshold 0.5487, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2222
[2019-02-24 18:02:15,833]   >> epcoh 0, threshold 0.5590, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2222
[2019-02-24 18:02:15,834]   >> epcoh 0, threshold 0.5692, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2222
[2019-02-24 18:02:15,835]   >> epcoh 0, threshold 0.5795, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2222
[2019-02-24 18:02:15,836]   >> epcoh 0, threshold 0.5897, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2222
[2019-02-24 18:02:15,837]   >> epcoh 0, threshold 0.6000, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2222
[2019-02-24 18:02:15,851]   >> ***** Running training *****
[2019-02-24 18:02:15,851]   >>   Num examples = 101
[2019-02-24 18:02:15,851]   >>   Batch size = 64
[2019-02-24 18:02:15,851]   >>   Num steps = 4
[2019-02-24 18:02:16,686]   >> epcoh 1, threshold 0.2000, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:16,688]   >> epcoh 1, threshold 0.2103, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:16,689]   >> epcoh 1, threshold 0.2205, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:16,691]   >> epcoh 1, threshold 0.2308, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:16,692]   >> epcoh 1, threshold 0.2410, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:16,694]   >> epcoh 1, threshold 0.2513, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:16,695]   >> epcoh 1, threshold 0.2615, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:16,696]   >> epcoh 1, threshold 0.2718, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:16,697]   >> epcoh 1, threshold 0.2821, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:16,699]   >> epcoh 1, threshold 0.2923, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:16,700]   >> epcoh 1, threshold 0.3026, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:16,701]   >> epcoh 1, threshold 0.3128, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:16,702]   >> epcoh 1, threshold 0.3231, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:16,703]   >> epcoh 1, threshold 0.3333, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:17,145]   >> epcoh 1, threshold 0.3436, accuracy 0.1111, precision 0.0588, recall 1.0000, f1 0.1111, best_f1 0.1111
[2019-02-24 18:02:17,673]   >> epcoh 1, threshold 0.3538, accuracy 0.2222, precision 0.0667, recall 1.0000, f1 0.1250, best_f1 0.1250
[2019-02-24 18:02:17,674]   >> epcoh 1, threshold 0.3641, accuracy 0.2222, precision 0.0667, recall 1.0000, f1 0.1250, best_f1 0.1250
[2019-02-24 18:02:18,200]   >> epcoh 1, threshold 0.3744, accuracy 0.3333, precision 0.0769, recall 1.0000, f1 0.1429, best_f1 0.1429
[2019-02-24 18:02:18,201]   >> epcoh 1, threshold 0.3846, accuracy 0.3889, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1429
[2019-02-24 18:02:18,202]   >> epcoh 1, threshold 0.3949, accuracy 0.7222, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1429
[2019-02-24 18:02:18,203]   >> epcoh 1, threshold 0.4051, accuracy 0.8333, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1429
[2019-02-24 18:02:18,204]   >> epcoh 1, threshold 0.4154, accuracy 0.8333, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1429
[2019-02-24 18:02:18,204]   >> epcoh 1, threshold 0.4256, accuracy 0.8889, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1429
[2019-02-24 18:02:18,205]   >> epcoh 1, threshold 0.4359, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1429
[2019-02-24 18:02:18,206]   >> epcoh 1, threshold 0.4462, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1429
[2019-02-24 18:02:18,207]   >> epcoh 1, threshold 0.4564, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1429
[2019-02-24 18:02:18,208]   >> epcoh 1, threshold 0.4667, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1429
[2019-02-24 18:02:18,209]   >> epcoh 1, threshold 0.4769, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1429
[2019-02-24 18:02:18,210]   >> epcoh 1, threshold 0.4872, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1429
[2019-02-24 18:02:18,211]   >> epcoh 1, threshold 0.4974, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1429
[2019-02-24 18:02:18,212]   >> epcoh 1, threshold 0.5077, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1429
[2019-02-24 18:02:18,213]   >> epcoh 1, threshold 0.5179, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1429
[2019-02-24 18:02:18,214]   >> epcoh 1, threshold 0.5282, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1429
[2019-02-24 18:02:18,215]   >> epcoh 1, threshold 0.5385, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1429
[2019-02-24 18:02:18,216]   >> epcoh 1, threshold 0.5487, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1429
[2019-02-24 18:02:18,217]   >> epcoh 1, threshold 0.5590, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1429
[2019-02-24 18:02:18,218]   >> epcoh 1, threshold 0.5692, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1429
[2019-02-24 18:02:18,219]   >> epcoh 1, threshold 0.5795, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1429
[2019-02-24 18:02:18,220]   >> epcoh 1, threshold 0.5897, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1429
[2019-02-24 18:02:18,221]   >> epcoh 1, threshold 0.6000, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1429
[2019-02-24 18:02:18,235]   >> ***** Running training *****
[2019-02-24 18:02:18,235]   >>   Num examples = 101
[2019-02-24 18:02:18,235]   >>   Batch size = 64
[2019-02-24 18:02:18,235]   >>   Num steps = 4
[2019-02-24 18:02:19,094]   >> epcoh 2, threshold 0.2000, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:19,095]   >> epcoh 2, threshold 0.2103, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:19,096]   >> epcoh 2, threshold 0.2205, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:19,097]   >> epcoh 2, threshold 0.2308, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:19,098]   >> epcoh 2, threshold 0.2410, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:19,098]   >> epcoh 2, threshold 0.2513, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:19,099]   >> epcoh 2, threshold 0.2615, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:19,100]   >> epcoh 2, threshold 0.2718, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:19,101]   >> epcoh 2, threshold 0.2821, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:19,102]   >> epcoh 2, threshold 0.2923, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:19,103]   >> epcoh 2, threshold 0.3026, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:19,104]   >> epcoh 2, threshold 0.3128, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:19,104]   >> epcoh 2, threshold 0.3231, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:19,105]   >> epcoh 2, threshold 0.3333, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:19,106]   >> epcoh 2, threshold 0.3436, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:19,107]   >> epcoh 2, threshold 0.3538, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:19,108]   >> epcoh 2, threshold 0.3641, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:19,109]   >> epcoh 2, threshold 0.3744, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:19,109]   >> epcoh 2, threshold 0.3846, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:19,110]   >> epcoh 2, threshold 0.3949, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:19,111]   >> epcoh 2, threshold 0.4051, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:19,112]   >> epcoh 2, threshold 0.4154, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:19,113]   >> epcoh 2, threshold 0.4256, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:19,114]   >> epcoh 2, threshold 0.4359, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:19,114]   >> epcoh 2, threshold 0.4462, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:19,115]   >> epcoh 2, threshold 0.4564, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:19,116]   >> epcoh 2, threshold 0.4667, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:19,509]   >> epcoh 2, threshold 0.4769, accuracy 0.1111, precision 0.0588, recall 1.0000, f1 0.1111, best_f1 0.1111
[2019-02-24 18:02:21,227]   >> epcoh 2, threshold 0.4872, accuracy 0.2222, precision 0.0667, recall 1.0000, f1 0.1250, best_f1 0.1250
[2019-02-24 18:02:22,674]   >> epcoh 2, threshold 0.4974, accuracy 0.5000, precision 0.1000, recall 1.0000, f1 0.1818, best_f1 0.1818
[2019-02-24 18:02:22,675]   >> epcoh 2, threshold 0.5077, accuracy 0.7222, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1818
[2019-02-24 18:02:22,676]   >> epcoh 2, threshold 0.5179, accuracy 0.8889, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1818
[2019-02-24 18:02:22,677]   >> epcoh 2, threshold 0.5282, accuracy 0.8889, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1818
[2019-02-24 18:02:22,678]   >> epcoh 2, threshold 0.5385, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1818
[2019-02-24 18:02:22,679]   >> epcoh 2, threshold 0.5487, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1818
[2019-02-24 18:02:22,680]   >> epcoh 2, threshold 0.5590, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1818
[2019-02-24 18:02:22,681]   >> epcoh 2, threshold 0.5692, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1818
[2019-02-24 18:02:22,681]   >> epcoh 2, threshold 0.5795, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1818
[2019-02-24 18:02:22,682]   >> epcoh 2, threshold 0.5897, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1818
[2019-02-24 18:02:22,683]   >> epcoh 2, threshold 0.6000, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1818
[2019-02-24 18:02:49,348]   >> device: cuda n_gpu: 1, distributed training: False, 16-bits training: False
[2019-02-24 18:02:49,364]   >> LOOKING AT /home/panxie/Document/kaggle/quora/data/splited_data/train.csv
[2019-02-24 18:02:56,144]   >> ***** Running evaluation *****
[2019-02-24 18:02:56,144]   >>   Num examples = 18
[2019-02-24 18:02:56,144]   >>   Batch size = 8
[2019-02-24 18:02:56,158]   >> ***** Running training *****
[2019-02-24 18:02:56,158]   >>   Num examples = 101
[2019-02-24 18:02:56,158]   >>   Batch size = 64
[2019-02-24 18:02:56,159]   >>   Num steps = 4
[2019-02-24 18:02:57,208]   >> epcoh 0, threshold 0.2000, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:57,214]   >> epcoh 0, threshold 0.2103, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:57,218]   >> epcoh 0, threshold 0.2205, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:57,223]   >> epcoh 0, threshold 0.2308, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:57,226]   >> epcoh 0, threshold 0.2410, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:57,229]   >> epcoh 0, threshold 0.2513, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:57,232]   >> epcoh 0, threshold 0.2615, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:57,234]   >> epcoh 0, threshold 0.2718, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:57,236]   >> epcoh 0, threshold 0.2821, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:57,238]   >> epcoh 0, threshold 0.2923, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:57,240]   >> epcoh 0, threshold 0.3026, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:57,241]   >> epcoh 0, threshold 0.3128, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:57,243]   >> epcoh 0, threshold 0.3231, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:57,244]   >> epcoh 0, threshold 0.3333, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:57,246]   >> epcoh 0, threshold 0.3436, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:57,247]   >> epcoh 0, threshold 0.3538, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:57,248]   >> epcoh 0, threshold 0.3641, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:57,249]   >> epcoh 0, threshold 0.3744, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:57,251]   >> epcoh 0, threshold 0.3846, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:57,252]   >> epcoh 0, threshold 0.3949, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:57,253]   >> epcoh 0, threshold 0.4051, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:57,254]   >> epcoh 0, threshold 0.4154, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:57,255]   >> epcoh 0, threshold 0.4256, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:57,256]   >> epcoh 0, threshold 0.4359, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:57,257]   >> epcoh 0, threshold 0.4462, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:57,661]   >> epcoh 0, threshold 0.4564, accuracy 0.1111, precision 0.0588, recall 1.0000, f1 0.1111, best_f1 0.1111
[2019-02-24 18:02:58,074]   >> epcoh 0, threshold 0.4667, accuracy 0.2222, precision 0.0667, recall 1.0000, f1 0.1250, best_f1 0.1250
[2019-02-24 18:02:58,609]   >> epcoh 0, threshold 0.4769, accuracy 0.6111, precision 0.1250, recall 1.0000, f1 0.2222, best_f1 0.2222
[2019-02-24 18:02:58,611]   >> epcoh 0, threshold 0.4872, accuracy 0.8889, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2222
[2019-02-24 18:02:58,612]   >> epcoh 0, threshold 0.4974, accuracy 0.8889, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2222
[2019-02-24 18:02:58,614]   >> epcoh 0, threshold 0.5077, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2222
[2019-02-24 18:02:58,615]   >> epcoh 0, threshold 0.5179, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2222
[2019-02-24 18:02:58,616]   >> epcoh 0, threshold 0.5282, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2222
[2019-02-24 18:02:58,617]   >> epcoh 0, threshold 0.5385, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2222
[2019-02-24 18:02:58,618]   >> epcoh 0, threshold 0.5487, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2222
[2019-02-24 18:02:58,619]   >> epcoh 0, threshold 0.5590, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2222
[2019-02-24 18:02:58,620]   >> epcoh 0, threshold 0.5692, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2222
[2019-02-24 18:02:58,622]   >> epcoh 0, threshold 0.5795, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2222
[2019-02-24 18:02:58,623]   >> epcoh 0, threshold 0.5897, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2222
[2019-02-24 18:02:58,624]   >> epcoh 0, threshold 0.6000, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2222
[2019-02-24 18:02:58,643]   >> ***** Running training *****
[2019-02-24 18:02:58,643]   >>   Num examples = 101
[2019-02-24 18:02:58,643]   >>   Batch size = 64
[2019-02-24 18:02:58,643]   >>   Num steps = 4
[2019-02-24 18:02:59,429]   >> epcoh 1, threshold 0.2000, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:59,430]   >> epcoh 1, threshold 0.2103, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:59,432]   >> epcoh 1, threshold 0.2205, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:59,433]   >> epcoh 1, threshold 0.2308, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:59,434]   >> epcoh 1, threshold 0.2410, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:59,435]   >> epcoh 1, threshold 0.2513, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:59,436]   >> epcoh 1, threshold 0.2615, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:59,437]   >> epcoh 1, threshold 0.2718, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:59,438]   >> epcoh 1, threshold 0.2821, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:59,439]   >> epcoh 1, threshold 0.2923, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:59,440]   >> epcoh 1, threshold 0.3026, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:59,441]   >> epcoh 1, threshold 0.3128, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:59,442]   >> epcoh 1, threshold 0.3231, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:59,444]   >> epcoh 1, threshold 0.3333, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:02:59,944]   >> epcoh 1, threshold 0.3436, accuracy 0.1111, precision 0.0588, recall 1.0000, f1 0.1111, best_f1 0.1111
[2019-02-24 18:03:00,483]   >> epcoh 1, threshold 0.3538, accuracy 0.2222, precision 0.0667, recall 1.0000, f1 0.1250, best_f1 0.1250
[2019-02-24 18:03:00,484]   >> epcoh 1, threshold 0.3641, accuracy 0.2222, precision 0.0667, recall 1.0000, f1 0.1250, best_f1 0.1250
[2019-02-24 18:03:01,024]   >> epcoh 1, threshold 0.3744, accuracy 0.3333, precision 0.0769, recall 1.0000, f1 0.1429, best_f1 0.1429
[2019-02-24 18:03:01,025]   >> epcoh 1, threshold 0.3846, accuracy 0.3889, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1429
[2019-02-24 18:03:01,026]   >> epcoh 1, threshold 0.3949, accuracy 0.7222, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1429
[2019-02-24 18:03:01,028]   >> epcoh 1, threshold 0.4051, accuracy 0.8333, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1429
[2019-02-24 18:03:01,029]   >> epcoh 1, threshold 0.4154, accuracy 0.8333, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1429
[2019-02-24 18:03:01,030]   >> epcoh 1, threshold 0.4256, accuracy 0.8889, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1429
[2019-02-24 18:03:01,031]   >> epcoh 1, threshold 0.4359, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1429
[2019-02-24 18:03:01,032]   >> epcoh 1, threshold 0.4462, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1429
[2019-02-24 18:03:01,033]   >> epcoh 1, threshold 0.4564, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1429
[2019-02-24 18:03:01,034]   >> epcoh 1, threshold 0.4667, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1429
[2019-02-24 18:03:01,036]   >> epcoh 1, threshold 0.4769, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1429
[2019-02-24 18:03:01,037]   >> epcoh 1, threshold 0.4872, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1429
[2019-02-24 18:03:01,038]   >> epcoh 1, threshold 0.4974, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1429
[2019-02-24 18:03:01,039]   >> epcoh 1, threshold 0.5077, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1429
[2019-02-24 18:03:01,040]   >> epcoh 1, threshold 0.5179, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1429
[2019-02-24 18:03:01,041]   >> epcoh 1, threshold 0.5282, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1429
[2019-02-24 18:03:01,042]   >> epcoh 1, threshold 0.5385, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1429
[2019-02-24 18:03:01,044]   >> epcoh 1, threshold 0.5487, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1429
[2019-02-24 18:03:01,045]   >> epcoh 1, threshold 0.5590, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1429
[2019-02-24 18:03:01,046]   >> epcoh 1, threshold 0.5692, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1429
[2019-02-24 18:03:01,047]   >> epcoh 1, threshold 0.5795, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1429
[2019-02-24 18:03:01,048]   >> epcoh 1, threshold 0.5897, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1429
[2019-02-24 18:03:01,049]   >> epcoh 1, threshold 0.6000, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1429
[2019-02-24 18:03:01,069]   >> ***** Running training *****
[2019-02-24 18:03:01,069]   >>   Num examples = 101
[2019-02-24 18:03:01,069]   >>   Batch size = 64
[2019-02-24 18:03:01,069]   >>   Num steps = 4
[2019-02-24 18:03:01,955]   >> epcoh 2, threshold 0.2000, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:03:01,957]   >> epcoh 2, threshold 0.2103, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:03:01,959]   >> epcoh 2, threshold 0.2205, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:03:01,960]   >> epcoh 2, threshold 0.2308, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:03:01,962]   >> epcoh 2, threshold 0.2410, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:03:01,963]   >> epcoh 2, threshold 0.2513, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:03:01,965]   >> epcoh 2, threshold 0.2615, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:03:01,966]   >> epcoh 2, threshold 0.2718, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:03:01,967]   >> epcoh 2, threshold 0.2821, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:03:01,968]   >> epcoh 2, threshold 0.2923, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:03:01,970]   >> epcoh 2, threshold 0.3026, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:03:01,971]   >> epcoh 2, threshold 0.3128, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:03:01,972]   >> epcoh 2, threshold 0.3231, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:03:01,973]   >> epcoh 2, threshold 0.3333, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:03:01,974]   >> epcoh 2, threshold 0.3436, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:03:01,975]   >> epcoh 2, threshold 0.3538, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:03:01,976]   >> epcoh 2, threshold 0.3641, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:03:01,977]   >> epcoh 2, threshold 0.3744, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:03:01,978]   >> epcoh 2, threshold 0.3846, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:03:01,979]   >> epcoh 2, threshold 0.3949, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:03:01,980]   >> epcoh 2, threshold 0.4051, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:03:01,981]   >> epcoh 2, threshold 0.4154, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:03:01,982]   >> epcoh 2, threshold 0.4256, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:03:01,983]   >> epcoh 2, threshold 0.4359, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:03:01,983]   >> epcoh 2, threshold 0.4462, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:03:01,984]   >> epcoh 2, threshold 0.4564, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:03:01,985]   >> epcoh 2, threshold 0.4667, accuracy 0.0556, precision 0.0556, recall 1.0000, f1 0.1053, best_f1 0.1053
[2019-02-24 18:03:02,379]   >> epcoh 2, threshold 0.4769, accuracy 0.1111, precision 0.0588, recall 1.0000, f1 0.1111, best_f1 0.1111
[2019-02-24 18:03:04,091]   >> epcoh 2, threshold 0.4872, accuracy 0.2222, precision 0.0667, recall 1.0000, f1 0.1250, best_f1 0.1250
[2019-02-24 18:03:05,539]   >> epcoh 2, threshold 0.4974, accuracy 0.5000, precision 0.1000, recall 1.0000, f1 0.1818, best_f1 0.1818
[2019-02-24 18:03:05,541]   >> epcoh 2, threshold 0.5077, accuracy 0.7222, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1818
[2019-02-24 18:03:05,542]   >> epcoh 2, threshold 0.5179, accuracy 0.8889, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1818
[2019-02-24 18:03:05,542]   >> epcoh 2, threshold 0.5282, accuracy 0.8889, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1818
[2019-02-24 18:03:05,543]   >> epcoh 2, threshold 0.5385, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1818
[2019-02-24 18:03:05,544]   >> epcoh 2, threshold 0.5487, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1818
[2019-02-24 18:03:05,545]   >> epcoh 2, threshold 0.5590, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1818
[2019-02-24 18:03:05,546]   >> epcoh 2, threshold 0.5692, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1818
[2019-02-24 18:03:05,547]   >> epcoh 2, threshold 0.5795, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1818
[2019-02-24 18:03:05,548]   >> epcoh 2, threshold 0.5897, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1818
[2019-02-24 18:03:05,549]   >> epcoh 2, threshold 0.6000, accuracy 0.9444, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.1818
[2019-02-24 18:03:22,017]   >> device: cuda n_gpu: 1, distributed training: False, 16-bits training: False
[2019-02-24 18:03:22,033]   >> LOOKING AT /home/panxie/Document/kaggle/quora/data/splited_data/train.csv
[2019-02-24 18:03:28,835]   >> ***** Running evaluation *****
[2019-02-24 18:03:28,835]   >>   Num examples = 17
[2019-02-24 18:03:28,835]   >>   Batch size = 8
[2019-02-24 18:03:28,849]   >> ***** Running training *****
[2019-02-24 18:03:28,849]   >>   Num examples = 101
[2019-02-24 18:03:28,849]   >>   Batch size = 64
[2019-02-24 18:03:28,850]   >>   Num steps = 4
[2019-02-24 18:04:27,773]   >> device: cuda n_gpu: 1, distributed training: False, 16-bits training: False
[2019-02-24 18:04:27,790]   >> LOOKING AT /home/panxie/Document/kaggle/quora/data/splited_data/train.csv
[2019-02-24 18:04:34,621]   >> ***** Running evaluation *****
[2019-02-24 18:04:34,621]   >>   Num examples = 17
[2019-02-24 18:04:34,622]   >>   Batch size = 8
[2019-02-24 18:04:34,636]   >> ***** Running training *****
[2019-02-24 18:04:34,636]   >>   Num examples = 101
[2019-02-24 18:04:34,636]   >>   Batch size = 64
[2019-02-24 18:04:34,636]   >>   Num steps = 4
[2019-02-24 18:05:17,881]   >> device: cuda n_gpu: 1, distributed training: False, 16-bits training: False
[2019-02-24 18:05:17,898]   >> LOOKING AT /home/panxie/Document/kaggle/quora/data/splited_data/train.csv
[2019-02-24 18:05:24,699]   >> ***** Running evaluation *****
[2019-02-24 18:05:24,699]   >>   Num examples = 17
[2019-02-24 18:05:24,699]   >>   Batch size = 8
[2019-02-24 18:05:24,713]   >> ***** Running training *****
[2019-02-24 18:05:24,713]   >>   Num examples = 101
[2019-02-24 18:05:24,713]   >>   Batch size = 64
[2019-02-24 18:05:24,714]   >>   Num steps = 4
[2019-02-24 18:05:46,624]   >> device: cuda n_gpu: 1, distributed training: False, 16-bits training: False
[2019-02-24 18:05:46,640]   >> LOOKING AT /home/panxie/Document/kaggle/quora/data/splited_data/train.csv
[2019-02-24 18:05:53,419]   >> ***** Running evaluation *****
[2019-02-24 18:05:53,420]   >>   Num examples = 17
[2019-02-24 18:05:53,420]   >>   Batch size = 8
[2019-02-24 18:05:53,434]   >> ***** Running training *****
[2019-02-24 18:05:53,434]   >>   Num examples = 101
[2019-02-24 18:05:53,434]   >>   Batch size = 64
[2019-02-24 18:05:53,434]   >>   Num steps = 4
[2019-02-24 18:05:54,465]   >> epcoh 0, threshold 0.2000, accuracy 0.0588, precision 0.0588, recall 1.0000, f1 0.1111, best_f1 0.1111
[2019-02-24 18:05:54,469]   >> epcoh 0, threshold 0.2103, accuracy 0.0588, precision 0.0588, recall 1.0000, f1 0.1111, best_f1 0.1111
[2019-02-24 18:05:54,472]   >> epcoh 0, threshold 0.2205, accuracy 0.0588, precision 0.0588, recall 1.0000, f1 0.1111, best_f1 0.1111
[2019-02-24 18:05:54,474]   >> epcoh 0, threshold 0.2308, accuracy 0.0588, precision 0.0588, recall 1.0000, f1 0.1111, best_f1 0.1111
[2019-02-24 18:05:54,476]   >> epcoh 0, threshold 0.2410, accuracy 0.0588, precision 0.0588, recall 1.0000, f1 0.1111, best_f1 0.1111
[2019-02-24 18:05:54,479]   >> epcoh 0, threshold 0.2513, accuracy 0.0588, precision 0.0588, recall 1.0000, f1 0.1111, best_f1 0.1111
[2019-02-24 18:05:54,480]   >> epcoh 0, threshold 0.2615, accuracy 0.0588, precision 0.0588, recall 1.0000, f1 0.1111, best_f1 0.1111
[2019-02-24 18:05:54,482]   >> epcoh 0, threshold 0.2718, accuracy 0.0588, precision 0.0588, recall 1.0000, f1 0.1111, best_f1 0.1111
[2019-02-24 18:05:54,483]   >> epcoh 0, threshold 0.2821, accuracy 0.0588, precision 0.0588, recall 1.0000, f1 0.1111, best_f1 0.1111
[2019-02-24 18:05:54,485]   >> epcoh 0, threshold 0.2923, accuracy 0.0588, precision 0.0588, recall 1.0000, f1 0.1111, best_f1 0.1111
[2019-02-24 18:05:54,486]   >> epcoh 0, threshold 0.3026, accuracy 0.0588, precision 0.0588, recall 1.0000, f1 0.1111, best_f1 0.1111
[2019-02-24 18:05:54,487]   >> epcoh 0, threshold 0.3128, accuracy 0.0588, precision 0.0588, recall 1.0000, f1 0.1111, best_f1 0.1111
[2019-02-24 18:05:54,488]   >> epcoh 0, threshold 0.3231, accuracy 0.0588, precision 0.0588, recall 1.0000, f1 0.1111, best_f1 0.1111
[2019-02-24 18:05:54,490]   >> epcoh 0, threshold 0.3333, accuracy 0.0588, precision 0.0588, recall 1.0000, f1 0.1111, best_f1 0.1111
[2019-02-24 18:05:54,491]   >> epcoh 0, threshold 0.3436, accuracy 0.0588, precision 0.0588, recall 1.0000, f1 0.1111, best_f1 0.1111
[2019-02-24 18:05:54,492]   >> epcoh 0, threshold 0.3538, accuracy 0.0588, precision 0.0588, recall 1.0000, f1 0.1111, best_f1 0.1111
[2019-02-24 18:05:54,493]   >> epcoh 0, threshold 0.3641, accuracy 0.0588, precision 0.0588, recall 1.0000, f1 0.1111, best_f1 0.1111
[2019-02-24 18:05:54,494]   >> epcoh 0, threshold 0.3744, accuracy 0.0588, precision 0.0588, recall 1.0000, f1 0.1111, best_f1 0.1111
[2019-02-24 18:05:54,495]   >> epcoh 0, threshold 0.3846, accuracy 0.0588, precision 0.0588, recall 1.0000, f1 0.1111, best_f1 0.1111
[2019-02-24 18:05:54,496]   >> epcoh 0, threshold 0.3949, accuracy 0.0588, precision 0.0588, recall 1.0000, f1 0.1111, best_f1 0.1111
[2019-02-24 18:05:54,497]   >> epcoh 0, threshold 0.4051, accuracy 0.0588, precision 0.0588, recall 1.0000, f1 0.1111, best_f1 0.1111
[2019-02-24 18:05:54,498]   >> epcoh 0, threshold 0.4154, accuracy 0.0588, precision 0.0588, recall 1.0000, f1 0.1111, best_f1 0.1111
[2019-02-24 18:05:54,499]   >> epcoh 0, threshold 0.4256, accuracy 0.0588, precision 0.0588, recall 1.0000, f1 0.1111, best_f1 0.1111
[2019-02-24 18:05:54,500]   >> epcoh 0, threshold 0.4359, accuracy 0.0588, precision 0.0588, recall 1.0000, f1 0.1111, best_f1 0.1111
[2019-02-24 18:05:54,501]   >> epcoh 0, threshold 0.4462, accuracy 0.0588, precision 0.0588, recall 1.0000, f1 0.1111, best_f1 0.1111
[2019-02-24 18:05:54,922]   >> epcoh 0, threshold 0.4564, accuracy 0.1176, precision 0.0625, recall 1.0000, f1 0.1176, best_f1 0.1176
[2019-02-24 18:05:55,294]   >> epcoh 0, threshold 0.4667, accuracy 0.2353, precision 0.0714, recall 1.0000, f1 0.1333, best_f1 0.1333
[2019-02-24 18:05:55,812]   >> epcoh 0, threshold 0.4769, accuracy 0.5882, precision 0.1250, recall 1.0000, f1 0.2222, best_f1 0.2222
[2019-02-24 18:05:55,813]   >> epcoh 0, threshold 0.4872, accuracy 0.8824, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2222
[2019-02-24 18:05:55,814]   >> epcoh 0, threshold 0.4974, accuracy 0.8824, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2222
[2019-02-24 18:05:55,816]   >> epcoh 0, threshold 0.5077, accuracy 0.9412, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2222
[2019-02-24 18:05:55,817]   >> epcoh 0, threshold 0.5179, accuracy 0.9412, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2222
[2019-02-24 18:05:55,818]   >> epcoh 0, threshold 0.5282, accuracy 0.9412, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2222
[2019-02-24 18:05:55,819]   >> epcoh 0, threshold 0.5385, accuracy 0.9412, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2222
[2019-02-24 18:05:55,819]   >> epcoh 0, threshold 0.5487, accuracy 0.9412, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2222
[2019-02-24 18:05:55,820]   >> epcoh 0, threshold 0.5590, accuracy 0.9412, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2222
[2019-02-24 18:05:55,821]   >> epcoh 0, threshold 0.5692, accuracy 0.9412, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2222
[2019-02-24 18:05:55,822]   >> epcoh 0, threshold 0.5795, accuracy 0.9412, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2222
[2019-02-24 18:05:55,823]   >> epcoh 0, threshold 0.5897, accuracy 0.9412, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2222
[2019-02-24 18:05:55,824]   >> epcoh 0, threshold 0.6000, accuracy 0.9412, precision 0.0000, recall 0.0000, f1 0.0000, best_f1 0.2222
[2019-02-24 18:05:55,839]   >> ***** Running training *****
[2019-02-24 18:05:55,839]   >>   Num examples = 101
[2019-02-24 18:05:55,839]   >>   Batch size = 64
[2019-02-24 18:05:55,839]   >>   Num steps = 4
[2019-02-24 18:05:56,690]   >> epcoh 1, threshold 0.2000, accuracy 0.0588, precision 0.0588, recall 1.0000, f1 0.1111, best_f1 0.1111
[2019-02-24 18:05:56,692]   >> epcoh 1, threshold 0.2103, accuracy 0.0588, precision 0.0588, recall 1.0000, f1 0.1111, best_f1 0.1111
[2019-02-24 18:05:56,694]   >> epcoh 1, threshold 0.2205, accuracy 0.0588, precision 0.0588, recall 1.0000, f1 0.1111, best_f1 0.1111
[2019-02-24 18:05:56,695]   >> epcoh 1, threshold 0.2308, accuracy 0.0588, precision 0.0588, recall 1.0000, f1 0.1111, best_f1 0.1111
[2019-02-24 18:05:56,697]   >> epcoh 1, threshold 0.2410, accuracy 0.0588, precision 0.0588, recall 1.0000, f1 0.1111, best_f1 0.1111
[2019-02-24 18:05:56,698]   >> epcoh 1, threshold 0.2513, accuracy 0.0588, precision 0.0588, recall 1.0000, f1 0.1111, best_f1 0.1111
[2019-02-24 18:05:56,699]   >> epcoh 1, threshold 0.2615, accuracy 0.0588, precision 0.0588, recall 1.0000, f1 0.1111, best_f1 0.1111
[2019-02-24 18:05:56,701]   >> epcoh 1, threshold 0.2718, accuracy 0.0588, precision 0.0588, recall 1.0000, f1 0.1111, best_f1 0.1111
[2019-02-24 18:05:56,702]   >> epcoh 1, threshold 0.2821, accuracy 0.0588, precision 0.0588, recall 1.0000, f1 0.1111, best_f1 0.1111
[2019-02-24 18:05:56,703]   >> epcoh 1, threshold 0.2923, accuracy 0.0588, precision 0.0588, recall 1.0000, f1 0.1111, best_f1 0.1111
[2019-02-24 18:05:56,704]   >> epcoh 1, threshold 0.3026, accuracy 0.0588, precision 0.0588, recall 1.0000, f1 0.1111, best_f1 0.1111
[2019-02-24 18:05:56,705]   >> epcoh 1, threshold 0.3128, accuracy 0.0588, precision 0.0588, recall 1.0000, f1 0.1111, best_f1 0.1111
[2019-02-24 18:05:56,706]   >> epcoh 1, threshold 0.3231, accuracy 0.0588, precision 0.0588, recall 1.0000, f1 0.1111, best_f1 0.1111
[2019-02-24 18:05:56,707]   >> epcoh 1, threshold 0.3333, accuracy 0.0588, precision 0.0588, recall 1.0000, f1 0.1111, best_f1 0.1111
[2019-02-24 18:05:57,102]   >> epcoh 1, threshold 0.3436, accuracy 0.1176, precision 0.0625, recall 1.0000, f1 0.1176, best_f1 0.1176
[2019-02-24 18:05:57,611]   >> epcoh 1, threshold 0.3538, accuracy 0.2353, precision 0.0714, recall 1.0000, f1 0.1333, best_f1 0.1333
[2019-02-24 18:05:57,613]   >> epcoh 1, threshold 0.3641, accuracy 0.2353, precision 0.0714, recall 1.0000, f1 0.1333, best_f1 0.1333
[2019-02-24 18:06:30,062]   >> device: cuda n_gpu: 1, distributed training: False, 16-bits training: False
[2019-02-24 18:06:30,078]   >> LOOKING AT /home/panxie/Document/kaggle/quora/data/splited_data/train.csv
[2019-02-24 18:08:10,058]   >> ***** Running evaluation *****
[2019-02-24 18:08:10,058]   >>   Num examples = 261225
[2019-02-24 18:08:10,058]   >>   Batch size = 8
[2019-02-24 18:10:43,352]   >> ***** Running training *****
[2019-02-24 18:10:43,352]   >>   Num examples = 1044897
[2019-02-24 18:10:43,353]   >>   Batch size = 64
[2019-02-24 18:10:43,353]   >>   Num steps = 48979
[2019-02-24 18:11:57,207]   >> |----epoch 0, eclipse 300/16327, lr 0.0000,loss 0.4544, acc 0.6164
[2019-02-24 18:13:10,045]   >> |----epoch 0, eclipse 600/16327, lr 0.0000,loss 0.3019, acc 0.9314
[2019-02-24 18:14:22,982]   >> |----epoch 0, eclipse 900/16327, lr 0.0000,loss 0.1908, acc 0.9371
[2019-02-24 18:15:35,954]   >> |----epoch 0, eclipse 1200/16327, lr 0.0000,loss 0.1373, acc 0.9479
[2019-02-24 18:16:48,940]   >> |----epoch 0, eclipse 1500/16327, lr 0.0000,loss 0.1224, acc 0.9486
[2019-02-24 18:18:01,958]   >> |----epoch 0, eclipse 1800/16327, lr 0.0000,loss 0.1142, acc 0.9518
[2019-02-24 18:19:14,986]   >> |----epoch 0, eclipse 2100/16327, lr 0.0000,loss 0.1123, acc 0.9518
[2019-02-24 18:20:28,007]   >> |----epoch 0, eclipse 2400/16327, lr 0.0000,loss 0.1106, acc 0.9525
[2019-02-24 18:21:41,064]   >> |----epoch 0, eclipse 2700/16327, lr 0.0000,loss 0.1073, acc 0.9543
[2019-02-24 18:22:54,132]   >> |----epoch 0, eclipse 3000/16327, lr 0.0000,loss 0.1138, acc 0.9531
[2019-02-24 18:24:07,214]   >> |----epoch 0, eclipse 3300/16327, lr 0.0000,loss 0.1151, acc 0.9514
[2019-02-24 18:25:20,313]   >> |----epoch 0, eclipse 3600/16327, lr 0.0000,loss 0.1129, acc 0.9522
[2019-02-24 18:26:33,433]   >> |----epoch 0, eclipse 3900/16327, lr 0.0000,loss 0.1053, acc 0.9528
[2019-02-24 18:27:46,604]   >> |----epoch 0, eclipse 4200/16327, lr 0.0000,loss 0.1081, acc 0.9547
[2019-02-24 18:28:59,768]   >> |----epoch 0, eclipse 4500/16327, lr 0.0000,loss 0.1064, acc 0.9526
[2019-02-24 18:30:12,948]   >> |----epoch 0, eclipse 4800/16327, lr 0.0000,loss 0.1100, acc 0.9543
[2019-02-24 18:31:26,134]   >> |----epoch 0, eclipse 5100/16327, lr 0.0000,loss 0.1032, acc 0.9558
[2019-02-24 18:32:39,331]   >> |----epoch 0, eclipse 5400/16327, lr 0.0000,loss 0.1086, acc 0.9532
[2019-02-24 18:33:52,515]   >> |----epoch 0, eclipse 5700/16327, lr 0.0000,loss 0.1000, acc 0.9568
[2019-02-24 18:35:05,706]   >> |----epoch 0, eclipse 6000/16327, lr 0.0000,loss 0.1058, acc 0.9556
[2019-02-24 18:36:18,894]   >> |----epoch 0, eclipse 6300/16327, lr 0.0000,loss 0.1013, acc 0.9580
[2019-02-24 18:37:32,085]   >> |----epoch 0, eclipse 6600/16327, lr 0.0000,loss 0.1003, acc 0.9578
[2019-02-24 18:38:45,275]   >> |----epoch 0, eclipse 6900/16327, lr 0.0000,loss 0.0984, acc 0.9591
[2019-02-24 18:39:58,474]   >> |----epoch 0, eclipse 7200/16327, lr 0.0000,loss 0.0959, acc 0.9598
[2019-02-24 18:41:11,699]   >> |----epoch 0, eclipse 7500/16327, lr 0.0000,loss 0.0991, acc 0.9581
[2019-02-24 18:42:24,997]   >> |----epoch 0, eclipse 7800/16327, lr 0.0000,loss 0.1031, acc 0.9564
[2019-02-24 18:43:38,207]   >> |----epoch 0, eclipse 8100/16327, lr 0.0000,loss 0.1011, acc 0.9570
[2019-02-24 18:44:51,417]   >> |----epoch 0, eclipse 8400/16327, lr 0.0000,loss 0.1006, acc 0.9582
[2019-02-24 18:46:04,625]   >> |----epoch 0, eclipse 8700/16327, lr 0.0000,loss 0.0958, acc 0.9590
[2019-02-24 18:47:17,829]   >> |----epoch 0, eclipse 9000/16327, lr 0.0000,loss 0.1002, acc 0.9567
[2019-02-24 18:48:31,020]   >> |----epoch 0, eclipse 9300/16327, lr 0.0000,loss 0.0952, acc 0.9590
[2019-02-24 18:49:44,225]   >> |----epoch 0, eclipse 9600/16327, lr 0.0000,loss 0.0988, acc 0.9563
[2019-02-24 18:50:57,417]   >> |----epoch 0, eclipse 9900/16327, lr 0.0000,loss 0.1005, acc 0.9585
[2019-02-24 18:52:10,618]   >> |----epoch 0, eclipse 10200/16327, lr 0.0000,loss 0.0973, acc 0.9596
[2019-02-24 18:53:23,822]   >> |----epoch 0, eclipse 10500/16327, lr 0.0000,loss 0.1046, acc 0.9565
[2019-02-24 18:54:37,027]   >> |----epoch 0, eclipse 10800/16327, lr 0.0000,loss 0.0963, acc 0.9583
[2019-02-24 18:55:50,245]   >> |----epoch 0, eclipse 11100/16327, lr 0.0000,loss 0.0995, acc 0.9587
[2019-02-24 18:57:03,524]   >> |----epoch 0, eclipse 11400/16327, lr 0.0000,loss 0.1002, acc 0.9553
[2019-02-24 18:58:16,894]   >> |----epoch 0, eclipse 11700/16327, lr 0.0000,loss 0.0961, acc 0.9593
[2019-02-24 18:59:30,272]   >> |----epoch 0, eclipse 12000/16327, lr 0.0000,loss 0.0991, acc 0.9591
[2019-02-24 19:00:43,641]   >> |----epoch 0, eclipse 12300/16327, lr 0.0000,loss 0.0986, acc 0.9582
[2019-02-24 19:01:57,003]   >> |----epoch 0, eclipse 12600/16327, lr 0.0000,loss 0.0952, acc 0.9590
[2019-02-24 19:03:10,363]   >> |----epoch 0, eclipse 12900/16327, lr 0.0000,loss 0.0953, acc 0.9603
[2019-02-24 19:04:23,739]   >> |----epoch 0, eclipse 13200/16327, lr 0.0000,loss 0.0931, acc 0.9607
[2019-02-24 19:05:37,105]   >> |----epoch 0, eclipse 13500/16327, lr 0.0000,loss 0.0959, acc 0.9583
[2019-02-24 19:06:50,465]   >> |----epoch 0, eclipse 13800/16327, lr 0.0000,loss 0.0946, acc 0.9595
[2019-02-24 19:08:03,833]   >> |----epoch 0, eclipse 14100/16327, lr 0.0000,loss 0.0894, acc 0.9622
[2019-02-24 19:09:17,195]   >> |----epoch 0, eclipse 14400/16327, lr 0.0000,loss 0.0954, acc 0.9588
[2019-02-24 19:10:30,556]   >> |----epoch 0, eclipse 14700/16327, lr 0.0000,loss 0.0962, acc 0.9572
[2019-02-24 19:11:43,925]   >> |----epoch 0, eclipse 15000/16327, lr 0.0000,loss 0.0972, acc 0.9572
[2019-02-24 19:12:57,292]   >> |----epoch 0, eclipse 15300/16327, lr 0.0000,loss 0.0952, acc 0.9587
[2019-02-24 19:14:10,664]   >> |----epoch 0, eclipse 15600/16327, lr 0.0000,loss 0.0920, acc 0.9607
[2019-02-24 19:15:24,034]   >> |----epoch 0, eclipse 15900/16327, lr 0.0000,loss 0.0919, acc 0.9617
[2019-02-24 19:16:37,404]   >> |----epoch 0, eclipse 16200/16327, lr 0.0000,loss 0.0980, acc 0.9570
[2019-02-24 19:23:21,620]   >> epcoh 0, threshold 0.2000, accuracy 0.9523, precision 0.5805, recall 0.8350, f1 0.6849, best_f1 0.6849
[2019-02-24 19:23:22,114]   >> epcoh 0, threshold 0.2103, accuracy 0.9532, precision 0.5871, recall 0.8284, f1 0.6872, best_f1 0.6872
[2019-02-24 19:23:22,444]   >> epcoh 0, threshold 0.2205, accuracy 0.9541, precision 0.5939, recall 0.8224, f1 0.6897, best_f1 0.6897
[2019-02-24 19:23:22,937]   >> epcoh 0, threshold 0.2308, accuracy 0.9550, precision 0.6007, recall 0.8173, f1 0.6925, best_f1 0.6925
[2019-02-24 19:23:23,429]   >> epcoh 0, threshold 0.2410, accuracy 0.9557, precision 0.6070, recall 0.8108, f1 0.6942, best_f1 0.6942
[2019-02-24 19:23:23,924]   >> epcoh 0, threshold 0.2513, accuracy 0.9563, precision 0.6125, recall 0.8046, f1 0.6955, best_f1 0.6955
[2019-02-24 19:23:24,498]   >> epcoh 0, threshold 0.2615, accuracy 0.9569, precision 0.6184, recall 0.7983, f1 0.6969, best_f1 0.6969
[2019-02-24 19:23:24,906]   >> epcoh 0, threshold 0.2718, accuracy 0.9575, precision 0.6244, recall 0.7921, f1 0.6983, best_f1 0.6983
[2019-02-24 19:23:25,398]   >> epcoh 0, threshold 0.2821, accuracy 0.9581, precision 0.6307, recall 0.7856, f1 0.6997, best_f1 0.6997
[2019-02-24 19:23:25,892]   >> epcoh 0, threshold 0.2923, accuracy 0.9587, precision 0.6367, recall 0.7797, f1 0.7010, best_f1 0.7010
[2019-02-24 19:23:26,776]   >> epcoh 0, threshold 0.3026, accuracy 0.9592, precision 0.6426, recall 0.7732, f1 0.7019, best_f1 0.7019
[2019-02-24 19:23:29,270]   >> epcoh 0, threshold 0.3128, accuracy 0.9597, precision 0.6484, recall 0.7665, f1 0.7025, best_f1 0.7025
[2019-02-24 19:23:30,738]   >> epcoh 0, threshold 0.3231, accuracy 0.9602, precision 0.6550, recall 0.7593, f1 0.7033, best_f1 0.7033
[2019-02-24 19:23:32,209]   >> epcoh 0, threshold 0.3333, accuracy 0.9606, precision 0.6607, recall 0.7521, f1 0.7034, best_f1 0.7034
[2019-02-24 19:23:32,277]   >> epcoh 0, threshold 0.3436, accuracy 0.9610, precision 0.6661, recall 0.7449, f1 0.7033, best_f1 0.7034
[2019-02-24 19:23:32,344]   >> epcoh 0, threshold 0.3538, accuracy 0.9613, precision 0.6715, recall 0.7378, f1 0.7031, best_f1 0.7034
[2019-02-24 19:23:32,410]   >> epcoh 0, threshold 0.3641, accuracy 0.9616, precision 0.6767, recall 0.7299, f1 0.7023, best_f1 0.7034
[2019-02-24 19:23:32,477]   >> epcoh 0, threshold 0.3744, accuracy 0.9618, precision 0.6816, recall 0.7223, f1 0.7014, best_f1 0.7034
[2019-02-24 19:23:32,544]   >> epcoh 0, threshold 0.3846, accuracy 0.9620, precision 0.6862, recall 0.7146, f1 0.7001, best_f1 0.7034
[2019-02-24 19:23:32,609]   >> epcoh 0, threshold 0.3949, accuracy 0.9622, precision 0.6910, recall 0.7065, f1 0.6987, best_f1 0.7034
[2019-02-24 19:23:32,676]   >> epcoh 0, threshold 0.4051, accuracy 0.9625, precision 0.6978, recall 0.6981, f1 0.6980, best_f1 0.7034
[2019-02-24 19:23:32,742]   >> epcoh 0, threshold 0.4154, accuracy 0.9627, precision 0.7031, recall 0.6898, f1 0.6964, best_f1 0.7034
[2019-02-24 19:23:32,809]   >> epcoh 0, threshold 0.4256, accuracy 0.9628, precision 0.7081, recall 0.6808, f1 0.6942, best_f1 0.7034
[2019-02-24 19:23:32,875]   >> epcoh 0, threshold 0.4359, accuracy 0.9629, precision 0.7137, recall 0.6706, f1 0.6915, best_f1 0.7034
[2019-02-24 19:23:32,940]   >> epcoh 0, threshold 0.4462, accuracy 0.9630, precision 0.7193, recall 0.6624, f1 0.6896, best_f1 0.7034
[2019-02-24 19:23:33,006]   >> epcoh 0, threshold 0.4564, accuracy 0.9631, precision 0.7245, recall 0.6541, f1 0.6875, best_f1 0.7034
[2019-02-24 19:23:33,072]   >> epcoh 0, threshold 0.4667, accuracy 0.9630, precision 0.7290, recall 0.6434, f1 0.6836, best_f1 0.7034
[2019-02-24 19:23:33,137]   >> epcoh 0, threshold 0.4769, accuracy 0.9631, precision 0.7346, recall 0.6345, f1 0.6809, best_f1 0.7034
[2019-02-24 19:23:33,203]   >> epcoh 0, threshold 0.4872, accuracy 0.9631, precision 0.7399, recall 0.6253, f1 0.6778, best_f1 0.7034
[2019-02-24 19:23:33,268]   >> epcoh 0, threshold 0.4974, accuracy 0.9629, precision 0.7442, recall 0.6137, f1 0.6727, best_f1 0.7034
[2019-02-24 19:23:33,334]   >> epcoh 0, threshold 0.5077, accuracy 0.9628, precision 0.7493, recall 0.6013, f1 0.6672, best_f1 0.7034
[2019-02-24 19:23:33,399]   >> epcoh 0, threshold 0.5179, accuracy 0.9625, precision 0.7535, recall 0.5883, f1 0.6608, best_f1 0.7034
[2019-02-24 19:23:33,464]   >> epcoh 0, threshold 0.5282, accuracy 0.9624, precision 0.7592, recall 0.5764, f1 0.6553, best_f1 0.7034
[2019-02-24 19:23:33,530]   >> epcoh 0, threshold 0.5385, accuracy 0.9622, precision 0.7651, recall 0.5633, f1 0.6489, best_f1 0.7034
[2019-02-24 19:23:33,595]   >> epcoh 0, threshold 0.5487, accuracy 0.9619, precision 0.7707, recall 0.5494, f1 0.6415, best_f1 0.7034
[2019-02-24 19:23:33,661]   >> epcoh 0, threshold 0.5590, accuracy 0.9617, precision 0.7783, recall 0.5343, f1 0.6336, best_f1 0.7034
[2019-02-24 19:23:33,725]   >> epcoh 0, threshold 0.5692, accuracy 0.9614, precision 0.7852, recall 0.5195, f1 0.6253, best_f1 0.7034
[2019-02-24 19:23:33,790]   >> epcoh 0, threshold 0.5795, accuracy 0.9609, precision 0.7905, recall 0.5025, f1 0.6144, best_f1 0.7034
[2019-02-24 19:23:33,855]   >> epcoh 0, threshold 0.5897, accuracy 0.9603, precision 0.7968, recall 0.4837, f1 0.6020, best_f1 0.7034
[2019-02-24 19:23:33,919]   >> epcoh 0, threshold 0.6000, accuracy 0.9597, precision 0.8033, recall 0.4648, f1 0.5888, best_f1 0.7034
[2019-02-24 19:25:57,586]   >> ***** Running training *****
[2019-02-24 19:25:57,586]   >>   Num examples = 1044897
[2019-02-24 19:25:57,586]   >>   Batch size = 64
[2019-02-24 19:25:57,586]   >>   Num steps = 48979
[2019-02-24 19:27:11,541]   >> |----epoch 1, eclipse 300/16327, lr 0.0000,loss 0.0794, acc 0.9673
[2019-02-24 19:28:24,646]   >> |----epoch 1, eclipse 600/16327, lr 0.0000,loss 0.0752, acc 0.9663
[2019-02-24 19:29:37,857]   >> |----epoch 1, eclipse 900/16327, lr 0.0000,loss 0.0729, acc 0.9693
[2019-02-24 19:30:51,095]   >> |----epoch 1, eclipse 1200/16327, lr 0.0000,loss 0.0709, acc 0.9695
[2019-02-24 19:32:04,349]   >> |----epoch 1, eclipse 1500/16327, lr 0.0000,loss 0.0724, acc 0.9694
[2019-02-24 19:33:17,604]   >> |----epoch 1, eclipse 1800/16327, lr 0.0000,loss 0.0719, acc 0.9695
[2019-02-24 19:34:30,845]   >> |----epoch 1, eclipse 2100/16327, lr 0.0000,loss 0.0750, acc 0.9689
[2019-02-24 19:35:44,085]   >> |----epoch 1, eclipse 2400/16327, lr 0.0000,loss 0.0732, acc 0.9691
[2019-02-24 19:36:57,328]   >> |----epoch 1, eclipse 2700/16327, lr 0.0000,loss 0.0741, acc 0.9694
[2019-02-24 19:38:10,582]   >> |----epoch 1, eclipse 3000/16327, lr 0.0000,loss 0.0646, acc 0.9739
[2019-02-24 19:39:23,831]   >> |----epoch 1, eclipse 3300/16327, lr 0.0000,loss 0.0719, acc 0.9697
[2019-02-24 19:40:37,084]   >> |----epoch 1, eclipse 3600/16327, lr 0.0000,loss 0.0736, acc 0.9694
[2019-02-24 19:41:50,340]   >> |----epoch 1, eclipse 3900/16327, lr 0.0000,loss 0.0746, acc 0.9694
[2019-02-24 19:43:03,611]   >> |----epoch 1, eclipse 4200/16327, lr 0.0000,loss 0.0717, acc 0.9697
[2019-02-24 19:44:16,880]   >> |----epoch 1, eclipse 4500/16327, lr 0.0000,loss 0.0755, acc 0.9684
[2019-02-24 19:45:30,136]   >> |----epoch 1, eclipse 4800/16327, lr 0.0000,loss 0.0752, acc 0.9658
[2019-02-24 19:46:43,371]   >> |----epoch 1, eclipse 5100/16327, lr 0.0000,loss 0.0728, acc 0.9688
[2019-02-24 19:47:56,628]   >> |----epoch 1, eclipse 5400/16327, lr 0.0000,loss 0.0739, acc 0.9693
[2019-02-24 19:49:09,873]   >> |----epoch 1, eclipse 5700/16327, lr 0.0000,loss 0.0745, acc 0.9682
[2019-02-24 19:50:23,123]   >> |----epoch 1, eclipse 6000/16327, lr 0.0000,loss 0.0747, acc 0.9670
[2019-02-24 19:51:36,369]   >> |----epoch 1, eclipse 6300/16327, lr 0.0000,loss 0.0749, acc 0.9692
[2019-02-24 19:52:49,626]   >> |----epoch 1, eclipse 6600/16327, lr 0.0000,loss 0.0824, acc 0.9651
[2019-02-24 19:54:02,889]   >> |----epoch 1, eclipse 6900/16327, lr 0.0000,loss 0.0731, acc 0.9698
[2019-02-24 19:55:16,293]   >> |----epoch 1, eclipse 7200/16327, lr 0.0000,loss 0.0775, acc 0.9682
[2019-02-24 19:56:29,701]   >> |----epoch 1, eclipse 7500/16327, lr 0.0000,loss 0.0766, acc 0.9676
[2019-02-24 19:57:43,087]   >> |----epoch 1, eclipse 7800/16327, lr 0.0000,loss 0.0746, acc 0.9672
[2019-02-24 19:58:56,491]   >> |----epoch 1, eclipse 8100/16327, lr 0.0000,loss 0.0765, acc 0.9670
[2019-02-24 20:00:09,879]   >> |----epoch 1, eclipse 8400/16327, lr 0.0000,loss 0.0807, acc 0.9652
[2019-02-24 20:01:23,267]   >> |----epoch 1, eclipse 8700/16327, lr 0.0000,loss 0.0758, acc 0.9672
[2019-02-24 20:02:36,656]   >> |----epoch 1, eclipse 9000/16327, lr 0.0000,loss 0.0749, acc 0.9677
[2019-02-24 20:03:50,043]   >> |----epoch 1, eclipse 9300/16327, lr 0.0000,loss 0.0742, acc 0.9683
[2019-02-24 20:05:03,432]   >> |----epoch 1, eclipse 9600/16327, lr 0.0000,loss 0.0755, acc 0.9688
[2019-02-24 20:06:16,832]   >> |----epoch 1, eclipse 9900/16327, lr 0.0000,loss 0.0754, acc 0.9683
[2019-02-24 20:07:30,232]   >> |----epoch 1, eclipse 10200/16327, lr 0.0000,loss 0.0792, acc 0.9677
[2019-02-24 20:08:43,631]   >> |----epoch 1, eclipse 10500/16327, lr 0.0000,loss 0.0763, acc 0.9672
[2019-02-24 20:09:57,035]   >> |----epoch 1, eclipse 10800/16327, lr 0.0000,loss 0.0753, acc 0.9693
[2019-02-24 20:11:10,444]   >> |----epoch 1, eclipse 11100/16327, lr 0.0000,loss 0.0729, acc 0.9683
[2019-02-24 20:12:23,845]   >> |----epoch 1, eclipse 11400/16327, lr 0.0000,loss 0.0784, acc 0.9669
[2019-02-24 20:13:37,235]   >> |----epoch 1, eclipse 11700/16327, lr 0.0000,loss 0.0695, acc 0.9698
[2019-02-24 20:14:50,615]   >> |----epoch 1, eclipse 12000/16327, lr 0.0000,loss 0.0768, acc 0.9682
[2019-02-24 20:16:03,985]   >> |----epoch 1, eclipse 12300/16327, lr 0.0000,loss 0.0766, acc 0.9680
[2019-02-24 20:17:17,362]   >> |----epoch 1, eclipse 12600/16327, lr 0.0000,loss 0.0770, acc 0.9681
[2019-02-24 20:18:30,736]   >> |----epoch 1, eclipse 12900/16327, lr 0.0000,loss 0.0742, acc 0.9687
[2019-02-24 20:19:44,114]   >> |----epoch 1, eclipse 13200/16327, lr 0.0000,loss 0.0720, acc 0.9709
[2019-02-24 20:20:57,502]   >> |----epoch 1, eclipse 13500/16327, lr 0.0000,loss 0.0731, acc 0.9691
[2019-02-24 20:22:10,896]   >> |----epoch 1, eclipse 13800/16327, lr 0.0000,loss 0.0738, acc 0.9686
[2019-02-24 20:23:24,317]   >> |----epoch 1, eclipse 14100/16327, lr 0.0000,loss 0.0745, acc 0.9686
[2019-02-24 20:24:37,736]   >> |----epoch 1, eclipse 14400/16327, lr 0.0000,loss 0.0792, acc 0.9674
[2019-02-24 20:25:51,153]   >> |----epoch 1, eclipse 14700/16327, lr 0.0000,loss 0.0751, acc 0.9678
[2019-02-24 20:27:04,560]   >> |----epoch 1, eclipse 15000/16327, lr 0.0000,loss 0.0737, acc 0.9670
[2019-02-24 20:28:17,966]   >> |----epoch 1, eclipse 15300/16327, lr 0.0000,loss 0.0751, acc 0.9678
[2019-02-24 20:29:31,374]   >> |----epoch 1, eclipse 15600/16327, lr 0.0000,loss 0.0750, acc 0.9691
[2019-02-24 20:30:44,783]   >> |----epoch 1, eclipse 15900/16327, lr 0.0000,loss 0.0732, acc 0.9696
[2019-02-24 20:31:58,186]   >> |----epoch 1, eclipse 16200/16327, lr 0.0000,loss 0.0704, acc 0.9703
[2019-02-24 20:38:44,687]   >> epcoh 1, threshold 0.2000, accuracy 0.9595, precision 0.6423, recall 0.7851, f1 0.7066, best_f1 0.7066
[2019-02-24 20:38:45,162]   >> epcoh 1, threshold 0.2103, accuracy 0.9600, precision 0.6477, recall 0.7802, f1 0.7078, best_f1 0.7078
[2019-02-24 20:38:45,533]   >> epcoh 1, threshold 0.2205, accuracy 0.9604, precision 0.6523, recall 0.7748, f1 0.7083, best_f1 0.7083
[2019-02-24 20:38:46,033]   >> epcoh 1, threshold 0.2308, accuracy 0.9607, precision 0.6569, recall 0.7690, f1 0.7086, best_f1 0.7086
[2019-02-24 20:38:46,107]   >> epcoh 1, threshold 0.2410, accuracy 0.9610, precision 0.6613, recall 0.7631, f1 0.7086, best_f1 0.7086
[2019-02-24 20:38:46,526]   >> epcoh 1, threshold 0.2513, accuracy 0.9614, precision 0.6658, recall 0.7582, f1 0.7090, best_f1 0.7090
[2019-02-24 20:38:46,599]   >> epcoh 1, threshold 0.2615, accuracy 0.9616, precision 0.6697, recall 0.7519, f1 0.7084, best_f1 0.7090
[2019-02-24 20:38:46,672]   >> epcoh 1, threshold 0.2718, accuracy 0.9618, precision 0.6738, recall 0.7460, f1 0.7081, best_f1 0.7090
[2019-02-24 20:38:46,746]   >> epcoh 1, threshold 0.2821, accuracy 0.9620, precision 0.6775, recall 0.7400, f1 0.7073, best_f1 0.7090
[2019-02-24 20:38:46,817]   >> epcoh 1, threshold 0.2923, accuracy 0.9622, precision 0.6815, recall 0.7339, f1 0.7067, best_f1 0.7090
[2019-02-24 20:38:46,886]   >> epcoh 1, threshold 0.3026, accuracy 0.9624, precision 0.6851, recall 0.7283, f1 0.7060, best_f1 0.7090
[2019-02-24 20:38:46,954]   >> epcoh 1, threshold 0.3128, accuracy 0.9625, precision 0.6886, recall 0.7237, f1 0.7057, best_f1 0.7090
[2019-02-24 20:38:47,023]   >> epcoh 1, threshold 0.3231, accuracy 0.9627, precision 0.6922, recall 0.7180, f1 0.7049, best_f1 0.7090
[2019-02-24 20:38:47,090]   >> epcoh 1, threshold 0.3333, accuracy 0.9629, precision 0.6965, recall 0.7139, f1 0.7051, best_f1 0.7090
[2019-02-24 20:38:47,155]   >> epcoh 1, threshold 0.3436, accuracy 0.9630, precision 0.6992, recall 0.7083, f1 0.7037, best_f1 0.7090
[2019-02-24 20:38:47,222]   >> epcoh 1, threshold 0.3538, accuracy 0.9631, precision 0.7029, recall 0.7032, f1 0.7030, best_f1 0.7090
[2019-02-24 20:38:47,288]   >> epcoh 1, threshold 0.3641, accuracy 0.9633, precision 0.7071, recall 0.6983, f1 0.7027, best_f1 0.7090
[2019-02-24 20:38:47,355]   >> epcoh 1, threshold 0.3744, accuracy 0.9633, precision 0.7099, recall 0.6911, f1 0.7004, best_f1 0.7090
[2019-02-24 20:38:47,421]   >> epcoh 1, threshold 0.3846, accuracy 0.9634, precision 0.7132, recall 0.6849, f1 0.6988, best_f1 0.7090
[2019-02-24 20:38:47,487]   >> epcoh 1, threshold 0.3949, accuracy 0.9633, precision 0.7151, recall 0.6785, f1 0.6963, best_f1 0.7090
[2019-02-24 20:38:47,553]   >> epcoh 1, threshold 0.4051, accuracy 0.9634, precision 0.7182, recall 0.6740, f1 0.6954, best_f1 0.7090
[2019-02-24 20:38:47,620]   >> epcoh 1, threshold 0.4154, accuracy 0.9634, precision 0.7214, recall 0.6685, f1 0.6939, best_f1 0.7090
[2019-02-24 20:38:47,686]   >> epcoh 1, threshold 0.4256, accuracy 0.9634, precision 0.7246, recall 0.6627, f1 0.6923, best_f1 0.7090
[2019-02-24 20:38:47,752]   >> epcoh 1, threshold 0.4359, accuracy 0.9634, precision 0.7275, recall 0.6569, f1 0.6904, best_f1 0.7090
[2019-02-24 20:38:47,817]   >> epcoh 1, threshold 0.4462, accuracy 0.9634, precision 0.7296, recall 0.6521, f1 0.6887, best_f1 0.7090
[2019-02-24 20:38:47,883]   >> epcoh 1, threshold 0.4564, accuracy 0.9635, precision 0.7329, recall 0.6473, f1 0.6874, best_f1 0.7090
[2019-02-24 20:38:47,949]   >> epcoh 1, threshold 0.4667, accuracy 0.9635, precision 0.7357, recall 0.6419, f1 0.6856, best_f1 0.7090
[2019-02-24 20:38:48,014]   >> epcoh 1, threshold 0.4769, accuracy 0.9635, precision 0.7389, recall 0.6379, f1 0.6847, best_f1 0.7090
[2019-02-24 20:38:48,080]   >> epcoh 1, threshold 0.4872, accuracy 0.9635, precision 0.7420, recall 0.6319, f1 0.6825, best_f1 0.7090
[2019-02-24 20:38:48,146]   >> epcoh 1, threshold 0.4974, accuracy 0.9635, precision 0.7447, recall 0.6264, f1 0.6804, best_f1 0.7090
[2019-02-24 20:38:48,212]   >> epcoh 1, threshold 0.5077, accuracy 0.9634, precision 0.7473, recall 0.6202, f1 0.6778, best_f1 0.7090
[2019-02-24 20:38:48,277]   >> epcoh 1, threshold 0.5179, accuracy 0.9634, precision 0.7503, recall 0.6143, f1 0.6755, best_f1 0.7090
[2019-02-24 20:38:48,343]   >> epcoh 1, threshold 0.5282, accuracy 0.9633, precision 0.7536, recall 0.6078, f1 0.6729, best_f1 0.7090
[2019-02-24 20:38:48,409]   >> epcoh 1, threshold 0.5385, accuracy 0.9633, precision 0.7561, recall 0.6023, f1 0.6705, best_f1 0.7090
[2019-02-24 20:38:48,474]   >> epcoh 1, threshold 0.5487, accuracy 0.9632, precision 0.7589, recall 0.5957, f1 0.6675, best_f1 0.7090
[2019-02-24 20:38:48,540]   >> epcoh 1, threshold 0.5590, accuracy 0.9630, precision 0.7606, recall 0.5898, f1 0.6644, best_f1 0.7090
[2019-02-24 20:38:48,605]   >> epcoh 1, threshold 0.5692, accuracy 0.9629, precision 0.7628, recall 0.5825, f1 0.6606, best_f1 0.7090
[2019-02-24 20:38:48,671]   >> epcoh 1, threshold 0.5795, accuracy 0.9627, precision 0.7652, recall 0.5753, f1 0.6568, best_f1 0.7090
[2019-02-24 20:38:48,736]   >> epcoh 1, threshold 0.5897, accuracy 0.9626, precision 0.7680, recall 0.5688, f1 0.6536, best_f1 0.7090
[2019-02-24 20:38:48,801]   >> epcoh 1, threshold 0.6000, accuracy 0.9625, precision 0.7708, recall 0.5622, f1 0.6502, best_f1 0.7090
[2019-02-24 20:41:16,103]   >> ***** Running training *****
[2019-02-24 20:41:16,103]   >>   Num examples = 1044897
[2019-02-24 20:41:16,104]   >>   Batch size = 64
[2019-02-24 20:41:16,104]   >>   Num steps = 48979
[2019-02-24 20:42:30,098]   >> |----epoch 2, eclipse 300/16327, lr 0.0000,loss 0.0566, acc 0.9783
[2019-02-24 20:43:43,172]   >> |----epoch 2, eclipse 600/16327, lr 0.0000,loss 0.0508, acc 0.9795
[2019-02-24 20:44:56,366]   >> |----epoch 2, eclipse 900/16327, lr 0.0000,loss 0.0453, acc 0.9817
[2019-02-24 20:46:09,588]   >> |----epoch 2, eclipse 1200/16327, lr 0.0000,loss 0.0487, acc 0.9810
[2019-02-24 20:47:22,817]   >> |----epoch 2, eclipse 1500/16327, lr 0.0000,loss 0.0471, acc 0.9803
[2019-02-24 20:48:36,052]   >> |----epoch 2, eclipse 1800/16327, lr 0.0000,loss 0.0470, acc 0.9810
[2019-02-24 20:49:49,291]   >> |----epoch 2, eclipse 2100/16327, lr 0.0000,loss 0.0507, acc 0.9800
[2019-02-24 20:51:02,534]   >> |----epoch 2, eclipse 2400/16327, lr 0.0000,loss 0.0490, acc 0.9807
[2019-02-24 20:52:15,788]   >> |----epoch 2, eclipse 2700/16327, lr 0.0000,loss 0.0498, acc 0.9790
[2019-02-24 20:53:29,063]   >> |----epoch 2, eclipse 3000/16327, lr 0.0000,loss 0.0486, acc 0.9815
[2019-02-24 20:54:42,338]   >> |----epoch 2, eclipse 3300/16327, lr 0.0000,loss 0.0476, acc 0.9818
[2019-02-24 20:55:55,604]   >> |----epoch 2, eclipse 3600/16327, lr 0.0000,loss 0.0526, acc 0.9792
[2019-02-24 20:57:08,876]   >> |----epoch 2, eclipse 3900/16327, lr 0.0000,loss 0.0460, acc 0.9820
[2019-02-24 20:58:22,146]   >> |----epoch 2, eclipse 4200/16327, lr 0.0000,loss 0.0476, acc 0.9817
[2019-02-24 20:59:35,408]   >> |----epoch 2, eclipse 4500/16327, lr 0.0000,loss 0.0471, acc 0.9806
[2019-02-24 21:00:48,693]   >> |----epoch 2, eclipse 4800/16327, lr 0.0000,loss 0.0482, acc 0.9809
[2019-02-24 21:02:01,958]   >> |----epoch 2, eclipse 5100/16327, lr 0.0000,loss 0.0465, acc 0.9818
[2019-02-24 21:03:15,229]   >> |----epoch 2, eclipse 5400/16327, lr 0.0000,loss 0.0486, acc 0.9805
[2019-02-24 21:04:28,491]   >> |----epoch 2, eclipse 5700/16327, lr 0.0000,loss 0.0508, acc 0.9796
[2019-02-24 21:05:41,762]   >> |----epoch 2, eclipse 6000/16327, lr 0.0000,loss 0.0502, acc 0.9801
[2019-02-24 21:06:55,029]   >> |----epoch 2, eclipse 6300/16327, lr 0.0000,loss 0.0491, acc 0.9809
[2019-02-24 21:08:08,301]   >> |----epoch 2, eclipse 6600/16327, lr 0.0000,loss 0.0476, acc 0.9820
[2019-02-24 21:10:48,404]   >> device: cuda n_gpu: 1, distributed training: False, 16-bits training: False
[2019-02-24 21:10:48,421]   >> LOOKING AT /home/panxie/Document/kaggle/quora/data/splited_data/train.csv
[2019-02-24 21:12:26,405]   >> ***** Running evaluation *****
[2019-02-24 21:12:26,405]   >>   Num examples = 261225
[2019-02-24 21:12:26,405]   >>   Batch size = 8
[2019-02-24 21:14:50,094]   >> ***** Running training *****
[2019-02-24 21:14:50,094]   >>   Num examples = 1044897
[2019-02-24 21:14:50,094]   >>   Batch size = 64
[2019-02-24 21:14:50,094]   >>   Num steps = 48979
[2019-02-24 21:16:03,995]   >> |----epoch 0, eclipse 300/16327, lr 0.0000,loss 0.4544, acc 0.6164
[2019-02-24 21:17:16,937]   >> |----epoch 0, eclipse 600/16327, lr 0.0000,loss 0.3019, acc 0.9314
[2019-02-24 21:18:29,972]   >> |----epoch 0, eclipse 900/16327, lr 0.0000,loss 0.1908, acc 0.9371
[2019-02-24 21:19:43,033]   >> |----epoch 0, eclipse 1200/16327, lr 0.0000,loss 0.1373, acc 0.9479
[2019-02-24 21:20:56,137]   >> |----epoch 0, eclipse 1500/16327, lr 0.0000,loss 0.1224, acc 0.9486
[2019-02-24 21:22:09,224]   >> |----epoch 0, eclipse 1800/16327, lr 0.0000,loss 0.1142, acc 0.9518
[2019-02-24 21:23:22,314]   >> |----epoch 0, eclipse 2100/16327, lr 0.0000,loss 0.1123, acc 0.9518
[2019-02-24 21:24:35,430]   >> |----epoch 0, eclipse 2400/16327, lr 0.0000,loss 0.1106, acc 0.9525
[2019-02-24 21:25:48,570]   >> |----epoch 0, eclipse 2700/16327, lr 0.0000,loss 0.1073, acc 0.9543
[2019-02-24 21:27:01,725]   >> |----epoch 0, eclipse 3000/16327, lr 0.0000,loss 0.1138, acc 0.9531
[2019-02-24 21:28:14,873]   >> |----epoch 0, eclipse 3300/16327, lr 0.0000,loss 0.1151, acc 0.9514
[2019-02-24 21:29:28,006]   >> |----epoch 0, eclipse 3600/16327, lr 0.0000,loss 0.1129, acc 0.9522
[2019-02-24 21:30:41,147]   >> |----epoch 0, eclipse 3900/16327, lr 0.0000,loss 0.1053, acc 0.9528
[2019-02-24 21:31:54,293]   >> |----epoch 0, eclipse 4200/16327, lr 0.0000,loss 0.1081, acc 0.9547
[2019-02-24 21:33:07,444]   >> |----epoch 0, eclipse 4500/16327, lr 0.0000,loss 0.1064, acc 0.9526
[2019-02-24 21:34:20,591]   >> |----epoch 0, eclipse 4800/16327, lr 0.0000,loss 0.1100, acc 0.9543
[2019-02-24 21:35:33,746]   >> |----epoch 0, eclipse 5100/16327, lr 0.0000,loss 0.1032, acc 0.9558
[2019-02-24 21:36:46,919]   >> |----epoch 0, eclipse 5400/16327, lr 0.0000,loss 0.1086, acc 0.9532
[2019-02-24 21:38:00,093]   >> |----epoch 0, eclipse 5700/16327, lr 0.0000,loss 0.1000, acc 0.9568
[2019-02-24 21:39:13,256]   >> |----epoch 0, eclipse 6000/16327, lr 0.0000,loss 0.1058, acc 0.9556
[2019-02-24 21:40:26,412]   >> |----epoch 0, eclipse 6300/16327, lr 0.0000,loss 0.1013, acc 0.9580
[2019-02-24 21:41:39,561]   >> |----epoch 0, eclipse 6600/16327, lr 0.0000,loss 0.1003, acc 0.9578
[2019-02-24 21:42:52,688]   >> |----epoch 0, eclipse 6900/16327, lr 0.0000,loss 0.0984, acc 0.9591
[2019-02-24 21:44:05,797]   >> |----epoch 0, eclipse 7200/16327, lr 0.0000,loss 0.0959, acc 0.9598
[2019-02-24 21:45:18,946]   >> |----epoch 0, eclipse 7500/16327, lr 0.0000,loss 0.0991, acc 0.9581
[2019-02-24 21:46:32,145]   >> |----epoch 0, eclipse 7800/16327, lr 0.0000,loss 0.1031, acc 0.9564
[2019-02-24 21:47:45,388]   >> |----epoch 0, eclipse 8100/16327, lr 0.0000,loss 0.1011, acc 0.9570
[2019-02-24 21:48:58,592]   >> |----epoch 0, eclipse 8400/16327, lr 0.0000,loss 0.1006, acc 0.9582
[2019-02-24 21:50:11,791]   >> |----epoch 0, eclipse 8700/16327, lr 0.0000,loss 0.0958, acc 0.9590
[2019-02-24 21:51:24,971]   >> |----epoch 0, eclipse 9000/16327, lr 0.0000,loss 0.1002, acc 0.9567
[2019-02-24 21:52:38,122]   >> |----epoch 0, eclipse 9300/16327, lr 0.0000,loss 0.0952, acc 0.9590
[2019-02-24 21:53:51,287]   >> |----epoch 0, eclipse 9600/16327, lr 0.0000,loss 0.0988, acc 0.9563
[2019-02-24 21:55:04,476]   >> |----epoch 0, eclipse 9900/16327, lr 0.0000,loss 0.1005, acc 0.9585
[2019-02-24 21:56:17,642]   >> |----epoch 0, eclipse 10200/16327, lr 0.0000,loss 0.0973, acc 0.9596
[2019-02-24 21:57:30,819]   >> |----epoch 0, eclipse 10500/16327, lr 0.0000,loss 0.1046, acc 0.9565
[2019-02-24 21:58:43,993]   >> |----epoch 0, eclipse 10800/16327, lr 0.0000,loss 0.0963, acc 0.9583
[2019-02-24 21:59:57,167]   >> |----epoch 0, eclipse 11100/16327, lr 0.0000,loss 0.0995, acc 0.9587
[2019-02-24 22:01:10,362]   >> |----epoch 0, eclipse 11400/16327, lr 0.0000,loss 0.1002, acc 0.9553
[2019-02-24 22:02:23,539]   >> |----epoch 0, eclipse 11700/16327, lr 0.0000,loss 0.0961, acc 0.9593
[2019-02-24 22:03:36,803]   >> |----epoch 0, eclipse 12000/16327, lr 0.0000,loss 0.0991, acc 0.9591
[2019-02-24 22:04:50,070]   >> |----epoch 0, eclipse 12300/16327, lr 0.0000,loss 0.0986, acc 0.9582
[2019-02-24 22:06:03,365]   >> |----epoch 0, eclipse 12600/16327, lr 0.0000,loss 0.0952, acc 0.9590
[2019-02-24 22:07:16,538]   >> |----epoch 0, eclipse 12900/16327, lr 0.0000,loss 0.0953, acc 0.9603
[2019-02-24 22:08:29,724]   >> |----epoch 0, eclipse 13200/16327, lr 0.0000,loss 0.0931, acc 0.9607
[2019-02-24 22:09:42,913]   >> |----epoch 0, eclipse 13500/16327, lr 0.0000,loss 0.0959, acc 0.9583
[2019-02-24 22:10:56,119]   >> |----epoch 0, eclipse 13800/16327, lr 0.0000,loss 0.0946, acc 0.9595
[2019-02-24 22:12:09,312]   >> |----epoch 0, eclipse 14100/16327, lr 0.0000,loss 0.0894, acc 0.9622
[2019-02-24 22:13:22,507]   >> |----epoch 0, eclipse 14400/16327, lr 0.0000,loss 0.0954, acc 0.9588
[2019-02-24 22:14:35,703]   >> |----epoch 0, eclipse 14700/16327, lr 0.0000,loss 0.0962, acc 0.9572
[2019-02-24 22:15:48,881]   >> |----epoch 0, eclipse 15000/16327, lr 0.0000,loss 0.0972, acc 0.9572
[2019-02-24 22:17:02,060]   >> |----epoch 0, eclipse 15300/16327, lr 0.0000,loss 0.0952, acc 0.9587
[2019-02-24 22:18:15,219]   >> |----epoch 0, eclipse 15600/16327, lr 0.0000,loss 0.0920, acc 0.9607
[2019-02-24 22:19:28,374]   >> |----epoch 0, eclipse 15900/16327, lr 0.0000,loss 0.0919, acc 0.9617
[2019-02-24 22:20:41,536]   >> |----epoch 0, eclipse 16200/16327, lr 0.0000,loss 0.0980, acc 0.9570
[2019-02-24 22:27:24,442]   >> epcoh 0, threshold 0.2000, accuracy 0.9523, precision 0.5805, recall 0.8350, f1 0.6849, best_f1 0.6849
[2019-02-24 22:27:24,923]   >> epcoh 0, threshold 0.2103, accuracy 0.9532, precision 0.5871, recall 0.8284, f1 0.6872, best_f1 0.6872
[2019-02-24 22:27:25,284]   >> epcoh 0, threshold 0.2205, accuracy 0.9541, precision 0.5939, recall 0.8224, f1 0.6897, best_f1 0.6897
[2019-02-24 22:27:25,783]   >> epcoh 0, threshold 0.2308, accuracy 0.9550, precision 0.6007, recall 0.8173, f1 0.6925, best_f1 0.6925
[2019-02-24 22:27:26,279]   >> epcoh 0, threshold 0.2410, accuracy 0.9557, precision 0.6070, recall 0.8108, f1 0.6942, best_f1 0.6942
[2019-02-24 22:27:26,772]   >> epcoh 0, threshold 0.2513, accuracy 0.9563, precision 0.6125, recall 0.8046, f1 0.6955, best_f1 0.6955
[2019-02-24 22:27:27,265]   >> epcoh 0, threshold 0.2615, accuracy 0.9569, precision 0.6184, recall 0.7983, f1 0.6969, best_f1 0.6969
[2019-02-24 22:27:27,764]   >> epcoh 0, threshold 0.2718, accuracy 0.9575, precision 0.6244, recall 0.7921, f1 0.6983, best_f1 0.6983
[2019-02-24 22:27:28,263]   >> epcoh 0, threshold 0.2821, accuracy 0.9581, precision 0.6307, recall 0.7856, f1 0.6997, best_f1 0.6997
[2019-02-24 22:27:28,759]   >> epcoh 0, threshold 0.2923, accuracy 0.9587, precision 0.6367, recall 0.7797, f1 0.7010, best_f1 0.7010
[2019-02-24 22:27:29,606]   >> epcoh 0, threshold 0.3026, accuracy 0.9592, precision 0.6426, recall 0.7732, f1 0.7019, best_f1 0.7019
[2019-02-24 22:27:32,080]   >> epcoh 0, threshold 0.3128, accuracy 0.9597, precision 0.6484, recall 0.7665, f1 0.7025, best_f1 0.7025
[2019-02-24 22:27:33,552]   >> epcoh 0, threshold 0.3231, accuracy 0.9602, precision 0.6550, recall 0.7593, f1 0.7033, best_f1 0.7033
[2019-02-24 22:27:33,959]   >> epcoh 0, threshold 0.3333, accuracy 0.9606, precision 0.6607, recall 0.7521, f1 0.7034, best_f1 0.7034
[2019-02-24 22:27:34,043]   >> epcoh 0, threshold 0.3436, accuracy 0.9610, precision 0.6661, recall 0.7449, f1 0.7033, best_f1 0.7034
[2019-02-24 22:27:34,113]   >> epcoh 0, threshold 0.3538, accuracy 0.9613, precision 0.6715, recall 0.7378, f1 0.7031, best_f1 0.7034
[2019-02-24 22:27:34,181]   >> epcoh 0, threshold 0.3641, accuracy 0.9616, precision 0.6767, recall 0.7299, f1 0.7023, best_f1 0.7034
[2019-02-24 22:27:34,247]   >> epcoh 0, threshold 0.3744, accuracy 0.9618, precision 0.6816, recall 0.7223, f1 0.7014, best_f1 0.7034
[2019-02-24 22:27:34,315]   >> epcoh 0, threshold 0.3846, accuracy 0.9620, precision 0.6862, recall 0.7146, f1 0.7001, best_f1 0.7034
[2019-02-24 22:27:34,508]   >> epcoh 0, threshold 0.3949, accuracy 0.9622, precision 0.6910, recall 0.7065, f1 0.6987, best_f1 0.7034
[2019-02-24 22:27:34,577]   >> epcoh 0, threshold 0.4051, accuracy 0.9625, precision 0.6978, recall 0.6981, f1 0.6980, best_f1 0.7034
[2019-02-24 22:27:34,646]   >> epcoh 0, threshold 0.4154, accuracy 0.9627, precision 0.7031, recall 0.6898, f1 0.6964, best_f1 0.7034
[2019-02-24 22:27:34,712]   >> epcoh 0, threshold 0.4256, accuracy 0.9628, precision 0.7081, recall 0.6808, f1 0.6942, best_f1 0.7034
[2019-02-24 22:27:34,778]   >> epcoh 0, threshold 0.4359, accuracy 0.9629, precision 0.7137, recall 0.6706, f1 0.6915, best_f1 0.7034
[2019-02-24 22:27:34,844]   >> epcoh 0, threshold 0.4462, accuracy 0.9630, precision 0.7193, recall 0.6624, f1 0.6896, best_f1 0.7034
[2019-02-24 22:27:34,910]   >> epcoh 0, threshold 0.4564, accuracy 0.9631, precision 0.7245, recall 0.6541, f1 0.6875, best_f1 0.7034
[2019-02-24 22:27:34,976]   >> epcoh 0, threshold 0.4667, accuracy 0.9630, precision 0.7290, recall 0.6434, f1 0.6836, best_f1 0.7034
[2019-02-24 22:27:35,041]   >> epcoh 0, threshold 0.4769, accuracy 0.9631, precision 0.7346, recall 0.6345, f1 0.6809, best_f1 0.7034
[2019-02-24 22:27:35,108]   >> epcoh 0, threshold 0.4872, accuracy 0.9631, precision 0.7399, recall 0.6253, f1 0.6778, best_f1 0.7034
[2019-02-24 22:27:35,173]   >> epcoh 0, threshold 0.4974, accuracy 0.9629, precision 0.7442, recall 0.6137, f1 0.6727, best_f1 0.7034
[2019-02-24 22:27:35,238]   >> epcoh 0, threshold 0.5077, accuracy 0.9628, precision 0.7493, recall 0.6013, f1 0.6672, best_f1 0.7034
[2019-02-24 22:27:35,303]   >> epcoh 0, threshold 0.5179, accuracy 0.9625, precision 0.7535, recall 0.5883, f1 0.6608, best_f1 0.7034
[2019-02-24 22:27:35,367]   >> epcoh 0, threshold 0.5282, accuracy 0.9624, precision 0.7592, recall 0.5764, f1 0.6553, best_f1 0.7034
[2019-02-24 22:27:35,432]   >> epcoh 0, threshold 0.5385, accuracy 0.9622, precision 0.7651, recall 0.5633, f1 0.6489, best_f1 0.7034
[2019-02-24 22:27:35,497]   >> epcoh 0, threshold 0.5487, accuracy 0.9619, precision 0.7707, recall 0.5494, f1 0.6415, best_f1 0.7034
[2019-02-24 22:27:35,562]   >> epcoh 0, threshold 0.5590, accuracy 0.9617, precision 0.7783, recall 0.5343, f1 0.6336, best_f1 0.7034
[2019-02-24 22:27:35,626]   >> epcoh 0, threshold 0.5692, accuracy 0.9614, precision 0.7852, recall 0.5195, f1 0.6253, best_f1 0.7034
[2019-02-24 22:27:35,690]   >> epcoh 0, threshold 0.5795, accuracy 0.9609, precision 0.7905, recall 0.5025, f1 0.6144, best_f1 0.7034
[2019-02-24 22:27:35,754]   >> epcoh 0, threshold 0.5897, accuracy 0.9603, precision 0.7968, recall 0.4837, f1 0.6020, best_f1 0.7034
[2019-02-24 22:27:35,818]   >> epcoh 0, threshold 0.6000, accuracy 0.9597, precision 0.8033, recall 0.4648, f1 0.5888, best_f1 0.7034
[2019-02-24 22:30:01,585]   >> ***** Running training *****
[2019-02-24 22:30:01,585]   >>   Num examples = 1044897
[2019-02-24 22:30:01,585]   >>   Batch size = 64
[2019-02-24 22:30:01,586]   >>   Num steps = 48979
[2019-02-24 22:31:15,476]   >> |----epoch 1, eclipse 300/16327, lr 0.0000,loss 0.0794, acc 0.9673
[2019-02-24 22:32:28,477]   >> |----epoch 1, eclipse 600/16327, lr 0.0000,loss 0.0752, acc 0.9663
[2019-02-24 22:33:41,588]   >> |----epoch 1, eclipse 900/16327, lr 0.0000,loss 0.0729, acc 0.9693
[2019-02-24 22:34:54,736]   >> |----epoch 1, eclipse 1200/16327, lr 0.0000,loss 0.0709, acc 0.9695
[2019-02-24 22:36:07,900]   >> |----epoch 1, eclipse 1500/16327, lr 0.0000,loss 0.0724, acc 0.9694
[2019-02-24 22:37:21,062]   >> |----epoch 1, eclipse 1800/16327, lr 0.0000,loss 0.0719, acc 0.9695
[2019-02-24 22:38:34,218]   >> |----epoch 1, eclipse 2100/16327, lr 0.0000,loss 0.0750, acc 0.9689
[2019-02-24 22:39:47,396]   >> |----epoch 1, eclipse 2400/16327, lr 0.0000,loss 0.0732, acc 0.9691
[2019-02-24 22:41:00,586]   >> |----epoch 1, eclipse 2700/16327, lr 0.0000,loss 0.0741, acc 0.9694
[2019-02-24 22:42:13,754]   >> |----epoch 1, eclipse 3000/16327, lr 0.0000,loss 0.0646, acc 0.9739
[2019-02-24 22:43:26,938]   >> |----epoch 1, eclipse 3300/16327, lr 0.0000,loss 0.0719, acc 0.9697
[2019-02-24 22:44:40,131]   >> |----epoch 1, eclipse 3600/16327, lr 0.0000,loss 0.0736, acc 0.9694
[2019-02-24 22:45:53,307]   >> |----epoch 1, eclipse 3900/16327, lr 0.0000,loss 0.0746, acc 0.9694
[2019-02-24 22:47:06,482]   >> |----epoch 1, eclipse 4200/16327, lr 0.0000,loss 0.0717, acc 0.9697
[2019-02-24 22:48:19,664]   >> |----epoch 1, eclipse 4500/16327, lr 0.0000,loss 0.0755, acc 0.9684
[2019-02-24 22:49:32,850]   >> |----epoch 1, eclipse 4800/16327, lr 0.0000,loss 0.0752, acc 0.9658
[2019-02-24 22:50:46,059]   >> |----epoch 1, eclipse 5100/16327, lr 0.0000,loss 0.0728, acc 0.9688
[2019-02-24 22:51:59,262]   >> |----epoch 1, eclipse 5400/16327, lr 0.0000,loss 0.0739, acc 0.9693
[2019-02-24 22:53:12,487]   >> |----epoch 1, eclipse 5700/16327, lr 0.0000,loss 0.0745, acc 0.9682
[2019-02-24 22:54:25,711]   >> |----epoch 1, eclipse 6000/16327, lr 0.0000,loss 0.0747, acc 0.9670
[2019-02-24 22:55:38,942]   >> |----epoch 1, eclipse 6300/16327, lr 0.0000,loss 0.0749, acc 0.9692
[2019-02-24 22:56:52,174]   >> |----epoch 1, eclipse 6600/16327, lr 0.0000,loss 0.0824, acc 0.9651
[2019-02-24 22:58:05,414]   >> |----epoch 1, eclipse 6900/16327, lr 0.0000,loss 0.0731, acc 0.9698
[2019-02-24 22:59:18,638]   >> |----epoch 1, eclipse 7200/16327, lr 0.0000,loss 0.0775, acc 0.9682
[2019-02-24 23:00:31,870]   >> |----epoch 1, eclipse 7500/16327, lr 0.0000,loss 0.0766, acc 0.9676
[2019-02-24 23:01:45,100]   >> |----epoch 1, eclipse 7800/16327, lr 0.0000,loss 0.0746, acc 0.9672
[2019-02-24 23:02:58,321]   >> |----epoch 1, eclipse 8100/16327, lr 0.0000,loss 0.0765, acc 0.9670
[2019-02-24 23:04:11,556]   >> |----epoch 1, eclipse 8400/16327, lr 0.0000,loss 0.0807, acc 0.9652
[2019-02-24 23:05:24,789]   >> |----epoch 1, eclipse 8700/16327, lr 0.0000,loss 0.0758, acc 0.9672
[2019-02-24 23:06:37,998]   >> |----epoch 1, eclipse 9000/16327, lr 0.0000,loss 0.0749, acc 0.9677
[2019-02-24 23:07:51,212]   >> |----epoch 1, eclipse 9300/16327, lr 0.0000,loss 0.0742, acc 0.9683
[2019-02-24 23:09:04,423]   >> |----epoch 1, eclipse 9600/16327, lr 0.0000,loss 0.0755, acc 0.9688
[2019-02-24 23:10:17,667]   >> |----epoch 1, eclipse 9900/16327, lr 0.0000,loss 0.0754, acc 0.9683
[2019-02-24 23:11:30,926]   >> |----epoch 1, eclipse 10200/16327, lr 0.0000,loss 0.0792, acc 0.9677
[2019-02-24 23:12:44,189]   >> |----epoch 1, eclipse 10500/16327, lr 0.0000,loss 0.0763, acc 0.9672
[2019-02-24 23:13:57,393]   >> |----epoch 1, eclipse 10800/16327, lr 0.0000,loss 0.0753, acc 0.9693
[2019-02-24 23:15:10,610]   >> |----epoch 1, eclipse 11100/16327, lr 0.0000,loss 0.0729, acc 0.9683
[2019-02-24 23:16:23,818]   >> |----epoch 1, eclipse 11400/16327, lr 0.0000,loss 0.0784, acc 0.9669
[2019-02-24 23:17:37,032]   >> |----epoch 1, eclipse 11700/16327, lr 0.0000,loss 0.0695, acc 0.9698
[2019-02-24 23:18:50,278]   >> |----epoch 1, eclipse 12000/16327, lr 0.0000,loss 0.0768, acc 0.9682
[2019-02-24 23:20:03,474]   >> |----epoch 1, eclipse 12300/16327, lr 0.0000,loss 0.0766, acc 0.9680
[2019-02-24 23:21:16,201]   >> |----epoch 1, eclipse 12600/16327, lr 0.0000,loss 0.0770, acc 0.9681
[2019-02-24 23:22:28,832]   >> |----epoch 1, eclipse 12900/16327, lr 0.0000,loss 0.0742, acc 0.9687
[2019-02-24 23:23:41,453]   >> |----epoch 1, eclipse 13200/16327, lr 0.0000,loss 0.0720, acc 0.9709
[2019-02-24 23:24:54,157]   >> |----epoch 1, eclipse 13500/16327, lr 0.0000,loss 0.0731, acc 0.9691
[2019-02-24 23:26:06,892]   >> |----epoch 1, eclipse 13800/16327, lr 0.0000,loss 0.0738, acc 0.9686
[2019-02-24 23:27:19,640]   >> |----epoch 1, eclipse 14100/16327, lr 0.0000,loss 0.0745, acc 0.9686
[2019-02-24 23:28:32,416]   >> |----epoch 1, eclipse 14400/16327, lr 0.0000,loss 0.0792, acc 0.9674
[2019-02-24 23:29:45,176]   >> |----epoch 1, eclipse 14700/16327, lr 0.0000,loss 0.0751, acc 0.9678
[2019-02-24 23:30:57,926]   >> |----epoch 1, eclipse 15000/16327, lr 0.0000,loss 0.0737, acc 0.9670
[2019-02-24 23:32:10,650]   >> |----epoch 1, eclipse 15300/16327, lr 0.0000,loss 0.0751, acc 0.9678
[2019-02-24 23:33:23,391]   >> |----epoch 1, eclipse 15600/16327, lr 0.0000,loss 0.0750, acc 0.9691
[2019-02-24 23:34:36,121]   >> |----epoch 1, eclipse 15900/16327, lr 0.0000,loss 0.0732, acc 0.9696
[2019-02-24 23:35:48,845]   >> |----epoch 1, eclipse 16200/16327, lr 0.0000,loss 0.0704, acc 0.9703
[2019-02-24 23:42:33,279]   >> epcoh 1, threshold 0.2000, accuracy 0.9595, precision 0.6423, recall 0.7851, f1 0.7066, best_f1 0.7066
[2019-02-24 23:42:33,767]   >> epcoh 1, threshold 0.2103, accuracy 0.9600, precision 0.6477, recall 0.7802, f1 0.7078, best_f1 0.7078
[2019-02-24 23:42:34,135]   >> epcoh 1, threshold 0.2205, accuracy 0.9604, precision 0.6523, recall 0.7748, f1 0.7083, best_f1 0.7083
[2019-02-24 23:42:34,627]   >> epcoh 1, threshold 0.2308, accuracy 0.9607, precision 0.6569, recall 0.7690, f1 0.7086, best_f1 0.7086
[2019-02-24 23:42:34,701]   >> epcoh 1, threshold 0.2410, accuracy 0.9610, precision 0.6613, recall 0.7631, f1 0.7086, best_f1 0.7086
[2019-02-24 23:42:35,124]   >> epcoh 1, threshold 0.2513, accuracy 0.9614, precision 0.6658, recall 0.7582, f1 0.7090, best_f1 0.7090
[2019-02-24 23:42:35,194]   >> epcoh 1, threshold 0.2615, accuracy 0.9616, precision 0.6697, recall 0.7519, f1 0.7084, best_f1 0.7090
[2019-02-24 23:42:35,263]   >> epcoh 1, threshold 0.2718, accuracy 0.9618, precision 0.6738, recall 0.7460, f1 0.7081, best_f1 0.7090
[2019-02-24 23:42:35,332]   >> epcoh 1, threshold 0.2821, accuracy 0.9620, precision 0.6775, recall 0.7400, f1 0.7073, best_f1 0.7090
[2019-02-24 23:42:35,400]   >> epcoh 1, threshold 0.2923, accuracy 0.9622, precision 0.6815, recall 0.7339, f1 0.7067, best_f1 0.7090
[2019-02-24 23:42:35,466]   >> epcoh 1, threshold 0.3026, accuracy 0.9624, precision 0.6851, recall 0.7283, f1 0.7060, best_f1 0.7090
[2019-02-24 23:42:35,531]   >> epcoh 1, threshold 0.3128, accuracy 0.9625, precision 0.6886, recall 0.7237, f1 0.7057, best_f1 0.7090
[2019-02-24 23:42:35,596]   >> epcoh 1, threshold 0.3231, accuracy 0.9627, precision 0.6922, recall 0.7180, f1 0.7049, best_f1 0.7090
[2019-02-24 23:42:35,662]   >> epcoh 1, threshold 0.3333, accuracy 0.9629, precision 0.6965, recall 0.7139, f1 0.7051, best_f1 0.7090
[2019-02-24 23:42:35,727]   >> epcoh 1, threshold 0.3436, accuracy 0.9630, precision 0.6992, recall 0.7083, f1 0.7037, best_f1 0.7090
[2019-02-24 23:42:35,792]   >> epcoh 1, threshold 0.3538, accuracy 0.9631, precision 0.7029, recall 0.7032, f1 0.7030, best_f1 0.7090
[2019-02-24 23:42:35,858]   >> epcoh 1, threshold 0.3641, accuracy 0.9633, precision 0.7071, recall 0.6983, f1 0.7027, best_f1 0.7090
[2019-02-24 23:42:35,924]   >> epcoh 1, threshold 0.3744, accuracy 0.9633, precision 0.7099, recall 0.6911, f1 0.7004, best_f1 0.7090
[2019-02-24 23:42:35,989]   >> epcoh 1, threshold 0.3846, accuracy 0.9634, precision 0.7132, recall 0.6849, f1 0.6988, best_f1 0.7090
[2019-02-24 23:42:36,054]   >> epcoh 1, threshold 0.3949, accuracy 0.9633, precision 0.7151, recall 0.6785, f1 0.6963, best_f1 0.7090
[2019-02-24 23:42:36,120]   >> epcoh 1, threshold 0.4051, accuracy 0.9634, precision 0.7182, recall 0.6740, f1 0.6954, best_f1 0.7090
[2019-02-24 23:42:36,185]   >> epcoh 1, threshold 0.4154, accuracy 0.9634, precision 0.7214, recall 0.6685, f1 0.6939, best_f1 0.7090
[2019-02-24 23:42:36,251]   >> epcoh 1, threshold 0.4256, accuracy 0.9634, precision 0.7246, recall 0.6627, f1 0.6923, best_f1 0.7090
[2019-02-24 23:42:36,316]   >> epcoh 1, threshold 0.4359, accuracy 0.9634, precision 0.7275, recall 0.6569, f1 0.6904, best_f1 0.7090
[2019-02-24 23:42:36,380]   >> epcoh 1, threshold 0.4462, accuracy 0.9634, precision 0.7296, recall 0.6521, f1 0.6887, best_f1 0.7090
[2019-02-24 23:42:36,445]   >> epcoh 1, threshold 0.4564, accuracy 0.9635, precision 0.7329, recall 0.6473, f1 0.6874, best_f1 0.7090
[2019-02-24 23:42:36,510]   >> epcoh 1, threshold 0.4667, accuracy 0.9635, precision 0.7357, recall 0.6419, f1 0.6856, best_f1 0.7090
[2019-02-24 23:42:36,575]   >> epcoh 1, threshold 0.4769, accuracy 0.9635, precision 0.7389, recall 0.6379, f1 0.6847, best_f1 0.7090
[2019-02-24 23:42:36,641]   >> epcoh 1, threshold 0.4872, accuracy 0.9635, precision 0.7420, recall 0.6319, f1 0.6825, best_f1 0.7090
[2019-02-24 23:42:36,705]   >> epcoh 1, threshold 0.4974, accuracy 0.9635, precision 0.7447, recall 0.6264, f1 0.6804, best_f1 0.7090
[2019-02-24 23:42:36,770]   >> epcoh 1, threshold 0.5077, accuracy 0.9634, precision 0.7473, recall 0.6202, f1 0.6778, best_f1 0.7090
[2019-02-24 23:42:36,835]   >> epcoh 1, threshold 0.5179, accuracy 0.9634, precision 0.7503, recall 0.6143, f1 0.6755, best_f1 0.7090
[2019-02-24 23:42:36,900]   >> epcoh 1, threshold 0.5282, accuracy 0.9633, precision 0.7536, recall 0.6078, f1 0.6729, best_f1 0.7090
[2019-02-24 23:42:36,964]   >> epcoh 1, threshold 0.5385, accuracy 0.9633, precision 0.7561, recall 0.6023, f1 0.6705, best_f1 0.7090
[2019-02-24 23:42:37,030]   >> epcoh 1, threshold 0.5487, accuracy 0.9632, precision 0.7589, recall 0.5957, f1 0.6675, best_f1 0.7090
[2019-02-24 23:42:37,095]   >> epcoh 1, threshold 0.5590, accuracy 0.9630, precision 0.7606, recall 0.5898, f1 0.6644, best_f1 0.7090
[2019-02-24 23:42:37,159]   >> epcoh 1, threshold 0.5692, accuracy 0.9629, precision 0.7628, recall 0.5825, f1 0.6606, best_f1 0.7090
[2019-02-24 23:42:37,224]   >> epcoh 1, threshold 0.5795, accuracy 0.9627, precision 0.7652, recall 0.5753, f1 0.6568, best_f1 0.7090
[2019-02-24 23:42:37,287]   >> epcoh 1, threshold 0.5897, accuracy 0.9626, precision 0.7680, recall 0.5688, f1 0.6536, best_f1 0.7090
[2019-02-24 23:42:37,352]   >> epcoh 1, threshold 0.6000, accuracy 0.9625, precision 0.7708, recall 0.5622, f1 0.6502, best_f1 0.7090
[2019-02-24 23:45:05,809]   >> ***** Running training *****
[2019-02-24 23:45:05,809]   >>   Num examples = 1044897
[2019-02-24 23:45:05,809]   >>   Batch size = 64
[2019-02-24 23:45:05,809]   >>   Num steps = 48979
[2019-02-24 23:46:19,652]   >> |----epoch 2, eclipse 300/16327, lr 0.0000,loss 0.0566, acc 0.9783
[2019-02-24 23:47:32,408]   >> |----epoch 2, eclipse 600/16327, lr 0.0000,loss 0.0508, acc 0.9795
[2019-02-24 23:48:45,181]   >> |----epoch 2, eclipse 900/16327, lr 0.0000,loss 0.0453, acc 0.9817
[2019-02-24 23:49:57,972]   >> |----epoch 2, eclipse 1200/16327, lr 0.0000,loss 0.0487, acc 0.9810
[2019-02-24 23:51:10,766]   >> |----epoch 2, eclipse 1500/16327, lr 0.0000,loss 0.0471, acc 0.9803
[2019-02-24 23:52:23,526]   >> |----epoch 2, eclipse 1800/16327, lr 0.0000,loss 0.0470, acc 0.9810
[2019-02-24 23:53:36,289]   >> |----epoch 2, eclipse 2100/16327, lr 0.0000,loss 0.0507, acc 0.9800
[2019-02-24 23:54:49,059]   >> |----epoch 2, eclipse 2400/16327, lr 0.0000,loss 0.0490, acc 0.9807
[2019-02-24 23:56:01,833]   >> |----epoch 2, eclipse 2700/16327, lr 0.0000,loss 0.0498, acc 0.9790
[2019-02-24 23:57:14,633]   >> |----epoch 2, eclipse 3000/16327, lr 0.0000,loss 0.0486, acc 0.9815
[2019-02-24 23:58:27,403]   >> |----epoch 2, eclipse 3300/16327, lr 0.0000,loss 0.0476, acc 0.9818
[2019-02-24 23:59:40,167]   >> |----epoch 2, eclipse 3600/16327, lr 0.0000,loss 0.0526, acc 0.9792
[2019-02-25 00:00:52,883]   >> |----epoch 2, eclipse 3900/16327, lr 0.0000,loss 0.0460, acc 0.9820
[2019-02-25 00:02:05,538]   >> |----epoch 2, eclipse 4200/16327, lr 0.0000,loss 0.0476, acc 0.9817
[2019-02-25 00:03:18,211]   >> |----epoch 2, eclipse 4500/16327, lr 0.0000,loss 0.0471, acc 0.9806
[2019-02-25 00:04:30,866]   >> |----epoch 2, eclipse 4800/16327, lr 0.0000,loss 0.0482, acc 0.9809
[2019-02-25 00:05:43,502]   >> |----epoch 2, eclipse 5100/16327, lr 0.0000,loss 0.0465, acc 0.9818
[2019-02-25 00:06:56,155]   >> |----epoch 2, eclipse 5400/16327, lr 0.0000,loss 0.0486, acc 0.9805
[2019-02-25 00:08:08,793]   >> |----epoch 2, eclipse 5700/16327, lr 0.0000,loss 0.0508, acc 0.9796
[2019-02-25 00:09:21,442]   >> |----epoch 2, eclipse 6000/16327, lr 0.0000,loss 0.0502, acc 0.9801
[2019-02-25 00:10:34,087]   >> |----epoch 2, eclipse 6300/16327, lr 0.0000,loss 0.0491, acc 0.9809
[2019-02-25 00:11:46,745]   >> |----epoch 2, eclipse 6600/16327, lr 0.0000,loss 0.0476, acc 0.9820
[2019-02-25 00:12:59,401]   >> |----epoch 2, eclipse 6900/16327, lr 0.0000,loss 0.0497, acc 0.9805
[2019-02-25 00:14:12,065]   >> |----epoch 2, eclipse 7200/16327, lr 0.0000,loss 0.0500, acc 0.9805
[2019-02-25 00:15:24,784]   >> |----epoch 2, eclipse 7500/16327, lr 0.0000,loss 0.0492, acc 0.9795
[2019-02-25 00:16:37,564]   >> |----epoch 2, eclipse 7800/16327, lr 0.0000,loss 0.0499, acc 0.9806
[2019-02-25 00:17:50,306]   >> |----epoch 2, eclipse 8100/16327, lr 0.0000,loss 0.0457, acc 0.9820
[2019-02-25 00:19:03,022]   >> |----epoch 2, eclipse 8400/16327, lr 0.0000,loss 0.0487, acc 0.9797
[2019-02-25 00:20:15,778]   >> |----epoch 2, eclipse 8700/16327, lr 0.0000,loss 0.0458, acc 0.9817
[2019-02-25 00:21:28,535]   >> |----epoch 2, eclipse 9000/16327, lr 0.0000,loss 0.0477, acc 0.9809
[2019-02-25 00:22:41,286]   >> |----epoch 2, eclipse 9300/16327, lr 0.0000,loss 0.0450, acc 0.9822
[2019-02-25 00:23:53,988]   >> |----epoch 2, eclipse 9600/16327, lr 0.0000,loss 0.0484, acc 0.9817
[2019-02-25 00:25:06,701]   >> |----epoch 2, eclipse 9900/16327, lr 0.0000,loss 0.0490, acc 0.9802
[2019-02-25 00:26:19,413]   >> |----epoch 2, eclipse 10200/16327, lr 0.0000,loss 0.0433, acc 0.9833
[2019-02-25 00:27:32,121]   >> |----epoch 2, eclipse 10500/16327, lr 0.0000,loss 0.0463, acc 0.9811
[2019-02-25 00:28:44,833]   >> |----epoch 2, eclipse 10800/16327, lr 0.0000,loss 0.0453, acc 0.9817
[2019-02-25 00:29:57,560]   >> |----epoch 2, eclipse 11100/16327, lr 0.0000,loss 0.0452, acc 0.9820
[2019-02-25 00:31:10,272]   >> |----epoch 2, eclipse 11400/16327, lr 0.0000,loss 0.0474, acc 0.9815
[2019-02-25 00:32:23,000]   >> |----epoch 2, eclipse 11700/16327, lr 0.0000,loss 0.0471, acc 0.9805
[2019-02-25 00:33:35,756]   >> |----epoch 2, eclipse 12000/16327, lr 0.0000,loss 0.0468, acc 0.9808
[2019-02-25 00:34:48,508]   >> |----epoch 2, eclipse 12300/16327, lr 0.0000,loss 0.0454, acc 0.9813
[2019-02-25 00:36:01,242]   >> |----epoch 2, eclipse 12600/16327, lr 0.0000,loss 0.0482, acc 0.9817
[2019-02-25 00:37:14,004]   >> |----epoch 2, eclipse 12900/16327, lr 0.0000,loss 0.0484, acc 0.9818
[2019-02-25 00:38:26,729]   >> |----epoch 2, eclipse 13200/16327, lr 0.0000,loss 0.0467, acc 0.9819
[2019-02-25 00:39:39,463]   >> |----epoch 2, eclipse 13500/16327, lr 0.0000,loss 0.0464, acc 0.9818
[2019-02-25 00:40:52,198]   >> |----epoch 2, eclipse 13800/16327, lr 0.0000,loss 0.0470, acc 0.9817
[2019-02-25 00:42:04,943]   >> |----epoch 2, eclipse 14100/16327, lr 0.0000,loss 0.0459, acc 0.9818
[2019-02-25 00:43:17,727]   >> |----epoch 2, eclipse 14400/16327, lr 0.0000,loss 0.0451, acc 0.9816
[2019-02-25 00:44:30,492]   >> |----epoch 2, eclipse 14700/16327, lr 0.0000,loss 0.0452, acc 0.9822
[2019-02-25 00:45:43,246]   >> |----epoch 2, eclipse 15000/16327, lr 0.0000,loss 0.0437, acc 0.9818
[2019-02-25 00:46:55,982]   >> |----epoch 2, eclipse 15300/16327, lr 0.0000,loss 0.0492, acc 0.9811
[2019-02-25 00:48:08,705]   >> |----epoch 2, eclipse 15600/16327, lr 0.0000,loss 0.0481, acc 0.9807
[2019-02-25 00:49:21,429]   >> |----epoch 2, eclipse 15900/16327, lr 0.0000,loss 0.0501, acc 0.9806
[2019-02-25 00:50:34,135]   >> |----epoch 2, eclipse 16200/16327, lr 0.0000,loss 0.0496, acc 0.9797
[2019-02-25 00:57:12,865]   >> epcoh 2, threshold 0.2000, accuracy 0.9597, precision 0.6470, recall 0.7706, f1 0.7034, best_f1 0.7034
[2019-02-25 00:57:13,352]   >> epcoh 2, threshold 0.2103, accuracy 0.9600, precision 0.6511, recall 0.7668, f1 0.7042, best_f1 0.7042
[2019-02-25 00:57:13,704]   >> epcoh 2, threshold 0.2205, accuracy 0.9603, precision 0.6542, recall 0.7629, f1 0.7044, best_f1 0.7044
[2019-02-25 00:57:14,209]   >> epcoh 2, threshold 0.2308, accuracy 0.9605, precision 0.6576, recall 0.7590, f1 0.7047, best_f1 0.7047
[2019-02-25 00:57:14,280]   >> epcoh 2, threshold 0.2410, accuracy 0.9607, precision 0.6599, recall 0.7555, f1 0.7045, best_f1 0.7047
[2019-02-25 00:57:14,701]   >> epcoh 2, threshold 0.2513, accuracy 0.9609, precision 0.6630, recall 0.7527, f1 0.7050, best_f1 0.7050
[2019-02-25 00:57:14,771]   >> epcoh 2, threshold 0.2615, accuracy 0.9611, precision 0.6655, recall 0.7490, f1 0.7048, best_f1 0.7050
[2019-02-25 00:57:14,841]   >> epcoh 2, threshold 0.2718, accuracy 0.9612, precision 0.6683, recall 0.7452, f1 0.7047, best_f1 0.7050
[2019-02-25 00:57:14,910]   >> epcoh 2, threshold 0.2821, accuracy 0.9614, precision 0.6716, recall 0.7410, f1 0.7046, best_f1 0.7050
[2019-02-25 00:57:14,978]   >> epcoh 2, threshold 0.2923, accuracy 0.9615, precision 0.6739, recall 0.7365, f1 0.7038, best_f1 0.7050
[2019-02-25 00:57:15,044]   >> epcoh 2, threshold 0.3026, accuracy 0.9616, precision 0.6762, recall 0.7321, f1 0.7030, best_f1 0.7050
[2019-02-25 00:57:15,109]   >> epcoh 2, threshold 0.3128, accuracy 0.9618, precision 0.6793, recall 0.7286, f1 0.7031, best_f1 0.7050
[2019-02-25 00:57:15,176]   >> epcoh 2, threshold 0.3231, accuracy 0.9619, precision 0.6812, recall 0.7249, f1 0.7024, best_f1 0.7050
[2019-02-25 00:57:15,241]   >> epcoh 2, threshold 0.3333, accuracy 0.9620, precision 0.6836, recall 0.7212, f1 0.7019, best_f1 0.7050
[2019-02-25 00:57:15,307]   >> epcoh 2, threshold 0.3436, accuracy 0.9621, precision 0.6857, recall 0.7180, f1 0.7014, best_f1 0.7050
[2019-02-25 00:57:15,373]   >> epcoh 2, threshold 0.3538, accuracy 0.9622, precision 0.6881, recall 0.7140, f1 0.7008, best_f1 0.7050
[2019-02-25 00:57:15,439]   >> epcoh 2, threshold 0.3641, accuracy 0.9623, precision 0.6908, recall 0.7114, f1 0.7009, best_f1 0.7050
[2019-02-25 00:57:15,504]   >> epcoh 2, threshold 0.3744, accuracy 0.9624, precision 0.6927, recall 0.7082, f1 0.7004, best_f1 0.7050
[2019-02-25 00:57:15,570]   >> epcoh 2, threshold 0.3846, accuracy 0.9624, precision 0.6944, recall 0.7045, f1 0.6994, best_f1 0.7050
[2019-02-25 00:57:15,636]   >> epcoh 2, threshold 0.3949, accuracy 0.9625, precision 0.6963, recall 0.7008, f1 0.6986, best_f1 0.7050
[2019-02-25 00:57:15,701]   >> epcoh 2, threshold 0.4051, accuracy 0.9625, precision 0.6982, recall 0.6972, f1 0.6977, best_f1 0.7050
[2019-02-25 00:57:15,767]   >> epcoh 2, threshold 0.4154, accuracy 0.9626, precision 0.7004, recall 0.6940, f1 0.6972, best_f1 0.7050
[2019-02-25 00:57:15,832]   >> epcoh 2, threshold 0.4256, accuracy 0.9625, precision 0.7017, recall 0.6889, f1 0.6952, best_f1 0.7050
[2019-02-25 00:57:15,898]   >> epcoh 2, threshold 0.4359, accuracy 0.9626, precision 0.7040, recall 0.6856, f1 0.6947, best_f1 0.7050
[2019-02-25 00:57:15,962]   >> epcoh 2, threshold 0.4462, accuracy 0.9626, precision 0.7055, recall 0.6816, f1 0.6934, best_f1 0.7050
[2019-02-25 00:57:16,028]   >> epcoh 2, threshold 0.4564, accuracy 0.9626, precision 0.7076, recall 0.6780, f1 0.6925, best_f1 0.7050
[2019-02-25 00:57:16,093]   >> epcoh 2, threshold 0.4667, accuracy 0.9627, precision 0.7098, recall 0.6748, f1 0.6918, best_f1 0.7050
[2019-02-25 00:57:16,158]   >> epcoh 2, threshold 0.4769, accuracy 0.9627, precision 0.7115, recall 0.6716, f1 0.6910, best_f1 0.7050
[2019-02-25 00:57:16,224]   >> epcoh 2, threshold 0.4872, accuracy 0.9628, precision 0.7138, recall 0.6676, f1 0.6899, best_f1 0.7050
[2019-02-25 00:57:16,288]   >> epcoh 2, threshold 0.4974, accuracy 0.9626, precision 0.7144, recall 0.6626, f1 0.6875, best_f1 0.7050
[2019-02-25 00:57:16,353]   >> epcoh 2, threshold 0.5077, accuracy 0.9626, precision 0.7165, recall 0.6587, f1 0.6864, best_f1 0.7050
[2019-02-25 00:57:16,419]   >> epcoh 2, threshold 0.5179, accuracy 0.9627, precision 0.7190, recall 0.6542, f1 0.6851, best_f1 0.7050
[2019-02-25 00:57:16,484]   >> epcoh 2, threshold 0.5282, accuracy 0.9627, precision 0.7209, recall 0.6497, f1 0.6835, best_f1 0.7050
[2019-02-25 00:57:16,549]   >> epcoh 2, threshold 0.5385, accuracy 0.9627, precision 0.7238, recall 0.6460, f1 0.6827, best_f1 0.7050
[2019-02-25 00:57:16,614]   >> epcoh 2, threshold 0.5487, accuracy 0.9628, precision 0.7259, recall 0.6425, f1 0.6817, best_f1 0.7050
[2019-02-25 00:57:16,680]   >> epcoh 2, threshold 0.5590, accuracy 0.9628, precision 0.7279, recall 0.6387, f1 0.6804, best_f1 0.7050
[2019-02-25 00:57:16,744]   >> epcoh 2, threshold 0.5692, accuracy 0.9628, precision 0.7302, recall 0.6347, f1 0.6791, best_f1 0.7050
[2019-02-25 00:57:16,809]   >> epcoh 2, threshold 0.5795, accuracy 0.9628, precision 0.7327, recall 0.6305, f1 0.6778, best_f1 0.7050
[2019-02-25 00:57:16,874]   >> epcoh 2, threshold 0.5897, accuracy 0.9628, precision 0.7351, recall 0.6262, f1 0.6763, best_f1 0.7050
[2019-02-25 00:57:16,939]   >> epcoh 2, threshold 0.6000, accuracy 0.9628, precision 0.7375, recall 0.6221, f1 0.6749, best_f1 0.7050
